{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS_BP预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sc_special\n",
    "import tensorflow as tf \n",
    "from \ttensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers,metrics,layers,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据以及预处理\n",
    "data = pd.read_csv('DATASETS/EnvData.csv',sep=',',header=None,usecols=[0,1,2,3])\n",
    "X = data.iloc[:801,:3]\n",
    "Y = data.iloc[:801,3]\n",
    "TestX = data.iloc[801:,:3]\n",
    "TestY = data.iloc[801:,3]\n",
    "\n",
    "inputnum = 3\n",
    "hiddennum = 8\n",
    "outputnum = 2\n",
    "numsum = inputnum*hiddennum+hiddennum+hiddennum*outputnum+outputnum #6*10+10+10*3+3=103\n",
    "bestfit = []\n",
    "bestloss = []\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32) \n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=2)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "#零均值处理\n",
    "X[0] -= np.mean(X,axis=0)[0]  \n",
    "X[1] -= np.mean(X,axis=0)[1]\n",
    "X[2] -= np.mean(X,axis=0)[2]\n",
    "#归一化\n",
    "X[0] /= np.max(np.abs(X),axis=0)[0]\n",
    "X[1] /= np.max(np.abs(X),axis=0)[1]\n",
    "X[2] /= np.max(np.abs(X),axis=0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#零均值处理\n",
    "TestX[0] -= np.mean(TestX,axis=0)[0]  \n",
    "TestX[1] -= np.mean(TestX,axis=0)[1]\n",
    "TestX[2] -= np.mean(TestX,axis=0)[2]\n",
    "#归一化\n",
    "TestX[0] /= np.max(np.abs(TestX),axis=0)[0]\n",
    "TestX[1] /= np.max(np.abs(TestX),axis=0)[1]\n",
    "TestX[2] /= np.max(np.abs(TestX),axis=0)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3) (16, 2)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 16\n",
    "db = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((TestX,TestY))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape,sample[1].shape)\n",
    "copyX = X\n",
    "Y_onehot = tf.one_hot(Y,depth=2)\n",
    "TestY_onehot = tf.one_hot(TestY,depth=2)\n",
    "X = tf.cast(X,dtype=tf.float32) \n",
    "TestX = tf.cast(TestX,dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#n：布谷鸟数  m：布谷鸟的维度\n",
    "def cuckoo_search(n, m, lower_boundary, upper_boundary, iter_num = 2,pa = 0.25, beta = 1.5, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Cuckoo search function\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        iter_num: Number of iterations (default: 100) \n",
    "        pa: Possibility that hosts find cuckoos' eggs (default: 0.25)\n",
    "        beta: Power law index (note: 1 < beta < 2) (default: 1.5)\n",
    "        step_size:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        The best solution and its value\n",
    "    \"\"\"\n",
    "    # get initial nests' locations \n",
    "    nests = generate_nests(n, m, lower_boundary, upper_boundary)\n",
    "    fitness,lossness = calc_fitness( nests,0.5) #包含所有的适应度  用列表存储\n",
    "    \n",
    "    #得到每代最小loss\n",
    "    best_loss_index = np.argmin(lossness)\n",
    "    best_loss = lossness[best_loss_index]\n",
    "    best_nestloss = nests[best_loss_index].copy()\n",
    "    bestloss.append(best_loss)\n",
    "    \n",
    "    # get the best nest and record it\n",
    "    best_nest_index = np.argmax(fitness)\n",
    "    best_fitness = fitness[best_nest_index]\n",
    "    best_nest = nests[best_nest_index].copy()\n",
    "    bestfit.append(best_fitness) #全局变量，保存每代最佳适应度值\n",
    "    \n",
    "    best_two_nest = best_nest\n",
    "    best_two_loss = best_loss\n",
    "    best_two_fitness = fitness[best_nest_index]\n",
    "    print('\\r\\n BEST_TWO_LOSSNESS IS %.2f : \\r\\n',best_two_loss)\n",
    "    print('\\r\\n BEST_TWO_FITNESS IS %.2f : \\r\\n',best_two_fitness)\n",
    "    for _ in range(iter_num):\n",
    "        nests = update_nests(lower_boundary, upper_boundary, nests, best_nest, fitness, step_size,best_fitness)\n",
    "        nests = abandon_nests(nests, lower_boundary, upper_boundary, pa)\n",
    "        print('\\r\\n*******************************************************一轮迭代后开始计算适应度*************************************************************\\r\\n')\n",
    "        fitness,lossness = calc_fitness( nests,best_fitness)\n",
    "        print('\\r\\n*****************************************************************结束************************************************************\\r\\n')\n",
    "        max_nest_index = np.argmax(fitness)\n",
    "        max_fitness = fitness[max_nest_index]\n",
    "        max_nest = nests[max_nest_index]\n",
    "        bestfit.append(max_fitness)\n",
    "        \n",
    "        min_loss_index = np.argmin(lossness)\n",
    "        min_loss = lossness[min_loss_index]\n",
    "        min_loss_fit = fitness[min_loss_index]\n",
    "        min_nestloss = nests[min_loss_index]\n",
    "        bestloss.append(min_loss)\n",
    "            \n",
    "        if min_loss < best_two_loss  : #and  min_loss_fit > best_two_fitness\n",
    "            best_two_nest = min_nestloss\n",
    "            best_two_loss = min_loss\n",
    "            best_two_fitness = min_loss_fit\n",
    "            print('\\r\\n******')\n",
    "            print('\\r\\n BEST_TWO_FITNESS IS %.2f : \\r\\n',best_two_fitness)\n",
    "            print('\\r\\n BEST_TWO_LOSSNESS IS %.2f : \\r\\n',best_two_loss)\n",
    "            print('\\r\\n******\\r\\n')\n",
    "            \n",
    "\n",
    "    return (best_two_nest, best_two_loss,best_two_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nests(n, m, lower_boundary, upper_boundary):\n",
    "    \"\"\"\n",
    "    Generate the nests' locations\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "    Output:\n",
    "        generated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    nests = np.empty((n, m))\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        nests[each_nest] = lower_boundary + np.array([np.random.rand() for _ in range(m)]) * (upper_boundary - lower_boundary)\n",
    "\n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nests(lower_boundary, upper_boundary, nests, best_nest, fitness, step_coefficient,bestfitness):\n",
    "    \"\"\"\n",
    "    This function is to get new nests' locations and use new better one to replace the old nest\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        nests: Old nests' locations \n",
    "        best_nest: Nest with best fitness\n",
    "        fitness: Every nest's fitness\n",
    "        step_coefficient:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    # 莱维飞行生成步长：较长时间的短步长和较短时间的长步长\n",
    "    #生成的步长的shape也是n*m，保证所有元素得到更新\n",
    "    #这个步长通过step_size来控制大小\n",
    "    steps = levy_flight(n, m, 1.5)\n",
    "    new_nests = nests.copy()\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        # coefficient 0.01 is to avoid levy flights becoming too aggresive\n",
    "        # and (nest[each_nest] - best_nest) 保留了最佳nest，但会导致局部最优\n",
    "        step_size = step_coefficient * steps[each_nest] * (nests[each_nest] - best_nest)\n",
    "        step_direction = np.random.rand(m) #0-1均匀概率分布生成方向\n",
    "        #新的布谷鸟在原来的基础上加上步长和方向\n",
    "        new_nests[each_nest] += step_size * step_direction  \n",
    "        # apply boundary condtions\n",
    "        new_nests[each_nest][new_nests[each_nest] < lower_boundary] = lower_boundary[new_nests[each_nest] < lower_boundary]\n",
    "        new_nests[each_nest][new_nests[each_nest] > upper_boundary] = upper_boundary[new_nests[each_nest] > upper_boundary]\n",
    "\n",
    "    new_fitness,new_losses = calc_fitness(new_nests,bestfitness)\n",
    "    #适应度更好的才更新过去\n",
    "    nests[new_fitness > fitness] = new_nests[new_fitness > fitness] \n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abandon_nests(nests, lower_boundary, upper_boundary, pa):\n",
    "    \"\"\"\n",
    "    Some cuckoos' eggs are found by hosts, and are abandoned.So cuckoos need to find new nests.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        nests: Current nests' locations\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        pa: Possibility that hosts find cuckoos' eggs\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    for each_nest in range(n):  \n",
    "        #pa概率抛弃，抛弃后重新生成\n",
    "        if (np.random.rand() < pa):\n",
    "            #局部随机行走生成步长\n",
    "            #随机两个种群相差*一个0-1的随机数\n",
    "            step_size = np.random.rand() * (nests[np.random.randint(0, n)] - nests[np.random.randint(0, n)])\n",
    "            nests[each_nest] += step_size\n",
    "            # apply boundary condtions\n",
    "            nests[each_nest][nests[each_nest] < lower_boundary] = lower_boundary[nests[each_nest] < lower_boundary]\n",
    "            nests[each_nest][nests[each_nest] > upper_boundary] = upper_boundary[nests[each_nest] > upper_boundary]\n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(n, m, beta):\n",
    "    \"\"\"\n",
    "    This function implements Levy's flight.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of steps \n",
    "        m: Number of dimensions\n",
    "        beta: Power law index (note: 1 < beta < 2)\n",
    "    Output:\n",
    "        'n' levy steps in 'm' dimension\n",
    "    \"\"\"\n",
    "    sigma_u = (sc_special.gamma(1+beta)*np.sin(np.pi*beta/2)/(sc_special.gamma((1+beta)/2)*beta*(2**((beta-1)/2))))**(1/beta)\n",
    "    sigma_v = 1\n",
    "\n",
    "    u =  np.random.normal(0, sigma_u, (n, m))\n",
    "    v = np.random.normal(0, sigma_v, (n, m))\n",
    "\n",
    "    steps = u/((np.abs(v))**(1/beta))\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(nests,bestfitness):\n",
    "    \n",
    "    n, m = nests.shape\n",
    "    fitness = np.empty(n)\n",
    "    lossness = np.empty(n)\n",
    "    for Sig_nest in range(n):\n",
    "        chrom = nests[Sig_nest]\n",
    "        #分解模型参数\n",
    "        w1 = chrom[:inputnum*hiddennum]\n",
    "        w1 = w1.reshape(inputnum,hiddennum)\n",
    "        b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "        w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "        w2 = w2.reshape(hiddennum,outputnum)\n",
    "        b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "        WB_l1 = (w1,b1)\n",
    "        WB_l2 = (w2,b2)\n",
    "        #创建模型，并赋予参数\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(hiddennum,activation='relu',name='l1'),\n",
    "            keras.layers.Dense(outputnum,name='l2')\n",
    "        ])\n",
    "        model.build(input_shape=[None,inputnum])\n",
    "        \n",
    "        #model.summary()\n",
    "        model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                    loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        layer1 = model.get_layer('l1')\n",
    "        layer2 = model.get_layer('l2')\n",
    "        layer1.set_weights(WB_l1)\n",
    "        layer2.set_weights(WB_l2)\n",
    "        \n",
    "        #训练模型\n",
    "        #model.fit(db,epochs=1,validation_data=ds_val,validation_freq=1)\n",
    "        model.fit(db,epochs=1)\n",
    "        loss,acc = model.evaluate(db)  #这里是用验证集评估，其实应该用测试集吧 evaluate产生两个结果，前面是损失，后面是准确率\n",
    "        lossness[Sig_nest] = loss\n",
    "        fitness[Sig_nest] = acc  #将模型评估正确率作为适应度返回\n",
    "        \n",
    "        if(acc>bestfitness): #在计算适应度的过程当中，发现有更好的适应度就把参数保存\n",
    "            #model.save_weights('my_model_fun.h5')\n",
    "            bestfitness = acc\n",
    "    return fitness,lossness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 2ms/step - loss: 8.0003 - accuracy: 0.4692\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.6385 - accuracy: 0.6604\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 9.6811 - accuracy: 0.5164\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.8547 - accuracy: 0.4619\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 12.4893 - accuracy: 0.5086\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.7153 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 77.2821 - accuracy: 0.4879\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 26.6555 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 13.5342 - accuracy: 0.5041\n",
      "51/51 [==============================] - 0s 939us/step - loss: 1.9419 - accuracy: 0.5056\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 1.9418995380401611\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.6604244709014893\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 7.8386 - accuracy: 0.4918\n",
      "51/51 [==============================] - 0s 979us/step - loss: 2.5270 - accuracy: 0.6192\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 9.3987 - accuracy: 0.4900\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.7019 - accuracy: 0.4644\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 13.2875 - accuracy: 0.4650\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 4.0639 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 63.6401 - accuracy: 0.4532\n",
      "51/51 [==============================] - 0s 880us/step - loss: 20.7452 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 27.0979 - accuracy: 0.4983\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.7426 - accuracy: 0.6092\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 7.7774 - accuracy: 0.4822\n",
      "51/51 [==============================] - 0s 959us/step - loss: 2.5610 - accuracy: 0.6130\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 10.2140 - accuracy: 0.5213\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.7336 - accuracy: 0.4707\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 12.8699 - accuracy: 0.4396\n",
      "51/51 [==============================] - 0s 999us/step - loss: 3.7608 - accuracy: 0.4694\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 129.7251 - accuracy: 0.5439\n",
      "51/51 [==============================] - 0s 999us/step - loss: 54.5465 - accuracy: 0.5381\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 3.8215 - accuracy: 0.5668\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.7381 - accuracy: 0.6454\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.6454432010650635\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.7381342649459839\n",
      "\n",
      "******\n",
      "\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 7.2206 - accuracy: 0.4896\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.5410 - accuracy: 0.6542\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 9.1863 - accuracy: 0.5139\n",
      "51/51 [==============================] - 0s 979us/step - loss: 2.8693 - accuracy: 0.4657\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 19.9955 - accuracy: 0.4463\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 5.8362 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 164.6728 - accuracy: 0.5215\n",
      "51/51 [==============================] - 0s 939us/step - loss: 68.6389 - accuracy: 0.5243\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 4.0567 - accuracy: 0.5581\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.6442\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 3.5273 - accuracy: 0.4839\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.7100 - accuracy: 0.3920\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 10.5022 - accuracy: 0.5307\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.0715 - accuracy: 0.4644\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 12.8296 - accuracy: 0.4603\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.7487 - accuracy: 0.4694\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 129.9617 - accuracy: 0.5346\n",
      "51/51 [==============================] - 0s 959us/step - loss: 54.8112 - accuracy: 0.5381\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 7.1220 - accuracy: 0.6082\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 2.2417 - accuracy: 0.6667\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.392009973526001\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.7100431323051453\n",
      "\n",
      "******\n",
      "\n",
      "CS最优loss为:%.5f! 0.7100431323051453\n",
      "CS最优fit为：%.5f! 0.392009973526001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "low = -3*np.ones(numsum)\n",
    "upp = 3*np.ones(numsum)\n",
    "best_nestloss, best_loss,fit = cuckoo_search(5,numsum, low,upp, step_size = 0.1)\n",
    "best_nest = best_nestloss\n",
    "best_fitness = best_loss\n",
    "print('CS最优loss为:%.5f!',best_loss),print('CS最优fit为：%.5f!',fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = best_nest\n",
    "w1 = chrom[:inputnum*hiddennum]\n",
    "w1 = w1.reshape(inputnum,hiddennum)\n",
    "b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "w2 = w2.reshape(hiddennum,outputnum)\n",
    "b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "WB_layer1 = (w1,b1)\n",
    "WB_layer2 = (w2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 0.3495 - accuracy: 0.6047\n",
      "Epoch 2/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7958\n",
      "Epoch 3/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.8231\n",
      "Epoch 4/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.8578\n",
      "Epoch 5/500\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.8639 - val_loss: 0.1201 - val_accuracy: 0.8980\n",
      "Epoch 6/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9015\n",
      "Epoch 7/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.8643\n",
      "Epoch 8/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9008\n",
      "Epoch 9/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.8709\n",
      "Epoch 10/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.8866 - val_loss: 0.0898 - val_accuracy: 0.9592\n",
      "Epoch 11/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8809\n",
      "Epoch 12/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8899\n",
      "Epoch 13/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9014\n",
      "Epoch 14/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9012\n",
      "Epoch 15/500\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.8971 - val_loss: 0.0805 - val_accuracy: 0.9184\n",
      "Epoch 16/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.8922\n",
      "Epoch 17/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9184\n",
      "Epoch 18/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8880\n",
      "Epoch 19/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9107\n",
      "Epoch 20/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9197 - val_loss: 0.0809 - val_accuracy: 0.9388\n",
      "Epoch 21/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9045\n",
      "Epoch 22/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9218\n",
      "Epoch 23/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9059\n",
      "Epoch 24/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9267\n",
      "Epoch 25/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.8807 - val_loss: 0.0790 - val_accuracy: 0.9184\n",
      "Epoch 26/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9015\n",
      "Epoch 27/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9302\n",
      "Epoch 28/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9277\n",
      "Epoch 29/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9236\n",
      "Epoch 30/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9205 - val_loss: 0.0866 - val_accuracy: 0.9388\n",
      "Epoch 31/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9338\n",
      "Epoch 32/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9199\n",
      "Epoch 33/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9224\n",
      "Epoch 34/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9322\n",
      "Epoch 35/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9164 - val_loss: 0.0793 - val_accuracy: 0.9388\n",
      "Epoch 36/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9273\n",
      "Epoch 37/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9083\n",
      "Epoch 38/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9268\n",
      "Epoch 39/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9229\n",
      "Epoch 40/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9400 - val_loss: 0.0810 - val_accuracy: 0.9388\n",
      "Epoch 41/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9306\n",
      "Epoch 42/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9062\n",
      "Epoch 43/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9207\n",
      "Epoch 44/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9474\n",
      "Epoch 45/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9242 - val_loss: 0.0856 - val_accuracy: 0.9592\n",
      "Epoch 46/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9281\n",
      "Epoch 47/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9230\n",
      "Epoch 48/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9168\n",
      "Epoch 49/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9288\n",
      "Epoch 50/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9248 - val_loss: 0.0733 - val_accuracy: 0.9184\n",
      "Epoch 51/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9251\n",
      "Epoch 52/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9149\n",
      "Epoch 53/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9313\n",
      "Epoch 54/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9350\n",
      "Epoch 55/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9163 - val_loss: 0.0962 - val_accuracy: 0.9796\n",
      "Epoch 56/500\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0769 - accuracy: 0.9293\n",
      "Epoch 57/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9160\n",
      "Epoch 58/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9327\n",
      "Epoch 59/500\n",
      "51/51 [==============================] - 0s 958us/step - loss: 0.0721 - accuracy: 0.9381\n",
      "Epoch 60/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9375 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9439\n",
      "Epoch 62/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9345\n",
      "Epoch 63/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9200\n",
      "Epoch 64/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9276\n",
      "Epoch 65/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9325 - val_loss: 0.0773 - val_accuracy: 0.9184\n",
      "Epoch 66/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9226\n",
      "Epoch 67/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9346\n",
      "Epoch 68/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0778 - accuracy: 0.9261\n",
      "Epoch 69/500\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0691 - accuracy: 0.9346\n",
      "Epoch 70/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9403 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
      "Epoch 71/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9327\n",
      "Epoch 72/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9232\n",
      "Epoch 73/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9266\n",
      "Epoch 74/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9198\n",
      "Epoch 75/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9373 - val_loss: 0.0703 - val_accuracy: 0.9184\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.8952\n",
      "Epoch 77/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9101\n",
      "Epoch 78/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9349\n",
      "Epoch 79/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9298\n",
      "Epoch 80/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9361 - val_loss: 0.0711 - val_accuracy: 0.9388\n",
      "Epoch 81/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9170\n",
      "Epoch 82/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9220\n",
      "Epoch 83/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9368\n",
      "Epoch 84/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0725 - accuracy: 0.9286\n",
      "Epoch 85/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9370 - val_loss: 0.0738 - val_accuracy: 0.9388\n",
      "Epoch 86/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9320\n",
      "Epoch 87/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9261\n",
      "Epoch 88/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9453\n",
      "Epoch 89/500\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0768 - accuracy: 0.9170\n",
      "Epoch 90/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9414 - val_loss: 0.0702 - val_accuracy: 0.9388\n",
      "Epoch 91/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9309\n",
      "Epoch 92/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9366\n",
      "Epoch 93/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9315\n",
      "Epoch 94/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9195\n",
      "Epoch 95/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9257 - val_loss: 0.0770 - val_accuracy: 0.9796\n",
      "Epoch 96/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9323\n",
      "Epoch 97/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9131\n",
      "Epoch 98/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9214\n",
      "Epoch 99/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9277\n",
      "Epoch 100/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9392 - val_loss: 0.0733 - val_accuracy: 0.9388\n",
      "Epoch 101/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9217\n",
      "Epoch 102/500\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0750 - accuracy: 0.9270\n",
      "Epoch 103/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9416\n",
      "Epoch 104/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0760 - accuracy: 0.9215\n",
      "Epoch 105/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9275 - val_loss: 0.0742 - val_accuracy: 0.9592\n",
      "Epoch 106/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9270\n",
      "Epoch 107/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0671 - accuracy: 0.9323\n",
      "Epoch 108/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9380\n",
      "Epoch 109/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9271\n",
      "Epoch 110/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9268 - val_loss: 0.0709 - val_accuracy: 0.9388\n",
      "Epoch 111/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9347\n",
      "Epoch 112/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9337\n",
      "Epoch 113/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9299\n",
      "Epoch 114/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9304\n",
      "Epoch 115/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9368 - val_loss: 0.0655 - val_accuracy: 0.9592\n",
      "Epoch 116/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9406\n",
      "Epoch 117/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9393\n",
      "Epoch 118/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9130\n",
      "Epoch 119/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9274\n",
      "Epoch 120/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9232 - val_loss: 0.0708 - val_accuracy: 0.9388\n",
      "Epoch 121/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9362\n",
      "Epoch 122/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0695 - accuracy: 0.9340\n",
      "Epoch 123/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9432\n",
      "Epoch 124/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9290\n",
      "Epoch 125/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9429 - val_loss: 0.0695 - val_accuracy: 0.9184\n",
      "Epoch 126/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9354\n",
      "Epoch 127/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9374\n",
      "Epoch 128/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9274\n",
      "Epoch 129/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9357\n",
      "Epoch 130/500\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9277 - val_loss: 0.0733 - val_accuracy: 0.9388\n",
      "Epoch 131/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9361\n",
      "Epoch 132/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9459\n",
      "Epoch 133/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9218\n",
      "Epoch 134/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9335\n",
      "Epoch 135/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9297 - val_loss: 0.0779 - val_accuracy: 0.9592\n",
      "Epoch 136/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9447\n",
      "Epoch 137/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9272\n",
      "Epoch 138/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9499\n",
      "Epoch 139/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9278\n",
      "Epoch 140/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9212 - val_loss: 0.0723 - val_accuracy: 0.9184\n",
      "Epoch 141/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9420\n",
      "Epoch 142/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9331\n",
      "Epoch 143/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9385\n",
      "Epoch 144/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9194\n",
      "Epoch 145/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9355 - val_loss: 0.0721 - val_accuracy: 0.9184\n",
      "Epoch 146/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9315\n",
      "Epoch 147/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9312\n",
      "Epoch 148/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9335\n",
      "Epoch 149/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9291\n",
      "Epoch 150/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9367 - val_loss: 0.0690 - val_accuracy: 0.9388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9320\n",
      "Epoch 152/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9324\n",
      "Epoch 153/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9350\n",
      "Epoch 154/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9284\n",
      "Epoch 155/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9341 - val_loss: 0.0706 - val_accuracy: 0.9184\n",
      "Epoch 156/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9350\n",
      "Epoch 157/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9334\n",
      "Epoch 158/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9370\n",
      "Epoch 159/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9171\n",
      "Epoch 160/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9405 - val_loss: 0.0702 - val_accuracy: 0.9388\n",
      "Epoch 161/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9387\n",
      "Epoch 162/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9170\n",
      "Epoch 163/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9244\n",
      "Epoch 164/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9398\n",
      "Epoch 165/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9417 - val_loss: 0.0717 - val_accuracy: 0.9388\n",
      "Epoch 166/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9199\n",
      "Epoch 167/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9369\n",
      "Epoch 168/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9444\n",
      "Epoch 169/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9462\n",
      "Epoch 170/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9459 - val_loss: 0.0701 - val_accuracy: 0.9184\n",
      "Epoch 171/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9270\n",
      "Epoch 172/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9526\n",
      "Epoch 173/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9398\n",
      "Epoch 174/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9296\n",
      "Epoch 175/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9480 - val_loss: 0.0724 - val_accuracy: 0.9184\n",
      "Epoch 176/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0762 - accuracy: 0.9267\n",
      "Epoch 177/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9351\n",
      "Epoch 178/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9363\n",
      "Epoch 179/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9338\n",
      "Epoch 180/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9302 - val_loss: 0.0778 - val_accuracy: 0.9796\n",
      "Epoch 181/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9494\n",
      "Epoch 182/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9188\n",
      "Epoch 183/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9191\n",
      "Epoch 184/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9308\n",
      "Epoch 185/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9145 - val_loss: 0.0692 - val_accuracy: 0.9388\n",
      "Epoch 186/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0708 - accuracy: 0.9253\n",
      "Epoch 187/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9424\n",
      "Epoch 188/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9046\n",
      "Epoch 189/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9371\n",
      "Epoch 190/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9303 - val_loss: 0.0758 - val_accuracy: 0.9184\n",
      "Epoch 191/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9106\n",
      "Epoch 192/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9324\n",
      "Epoch 193/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9283\n",
      "Epoch 194/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9293\n",
      "Epoch 195/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9414 - val_loss: 0.0749 - val_accuracy: 0.9184\n",
      "Epoch 196/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9144\n",
      "Epoch 197/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9339\n",
      "Epoch 198/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9251\n",
      "Epoch 199/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9333\n",
      "Epoch 200/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9110 - val_loss: 0.0722 - val_accuracy: 0.9184\n",
      "Epoch 201/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9330\n",
      "Epoch 202/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9287\n",
      "Epoch 203/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9418\n",
      "Epoch 204/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9456\n",
      "Epoch 205/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9192 - val_loss: 0.0769 - val_accuracy: 0.9184\n",
      "Epoch 206/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9237\n",
      "Epoch 207/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9357\n",
      "Epoch 208/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9329\n",
      "Epoch 209/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9268\n",
      "Epoch 210/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9385 - val_loss: 0.0739 - val_accuracy: 0.9184\n",
      "Epoch 211/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9353\n",
      "Epoch 212/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9500\n",
      "Epoch 213/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9352\n",
      "Epoch 214/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9243\n",
      "Epoch 215/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9318 - val_loss: 0.0766 - val_accuracy: 0.9388\n",
      "Epoch 216/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9275\n",
      "Epoch 217/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9176\n",
      "Epoch 218/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9403\n",
      "Epoch 219/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0782 - accuracy: 0.9368\n",
      "Epoch 220/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9247 - val_loss: 0.0775 - val_accuracy: 0.9592\n",
      "Epoch 221/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9200\n",
      "Epoch 222/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9228\n",
      "Epoch 223/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9263\n",
      "Epoch 224/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9273\n",
      "Epoch 225/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9172 - val_loss: 0.0885 - val_accuracy: 0.9388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9397\n",
      "Epoch 227/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9332\n",
      "Epoch 228/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0818 - accuracy: 0.9216\n",
      "Epoch 229/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0698 - accuracy: 0.9352\n",
      "Epoch 230/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9363 - val_loss: 0.0729 - val_accuracy: 0.9388\n",
      "Epoch 231/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9379\n",
      "Epoch 232/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9414\n",
      "Epoch 233/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9215\n",
      "Epoch 234/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9176\n",
      "Epoch 235/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9336 - val_loss: 0.0757 - val_accuracy: 0.9184\n",
      "Epoch 236/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9391\n",
      "Epoch 237/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9058\n",
      "Epoch 238/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9479\n",
      "Epoch 239/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9176\n",
      "Epoch 240/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9236 - val_loss: 0.0773 - val_accuracy: 0.9796\n",
      "Epoch 241/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9283\n",
      "Epoch 242/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0718 - accuracy: 0.9401\n",
      "Epoch 243/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9294\n",
      "Epoch 244/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9213\n",
      "Epoch 245/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9158 - val_loss: 0.0876 - val_accuracy: 0.8776\n",
      "Epoch 246/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.8856\n",
      "Epoch 247/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9385\n",
      "Epoch 248/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9374\n",
      "Epoch 249/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9361\n",
      "Epoch 250/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9236 - val_loss: 0.0750 - val_accuracy: 0.9388\n",
      "Epoch 251/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9418\n",
      "Epoch 252/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9426\n",
      "Epoch 253/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9303\n",
      "Epoch 254/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9317\n",
      "Epoch 255/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9343 - val_loss: 0.0707 - val_accuracy: 0.9184\n",
      "Epoch 256/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9227\n",
      "Epoch 257/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0684 - accuracy: 0.9312\n",
      "Epoch 258/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9415\n",
      "Epoch 259/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9267\n",
      "Epoch 260/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9156 - val_loss: 0.0726 - val_accuracy: 0.9184\n",
      "Epoch 261/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9304\n",
      "Epoch 262/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9435\n",
      "Epoch 263/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9294\n",
      "Epoch 264/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9489\n",
      "Epoch 265/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9049 - val_loss: 0.0786 - val_accuracy: 0.9388\n",
      "Epoch 266/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9382\n",
      "Epoch 267/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9312\n",
      "Epoch 268/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9414\n",
      "Epoch 269/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9323\n",
      "Epoch 270/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9432 - val_loss: 0.0715 - val_accuracy: 0.9388\n",
      "Epoch 271/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9425\n",
      "Epoch 272/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9417\n",
      "Epoch 273/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9365\n",
      "Epoch 274/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9401\n",
      "Epoch 275/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9274 - val_loss: 0.0738 - val_accuracy: 0.9388\n",
      "Epoch 276/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9251\n",
      "Epoch 277/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0732 - accuracy: 0.9253\n",
      "Epoch 278/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9295\n",
      "Epoch 279/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9431\n",
      "Epoch 280/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9287 - val_loss: 0.0714 - val_accuracy: 0.9184\n",
      "Epoch 281/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9417\n",
      "Epoch 282/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9271\n",
      "Epoch 283/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9339\n",
      "Epoch 284/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9223\n",
      "Epoch 285/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9124 - val_loss: 0.0761 - val_accuracy: 0.9388\n",
      "Epoch 286/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9377\n",
      "Epoch 287/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9405\n",
      "Epoch 288/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9357\n",
      "Epoch 289/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9384\n",
      "Epoch 290/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9316 - val_loss: 0.0761 - val_accuracy: 0.9388\n",
      "Epoch 291/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0640 - accuracy: 0.9572\n",
      "Epoch 292/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9382\n",
      "Epoch 293/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9275\n",
      "Epoch 294/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9449\n",
      "Epoch 295/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9181 - val_loss: 0.0754 - val_accuracy: 0.8980\n",
      "Epoch 296/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9356\n",
      "Epoch 297/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0811 - accuracy: 0.9368\n",
      "Epoch 298/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9254\n",
      "Epoch 299/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0643 - accuracy: 0.9415\n",
      "Epoch 300/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9444 - val_loss: 0.0728 - val_accuracy: 0.9184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9240\n",
      "Epoch 302/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9251\n",
      "Epoch 303/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0672 - accuracy: 0.9257\n",
      "Epoch 304/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9468\n",
      "Epoch 305/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9424 - val_loss: 0.0710 - val_accuracy: 0.9184\n",
      "Epoch 306/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9313\n",
      "Epoch 307/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9254\n",
      "Epoch 308/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9305\n",
      "Epoch 309/500\n",
      "51/51 [==============================] - 0s 920us/step - loss: 0.0628 - accuracy: 0.9489\n",
      "Epoch 310/500\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9349 - val_loss: 0.0751 - val_accuracy: 0.8980\n",
      "Epoch 311/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0714 - accuracy: 0.9360\n",
      "Epoch 312/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0747 - accuracy: 0.9280\n",
      "Epoch 313/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9254\n",
      "Epoch 314/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9332\n",
      "Epoch 315/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9297 - val_loss: 0.0779 - val_accuracy: 0.9796\n",
      "Epoch 316/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9297\n",
      "Epoch 317/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9400\n",
      "Epoch 318/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9471\n",
      "Epoch 319/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9442\n",
      "Epoch 320/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9381 - val_loss: 0.0860 - val_accuracy: 0.9796\n",
      "Epoch 321/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9399\n",
      "Epoch 322/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0788 - accuracy: 0.9117\n",
      "Epoch 323/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0624 - accuracy: 0.9312\n",
      "Epoch 324/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9202\n",
      "Epoch 325/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9163 - val_loss: 0.0699 - val_accuracy: 0.9388\n",
      "Epoch 326/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0708 - accuracy: 0.9279\n",
      "Epoch 327/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9327\n",
      "Epoch 328/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9313\n",
      "Epoch 329/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9376\n",
      "Epoch 330/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9344 - val_loss: 0.0836 - val_accuracy: 0.9388\n",
      "Epoch 331/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9384\n",
      "Epoch 332/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9465\n",
      "Epoch 333/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9256\n",
      "Epoch 334/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9382\n",
      "Epoch 335/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9414 - val_loss: 0.0757 - val_accuracy: 0.9592\n",
      "Epoch 336/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9358\n",
      "Epoch 337/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0766 - accuracy: 0.9249\n",
      "Epoch 338/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9205\n",
      "Epoch 339/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9349\n",
      "Epoch 340/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9344 - val_loss: 0.0778 - val_accuracy: 0.9592\n",
      "Epoch 341/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9531\n",
      "Epoch 342/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0678 - accuracy: 0.9299\n",
      "Epoch 343/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9432\n",
      "Epoch 344/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0674 - accuracy: 0.9419\n",
      "Epoch 345/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9348 - val_loss: 0.0761 - val_accuracy: 0.9388\n",
      "Epoch 346/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9406\n",
      "Epoch 347/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9442\n",
      "Epoch 348/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9274\n",
      "Epoch 349/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9115\n",
      "Epoch 350/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9356 - val_loss: 0.0753 - val_accuracy: 0.9184\n",
      "Epoch 351/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9277\n",
      "Epoch 352/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0707 - accuracy: 0.9247\n",
      "Epoch 353/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0758 - accuracy: 0.9379\n",
      "Epoch 354/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0699 - accuracy: 0.9265\n",
      "Epoch 355/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9378 - val_loss: 0.0719 - val_accuracy: 0.9184\n",
      "Epoch 356/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0772 - accuracy: 0.9131\n",
      "Epoch 357/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9341\n",
      "Epoch 358/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0742 - accuracy: 0.9338\n",
      "Epoch 359/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0710 - accuracy: 0.9332\n",
      "Epoch 360/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9323 - val_loss: 0.0734 - val_accuracy: 0.9388\n",
      "Epoch 361/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9226\n",
      "Epoch 362/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9272\n",
      "Epoch 363/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9354\n",
      "Epoch 364/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9020\n",
      "Epoch 365/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9366 - val_loss: 0.0703 - val_accuracy: 0.9184\n",
      "Epoch 366/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9410\n",
      "Epoch 367/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0667 - accuracy: 0.9272\n",
      "Epoch 368/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9401\n",
      "Epoch 369/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9274\n",
      "Epoch 370/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9426 - val_loss: 0.0859 - val_accuracy: 0.8776\n",
      "Epoch 371/500\n",
      "51/51 [==============================] - 0s 964us/step - loss: 0.0781 - accuracy: 0.9206\n",
      "Epoch 372/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9254\n",
      "Epoch 373/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9474\n",
      "Epoch 374/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9199\n",
      "Epoch 375/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9342 - val_loss: 0.0723 - val_accuracy: 0.9388\n",
      "Epoch 376/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9299\n",
      "Epoch 377/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9401\n",
      "Epoch 378/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0623 - accuracy: 0.9395\n",
      "Epoch 379/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9374\n",
      "Epoch 380/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9426 - val_loss: 0.0970 - val_accuracy: 0.9592\n",
      "Epoch 381/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9458\n",
      "Epoch 382/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9384\n",
      "Epoch 383/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9282\n",
      "Epoch 384/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9305\n",
      "Epoch 385/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9247 - val_loss: 0.0766 - val_accuracy: 0.9388\n",
      "Epoch 386/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9424\n",
      "Epoch 387/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9369\n",
      "Epoch 388/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9437\n",
      "Epoch 389/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9421\n",
      "Epoch 390/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9368 - val_loss: 0.0689 - val_accuracy: 0.9388\n",
      "Epoch 391/500\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.0662 - accuracy: 0.9327\n",
      "Epoch 392/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9197\n",
      "Epoch 393/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9327\n",
      "Epoch 394/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9292: 0s - loss: 0.0676 - accuracy: 0.92\n",
      "Epoch 395/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9393 - val_loss: 0.0794 - val_accuracy: 0.9184\n",
      "Epoch 396/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9365\n",
      "Epoch 397/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0714 - accuracy: 0.9256\n",
      "Epoch 398/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9279\n",
      "Epoch 399/500\n",
      "51/51 [==============================] - 0s 968us/step - loss: 0.0711 - accuracy: 0.9123\n",
      "Epoch 400/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9258 - val_loss: 0.0725 - val_accuracy: 0.9388\n",
      "Epoch 401/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9439\n",
      "Epoch 402/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9504\n",
      "Epoch 403/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9342\n",
      "Epoch 404/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9272\n",
      "Epoch 405/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9419 - val_loss: 0.0852 - val_accuracy: 0.9184\n",
      "Epoch 406/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9354\n",
      "Epoch 407/500\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.0674 - accuracy: 0.9372\n",
      "Epoch 408/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9204\n",
      "Epoch 409/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0711 - accuracy: 0.9284\n",
      "Epoch 410/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9386 - val_loss: 0.0741 - val_accuracy: 0.9592\n",
      "Epoch 411/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9419\n",
      "Epoch 412/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9540\n",
      "Epoch 413/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9362\n",
      "Epoch 414/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0702 - accuracy: 0.9198\n",
      "Epoch 415/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9509 - val_loss: 0.0772 - val_accuracy: 0.9388\n",
      "Epoch 416/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9381\n",
      "Epoch 417/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0781 - accuracy: 0.9313\n",
      "Epoch 418/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9275\n",
      "Epoch 419/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9476\n",
      "Epoch 420/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9376 - val_loss: 0.0726 - val_accuracy: 0.9388\n",
      "Epoch 421/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9413\n",
      "Epoch 422/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9446\n",
      "Epoch 423/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9378\n",
      "Epoch 424/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9178\n",
      "Epoch 425/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9454 - val_loss: 0.0811 - val_accuracy: 0.9184\n",
      "Epoch 426/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9442\n",
      "Epoch 427/500\n",
      "51/51 [==============================] - 0s 947us/step - loss: 0.0644 - accuracy: 0.9476\n",
      "Epoch 428/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9256\n",
      "Epoch 429/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9483\n",
      "Epoch 430/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9204 - val_loss: 0.0832 - val_accuracy: 0.9592\n",
      "Epoch 431/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9346\n",
      "Epoch 432/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9388\n",
      "Epoch 433/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0684 - accuracy: 0.9375\n",
      "Epoch 434/500\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.0689 - accuracy: 0.9316\n",
      "Epoch 435/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9303 - val_loss: 0.0697 - val_accuracy: 0.9388\n",
      "Epoch 436/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9388\n",
      "Epoch 437/500\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.0659 - accuracy: 0.9302\n",
      "Epoch 438/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9351\n",
      "Epoch 439/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9428\n",
      "Epoch 440/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9291 - val_loss: 0.0722 - val_accuracy: 0.9388\n",
      "Epoch 441/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9278\n",
      "Epoch 442/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9392\n",
      "Epoch 443/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9302\n",
      "Epoch 444/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9345\n",
      "Epoch 445/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9381 - val_loss: 0.0713 - val_accuracy: 0.9388\n",
      "Epoch 446/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9373\n",
      "Epoch 447/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0685 - accuracy: 0.9338\n",
      "Epoch 448/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9256\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9337\n",
      "Epoch 450/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9277 - val_loss: 0.0710 - val_accuracy: 0.9388\n",
      "Epoch 451/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9216\n",
      "Epoch 452/500\n",
      "51/51 [==============================] - 0s 978us/step - loss: 0.0790 - accuracy: 0.9299\n",
      "Epoch 453/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9355\n",
      "Epoch 454/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9345\n",
      "Epoch 455/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9447 - val_loss: 0.0725 - val_accuracy: 0.9184\n",
      "Epoch 456/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9421\n",
      "Epoch 457/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9525\n",
      "Epoch 458/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9313\n",
      "Epoch 459/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9381\n",
      "Epoch 460/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9333 - val_loss: 0.0787 - val_accuracy: 0.8776\n",
      "Epoch 461/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9271\n",
      "Epoch 462/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9390\n",
      "Epoch 463/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9471\n",
      "Epoch 464/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9466\n",
      "Epoch 465/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9260 - val_loss: 0.0723 - val_accuracy: 0.9184\n",
      "Epoch 466/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9191\n",
      "Epoch 467/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9381\n",
      "Epoch 468/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9320\n",
      "Epoch 469/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9427\n",
      "Epoch 470/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9478 - val_loss: 0.0715 - val_accuracy: 0.9388\n",
      "Epoch 471/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9189\n",
      "Epoch 472/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9330\n",
      "Epoch 473/500\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.0694 - accuracy: 0.9290\n",
      "Epoch 474/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0757 - accuracy: 0.9435\n",
      "Epoch 475/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9315 - val_loss: 0.0733 - val_accuracy: 0.9388\n",
      "Epoch 476/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9533\n",
      "Epoch 477/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9244\n",
      "Epoch 478/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9286\n",
      "Epoch 479/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9369\n",
      "Epoch 480/500\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9484 - val_loss: 0.0725 - val_accuracy: 0.9184\n",
      "Epoch 481/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0708 - accuracy: 0.9357\n",
      "Epoch 482/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9494\n",
      "Epoch 483/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0618 - accuracy: 0.9465\n",
      "Epoch 484/500\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.0690 - accuracy: 0.9330\n",
      "Epoch 485/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9233 - val_loss: 0.0698 - val_accuracy: 0.9388\n",
      "Epoch 486/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9266\n",
      "Epoch 487/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9269\n",
      "Epoch 488/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9385\n",
      "Epoch 489/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9396\n",
      "Epoch 490/500\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9349 - val_loss: 0.0733 - val_accuracy: 0.9184\n",
      "Epoch 491/500\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.0664 - accuracy: 0.9255\n",
      "Epoch 492/500\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.0680 - accuracy: 0.9343\n",
      "Epoch 493/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9311\n",
      "Epoch 494/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9311\n",
      "Epoch 495/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9445 - val_loss: 0.0701 - val_accuracy: 0.9388\n",
      "Epoch 496/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9333\n",
      "Epoch 497/500\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9390\n",
      "Epoch 498/500\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.0658 - accuracy: 0.9319\n",
      "Epoch 499/500\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9357\n",
      "Epoch 500/500\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9573 - val_loss: 0.0832 - val_accuracy: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1950b3cc308>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用CS优化初始化阈值\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(hiddennum,name='layer1',activation='relu'),\n",
    "    keras.layers.Dense(outputnum,name='layer2')\n",
    "])\n",
    "\n",
    "\n",
    "model.build(input_shape=[None,inputnum])\n",
    "#model.summary()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "            loss='mse',\n",
    "            metrics=['accuracy'])\n",
    "#model.load_weights('my_model_fun.h5')\n",
    "#训练模型\n",
    "model.fit(db,epochs=500,validation_data=ds_val,validation_freq=5)\n",
    "\n",
    "# layer1 = model.get_layer('layer1')\n",
    "# layer2 = model.get_layer('layer2')\n",
    "# layer1.set_weights(WB_layer1)\n",
    "# layer2.set_weights(WB_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.4875704 , -1.8567637 ,  2.1771398 , -2.061858  ,  0.00475263,\n",
       "          2.4660892 ,  1.4634211 ,  0.32650545],\n",
       "        [-0.4929458 , -1.4671715 , -1.858962  , -0.8773004 , -1.4339482 ,\n",
       "         -0.16887647, -1.0841436 , -2.121088  ],\n",
       "        [-0.79854053, -0.1634232 , -1.8358492 , -0.24242344,  1.109231  ,\n",
       "          0.10794401, -0.48483464, -0.72820514]], dtype=float32),\n",
       " array([ 1.2582238, -2.0323274, -2.2291923, -2.3687668,  1.2368942,\n",
       "        -0.5347749, -1.6295109, -0.558057 ], dtype=float32),\n",
       " array([[-1.2160908 ,  0.05823324],\n",
       "        [ 1.1308508 ,  1.8576275 ],\n",
       "        [-1.9796593 ,  0.6110159 ],\n",
       "        [ 0.5758099 ,  0.53625387],\n",
       "        [ 2.6233857 ,  1.773005  ],\n",
       "        [-0.35329446, -0.95336735],\n",
       "        [-2.527787  ,  1.6016471 ],\n",
       "        [-1.5767891 ,  0.25695062]], dtype=float32),\n",
       " array([ 1.9622333, -1.042854 ], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型参数\n",
    "la1 = model.get_layer('layer1')\n",
    "la2 = model.get_layer('layer2')\n",
    "(k1,b1) = la1.get_weights()\n",
    "(k2,b2) = la2.get_weights()\n",
    "k1,b1,k2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 3.4766 - accuracy: 0.4714\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.3922\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.4752\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.5848\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.6507 - val_loss: 0.2371 - val_accuracy: 0.6939\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.7711\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.7217\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.7408\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.7442\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.7679 - val_loss: 0.1854 - val_accuracy: 0.7551\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.7780\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7660\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.7768\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.8058 - val_loss: 0.1712 - val_accuracy: 0.7755\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.7553\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.8132\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.7964\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.8095\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.8394 - val_loss: 0.1608 - val_accuracy: 0.7551\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.8130\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.1533 - accuracy: 0.8129\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.8038\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.8070\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.7805 - val_loss: 0.1553 - val_accuracy: 0.8163\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.8163\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.8088\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.8082\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.7881 - val_loss: 0.1515 - val_accuracy: 0.7959\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.8063\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.8135\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.8169\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.8274\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.7963 - val_loss: 0.1500 - val_accuracy: 0.7755\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.8132\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.8022\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.8051\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.8064 - val_loss: 0.1418 - val_accuracy: 0.7959\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.8181\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.8131\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.8076\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.8413\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.8123 - val_loss: 0.1403 - val_accuracy: 0.8163\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.8193\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.8274\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.8256\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.7976\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.8169 - val_loss: 0.1352 - val_accuracy: 0.8163\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.8330\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.8273\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.8357\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.8253\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.8088 - val_loss: 0.1299 - val_accuracy: 0.8163\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.8382\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.8247\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.8436\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.8129\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.8261 - val_loss: 0.1266 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.8495\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1380 - accuracy: 0.8179\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1421 - accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.8228\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.8105 - val_loss: 0.1264 - val_accuracy: 0.8367\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.8285\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.1362 - accuracy: 0.8225\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.8345\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.8309\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.8299 - val_loss: 0.1235 - val_accuracy: 0.8367\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.8342\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.8008\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 980us/step - loss: 0.1409 - accuracy: 0.8142\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.8282\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.8333 - val_loss: 0.1235 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.8503\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.1238 - accuracy: 0.8409\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.1365 - accuracy: 0.8291\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.8537\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.8246 - val_loss: 0.1243 - val_accuracy: 0.8367\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1223 - accuracy: 0.8516\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 940us/step - loss: 0.1360 - accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.8261\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.8309 - val_loss: 0.1210 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.8400\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.1372 - accuracy: 0.8335\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.8271\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.8432\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.8324 - val_loss: 0.1252 - val_accuracy: 0.8571\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.8302\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.1319 - accuracy: 0.8388\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.8367\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.8528 - val_loss: 0.1359 - val_accuracy: 0.8367\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.8415\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.8377\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.8467\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.8573: 0s - loss: 0.1221 - accuracy: 0.85\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.8329 - val_loss: 0.1281 - val_accuracy: 0.8163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1950f08be88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "model.fit(db,epochs=100,validation_data=ds_val,validation_freq=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9184\n",
      "\n",
      "test loss 0.09522389620542526\n",
      "accuracy 0.918367326259613\n"
     ]
    }
   ],
   "source": [
    "# 评估模型,不输出预测结果\n",
    "loss,accuracy = model.evaluate(ds_val)\n",
    "print('\\ntest loss',loss)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1779846 ,  0.8479603 ],\n",
       "       [ 0.8649198 ,  0.15356797],\n",
       "       [ 0.32143128,  0.7386407 ],\n",
       "       [ 0.6956669 ,  0.2750966 ],\n",
       "       [ 0.35711765,  0.6819511 ],\n",
       "       [-0.02068806,  1.0091612 ],\n",
       "       [ 0.6122236 ,  0.3618161 ],\n",
       "       [ 0.2014364 ,  0.78227836],\n",
       "       [ 0.63400066,  0.38282996],\n",
       "       [ 0.33712375,  0.69185835],\n",
       "       [ 0.49212712,  0.5728453 ],\n",
       "       [ 0.71215606,  0.24951822],\n",
       "       [ 0.9980166 ,  0.04948068],\n",
       "       [ 1.3983151 , -0.33317196],\n",
       "       [ 1.0024089 , -0.02815598],\n",
       "       [ 1.04518   , -0.09454542],\n",
       "       [ 0.42661107,  0.62209266],\n",
       "       [ 0.72485745,  0.27702373],\n",
       "       [ 0.90431654,  0.15034223],\n",
       "       [ 0.40744328,  0.61687297],\n",
       "       [ 0.0781585 ,  0.9507883 ],\n",
       "       [ 0.9695314 , -0.00616938],\n",
       "       [ 0.4542104 ,  0.5615484 ],\n",
       "       [ 1.0835104 , -0.03831428],\n",
       "       [ 0.39017868,  0.6264654 ],\n",
       "       [ 0.3473953 ,  0.6419485 ],\n",
       "       [ 0.5482373 ,  0.4456609 ],\n",
       "       [ 0.38692677,  0.64399034],\n",
       "       [ 0.22121286,  0.7832472 ],\n",
       "       [-0.06115437,  1.0598319 ],\n",
       "       [ 0.23011804,  0.7924394 ],\n",
       "       [ 0.18970418,  0.8180768 ],\n",
       "       [ 0.82028526,  0.2301088 ],\n",
       "       [ 0.60017335,  0.3953212 ],\n",
       "       [ 0.17019749,  0.86106044],\n",
       "       [ 0.07862604,  0.93062776],\n",
       "       [ 0.38178635,  0.64715594],\n",
       "       [ 0.55454975,  0.4918658 ],\n",
       "       [ 0.24067175,  0.76246625],\n",
       "       [ 0.25174558,  0.79010874],\n",
       "       [ 1.0088416 , -0.07666498],\n",
       "       [ 0.4008211 ,  0.60362536],\n",
       "       [ 1.0606258 , -0.09686857],\n",
       "       [ 0.22065067,  0.8055623 ],\n",
       "       [ 0.48619533,  0.48875803],\n",
       "       [ 0.24228728,  0.7659009 ],\n",
       "       [ 0.3485415 ,  0.65096563],\n",
       "       [ 0.86673   ,  0.1379087 ],\n",
       "       [ 0.12940717,  0.87034136]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(TestX)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型预测,输入测试集,输出预测结果\n",
    "y_pred = model.predict(TestX)\n",
    "y_pred = tf.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1], dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = tf.argmax(TestY_onehot,axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X)\n",
    "y_pred_train = tf.argmax(y_pred_train,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tf.argmax(Y_onehot,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestfit)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fitness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestFit', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = y_pred - test_y\n",
    "x = list(range(0,len(error)))\n",
    "fig = sns.lineplot(x,error,color=\"b\")\n",
    "plt.xlabel(\"Test Data Num\")\n",
    "plt.ylabel(\"error\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./Error_Num', dpi = 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestloss,color=\"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"lossness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestLoss', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns主题风格  darkgrid  whitegrid  dark  white  ticks\n",
    "sns.set_style(\"ticks\")  #设置主题风格\n",
    "sns.color_palette(\"hls\",8)  #设置颜色空间种类（几种可用颜色）\n",
    "data=np.random.normal(size=(20,8)) + np.arange(8) /2\n",
    "sns.boxplot(data = data,palette = sns.color_palette(\"hls\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描述两个变量的关系 最好用散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mean,cov = [0,1],[(1,.5),(.5,1)]\n",
    "data = np.random.multivariate_normal(mean,cov,200)\n",
    "df = pd.DataFrame(data,columns=[\"x\",\"y\"])\n",
    "#绘制散点图\n",
    "sns.jointplot(x=\"x\",y=\"y\",data = df,color=\"r\")  #如果点很多，用颜色深度表示数量 kind=\"hex\" ,可以单独传x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移植STM32准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testx = X / X.max().max()\n",
    "Testx = np.array(Testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Testx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-158e708c3fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTestx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Testx' is not defined"
     ]
    }
   ],
   "source": [
    "aa = []\n",
    "aa.append(list(Testx[0]))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3447314, 0.6587833]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_sig=model.predict(aa)\n",
    "pre_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmax(pre_sig,axis=None)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "796    0\n",
       "797    1\n",
       "798    0\n",
       "799    0\n",
       "800    1\n",
       "Name: 0, Length: 801, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Env.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a2c956a6c57c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Env.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(load_model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"Env.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #建立一个测试模型\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(5,), name='dense_xiaoming',\n",
    "          kernel_initializer='zeros',  # 全部初始化为0\n",
    "          bias_initializer='ones'),  # 全部初始化为1\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(shape=(8, 5))  # 创建测试数据\n",
    "y = model(x)\n",
    "layer = model.get_layer('dense_xiaoming')  # 通过层的名字得到层\n",
    "(k, b) = layer.get_weights()  # 查看层的初始化权重值和偏置项\n",
    "print(k)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
