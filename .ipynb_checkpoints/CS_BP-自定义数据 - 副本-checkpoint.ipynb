{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS_BP预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sc_special\n",
    "import tensorflow as tf \n",
    "from \ttensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers,metrics,layers,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据以及预处理\n",
    "data = pd.read_csv('TJ_AIR.csv',sep=',',header=0,usecols=[1,2,3,4,5,6,7])\n",
    "X = data.iloc[:231,1:]\n",
    "Y = data.iloc[:231,0]\n",
    "TestX = data.iloc[231:,1:]\n",
    "TestY = data.iloc[231:,0]\n",
    "\n",
    "inputnum = 6\n",
    "hiddennum = 11\n",
    "outputnum = 3\n",
    "numsum = inputnum*hiddennum+hiddennum+hiddennum*outputnum+outputnum #6*10+10+10*3+3=103\n",
    "bestfit = []\n",
    "bestloss = []\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=3)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>32.26</td>\n",
       "      <td>1847.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.53</td>\n",
       "      <td>69.30</td>\n",
       "      <td>3149.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.89</td>\n",
       "      <td>69.18</td>\n",
       "      <td>2753.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29.94</td>\n",
       "      <td>24.49</td>\n",
       "      <td>4473.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.88</td>\n",
       "      <td>56.98</td>\n",
       "      <td>5585.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>29.31</td>\n",
       "      <td>55.91</td>\n",
       "      <td>17729.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>37.21</td>\n",
       "      <td>81.02</td>\n",
       "      <td>10906.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>25.06</td>\n",
       "      <td>61.81</td>\n",
       "      <td>5774.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>12.62</td>\n",
       "      <td>8.15</td>\n",
       "      <td>1359.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>22.15</td>\n",
       "      <td>90.89</td>\n",
       "      <td>5878.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1         2\n",
       "0     1.10  32.26   1847.73\n",
       "1    17.53  69.30   3149.88\n",
       "2    23.89  69.18   2753.65\n",
       "3    29.94  24.49   4473.23\n",
       "4    27.88  56.98   5585.51\n",
       "..     ...    ...       ...\n",
       "796  29.31  55.91  17729.93\n",
       "797  37.21  81.02  10906.59\n",
       "798  25.06  61.81   5774.97\n",
       "799  12.62   8.15   1359.01\n",
       "800  22.15  90.89   5878.39\n",
       "\n",
       "[801 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "#零均值处理\n",
    "X.iloc[:,0] -= np.mean(X,axis=0)[0]  \n",
    "X.iloc[:,1] -= np.mean(X,axis=0)[1]\n",
    "X.iloc[:,2] -= np.mean(X,axis=0)[2]\n",
    "X.iloc[:,3] -= np.mean(X,axis=0)[3]  \n",
    "X.iloc[:,4] -= np.mean(X,axis=0)[4]\n",
    "X.iloc[:,5] -= np.mean(X,axis=0)[5]\n",
    "#归一化\n",
    "X.iloc[:,0] /= np.max(np.abs(X),axis=0)[0]\n",
    "X.iloc[:,1] /= np.max(np.abs(X),axis=0)[1]\n",
    "X.iloc[:,2] /= np.max(np.abs(X),axis=0)[2]\n",
    "X.iloc[:,3] /= np.max(np.abs(X),axis=0)[3]  \n",
    "X.iloc[:,4] /= np.max(np.abs(X),axis=0)[4]\n",
    "X.iloc[:,5] /= np.max(np.abs(X),axis=0)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>co</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>91</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.4</td>\n",
       "      <td>101</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.6</td>\n",
       "      <td>112</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0.7</td>\n",
       "      <td>196</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      so2   no2   co   o3   pm10   pm2_5\n",
       "231     5    26  0.4   91     50      13\n",
       "232     5    24  0.4  101     18       6\n",
       "233     9    32  0.6  112     49      22\n",
       "234     6    17  0.7  196     46      27\n",
       "235     8    21  0.8  131     39      21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231     5\n",
       "232     5\n",
       "233     9\n",
       "234     6\n",
       "235     8\n",
       "236     7\n",
       "237     8\n",
       "238     6\n",
       "239     7\n",
       "240     5\n",
       "241    10\n",
       "242    16\n",
       "243     5\n",
       "244    10\n",
       "245     5\n",
       "246     6\n",
       "247    10\n",
       "248     9\n",
       "249     4\n",
       "250     6\n",
       "Name:  so2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestX.iloc[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mF:\\ANA_Router\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6341e97133a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTestX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\ANA_Router\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ANA_Router\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "TestX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#零均值处理\n",
    "TestX[0] -= np.mean(TestX,axis=0)[0]  \n",
    "TestX[1] -= np.mean(TestX,axis=0)[1]\n",
    "TestX[2] -= np.mean(TestX,axis=0)[2]\n",
    "#归一化\n",
    "TestX[0] /= np.max(np.abs(TestX),axis=0)[0]\n",
    "TestX[1] /= np.max(np.abs(TestX),axis=0)[1]\n",
    "TestX[2] /= np.max(np.abs(TestX),axis=0)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3) (16, 2)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 16\n",
    "db = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((TestX,TestY))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape,sample[1].shape)\n",
    "copyX = X\n",
    "Y_onehot = tf.one_hot(Y,depth=2)\n",
    "TestY_onehot = tf.one_hot(TestY,depth=2)\n",
    "X = tf.cast(X,dtype=tf.float32) \n",
    "TestX = tf.cast(TestX,dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#n：布谷鸟数  m：布谷鸟的维度\n",
    "def cuckoo_search(n, m, lower_boundary, upper_boundary, iter_num = 10,pa = 0.25, beta = 1.5, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Cuckoo search function\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        iter_num: Number of iterations (default: 100) \n",
    "        pa: Possibility that hosts find cuckoos' eggs (default: 0.25)\n",
    "        beta: Power law index (note: 1 < beta < 2) (default: 1.5)\n",
    "        step_size:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        The best solution and its value\n",
    "    \"\"\"\n",
    "    # get initial nests' locations \n",
    "    nests = generate_nests(n, m, lower_boundary, upper_boundary)\n",
    "    fitness,lossness = calc_fitness( nests,0.5) #包含所有的适应度  用列表存储\n",
    "    \n",
    "    #得到每代最小loss\n",
    "    best_loss_index = np.argmin(lossness)\n",
    "    best_loss = lossness[best_loss_index]\n",
    "    best_nestloss = nests[best_loss_index].copy()\n",
    "    bestloss.append(best_loss)\n",
    "    \n",
    "    # get the best nest and record it\n",
    "    best_nest_index = np.argmax(fitness)\n",
    "    best_fitness = fitness[best_nest_index]\n",
    "    best_nest = nests[best_nest_index].copy()\n",
    "    bestfit.append(best_fitness) #全局变量，保存每代最佳适应度值\n",
    "    \n",
    "    best_two_nest = best_nest\n",
    "    best_two_loss = best_fitness\n",
    "    best_two_fitness = lossness[best_nest_index]\n",
    "    print('\\r\\n BEST_TWO_LOSSNESS IS %.2f : \\r\\n',best_two_loss)\n",
    "    print('\\r\\n BEST_TWO_FITNESS IS %.2f : \\r\\n',best_two_fitness)\n",
    "    for _ in range(iter_num):\n",
    "        nests = update_nests(lower_boundary, upper_boundary, nests, best_nest, fitness, step_size,best_fitness)\n",
    "        nests = abandon_nests(nests, lower_boundary, upper_boundary, pa)\n",
    "        print('\\r\\n*******************************************************一轮迭代后开始计算适应度*************************************************************\\r\\n')\n",
    "        fitness,lossness = calc_fitness( nests,best_fitness)\n",
    "        print('\\r\\n*****************************************************************结束************************************************************\\r\\n')\n",
    "        max_nest_index = np.argmax(fitness)\n",
    "        max_fitness = fitness[max_nest_index]\n",
    "        max_nest = nests[max_nest_index]\n",
    "        bestfit.append(max_fitness)\n",
    "        \n",
    "        min_loss_index = np.argmin(lossness)\n",
    "        min_loss = lossness[min_loss_index]\n",
    "        min_loss_fit = fitness[min_loss_index]\n",
    "        min_nestloss = nests[min_loss_index]\n",
    "        bestloss.append(min_loss)\n",
    "            \n",
    "        if min_loss < best_two_loss  : #and  min_loss_fit > best_two_fitness\n",
    "            best_two_nest = min_nestloss\n",
    "            best_two_loss = min_loss\n",
    "            best_two_fitness = min_loss_fit\n",
    "            print('\\r\\n******')\n",
    "            print('\\r\\n BEST_TWO_FITNESS IS %.2f : \\r\\n',best_two_fitness)\n",
    "            print('\\r\\n BEST_TWO_LOSSNESS IS %.2f : \\r\\n',best_two_loss)\n",
    "            print('\\r\\n******\\r\\n')\n",
    "            \n",
    "\n",
    "    return (best_two_nest, best_two_loss,best_two_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nests(n, m, lower_boundary, upper_boundary):\n",
    "    \"\"\"\n",
    "    Generate the nests' locations\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "    Output:\n",
    "        generated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    nests = np.empty((n, m))\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        nests[each_nest] = lower_boundary + np.array([np.random.rand() for _ in range(m)]) * (upper_boundary - lower_boundary)\n",
    "\n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nests(lower_boundary, upper_boundary, nests, best_nest, fitness, step_coefficient,bestfitness):\n",
    "    \"\"\"\n",
    "    This function is to get new nests' locations and use new better one to replace the old nest\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        nests: Old nests' locations \n",
    "        best_nest: Nest with best fitness\n",
    "        fitness: Every nest's fitness\n",
    "        step_coefficient:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    # 莱维飞行生成步长：较长时间的短步长和较短时间的长步长\n",
    "    #生成的步长的shape也是n*m，保证所有元素得到更新\n",
    "    #这个步长通过step_size来控制大小\n",
    "    steps = levy_flight(n, m, 1.5)\n",
    "    new_nests = nests.copy()\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        # coefficient 0.01 is to avoid levy flights becoming too aggresive\n",
    "        # and (nest[each_nest] - best_nest) 保留了最佳nest，但会导致局部最优\n",
    "        step_size = step_coefficient * steps[each_nest] * (nests[each_nest] - best_nest)\n",
    "        step_direction = np.random.rand(m) #0-1均匀概率分布生成方向\n",
    "        #新的布谷鸟在原来的基础上加上步长和方向\n",
    "        new_nests[each_nest] += step_size * step_direction  \n",
    "        # apply boundary condtions\n",
    "        new_nests[each_nest][new_nests[each_nest] < lower_boundary] = lower_boundary[new_nests[each_nest] < lower_boundary]\n",
    "        new_nests[each_nest][new_nests[each_nest] > upper_boundary] = upper_boundary[new_nests[each_nest] > upper_boundary]\n",
    "\n",
    "    new_fitness,new_losses = calc_fitness(new_nests,bestfitness)\n",
    "    #适应度更好的才更新过去\n",
    "    nests[new_fitness > fitness] = new_nests[new_fitness > fitness] \n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abandon_nests(nests, lower_boundary, upper_boundary, pa):\n",
    "    \"\"\"\n",
    "    Some cuckoos' eggs are found by hosts, and are abandoned.So cuckoos need to find new nests.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        nests: Current nests' locations\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        pa: Possibility that hosts find cuckoos' eggs\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    for each_nest in range(n):  \n",
    "        #pa概率抛弃，抛弃后重新生成\n",
    "        if (np.random.rand() < pa):\n",
    "            #局部随机行走生成步长\n",
    "            #随机两个种群相差*一个0-1的随机数\n",
    "            step_size = np.random.rand() * (nests[np.random.randint(0, n)] - nests[np.random.randint(0, n)])\n",
    "            nests[each_nest] += step_size\n",
    "            # apply boundary condtions\n",
    "            nests[each_nest][nests[each_nest] < lower_boundary] = lower_boundary[nests[each_nest] < lower_boundary]\n",
    "            nests[each_nest][nests[each_nest] > upper_boundary] = upper_boundary[nests[each_nest] > upper_boundary]\n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(n, m, beta):\n",
    "    \"\"\"\n",
    "    This function implements Levy's flight.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of steps \n",
    "        m: Number of dimensions\n",
    "        beta: Power law index (note: 1 < beta < 2)\n",
    "    Output:\n",
    "        'n' levy steps in 'm' dimension\n",
    "    \"\"\"\n",
    "    sigma_u = (sc_special.gamma(1+beta)*np.sin(np.pi*beta/2)/(sc_special.gamma((1+beta)/2)*beta*(2**((beta-1)/2))))**(1/beta)\n",
    "    sigma_v = 1\n",
    "\n",
    "    u =  np.random.normal(0, sigma_u, (n, m))\n",
    "    v = np.random.normal(0, sigma_v, (n, m))\n",
    "\n",
    "    steps = u/((np.abs(v))**(1/beta))\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(nests,bestfitness):\n",
    "    \n",
    "    n, m = nests.shape\n",
    "    fitness = np.empty(n)\n",
    "    lossness = np.empty(n)\n",
    "    for Sig_nest in range(n):\n",
    "        chrom = nests[Sig_nest]\n",
    "        #分解模型参数\n",
    "        w1 = chrom[:inputnum*hiddennum]\n",
    "        w1 = w1.reshape(inputnum,hiddennum)\n",
    "        b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "        w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "        w2 = w2.reshape(hiddennum,outputnum)\n",
    "        b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "        WB_l1 = (w1,b1)\n",
    "        WB_l2 = (w2,b2)\n",
    "        #创建模型，并赋予参数\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(hiddennum,activation='relu',name='l1'),\n",
    "            keras.layers.Dense(outputnum,name='l2')\n",
    "        ])\n",
    "        model.build(input_shape=[None,3])\n",
    "        \n",
    "        #model.summary()\n",
    "        model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                    loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        layer1 = model.get_layer('l1')\n",
    "        layer2 = model.get_layer('l2')\n",
    "        layer1.set_weights(WB_l1)\n",
    "        layer2.set_weights(WB_l2)\n",
    "        \n",
    "        #训练模型\n",
    "        #model.fit(db,epochs=1,validation_data=ds_val,validation_freq=1)\n",
    "        model.fit(db,epochs=1)\n",
    "        loss,acc = model.evaluate(db)  #这里是用验证集评估，其实应该用测试集吧 evaluate产生两个结果，前面是损失，后面是准确率\n",
    "        lossness[Sig_nest] = loss\n",
    "        fitness[Sig_nest] = acc  #将模型评估正确率作为适应度返回\n",
    "        \n",
    "        if(acc>bestfitness): #在计算适应度的过程当中，发现有更好的适应度就把参数保存\n",
    "            #model.save_weights('my_model_fun.h5')\n",
    "            bestfitness = acc\n",
    "    return fitness,lossness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 959us/step - loss: 15.4654 - accuracy: 0.6553\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.6475 - accuracy: 0.6767\n",
      "51/51 [==============================] - 0s 860us/step - loss: 4.2151 - accuracy: 0.6840\n",
      "51/51 [==============================] - 0s 780us/step - loss: 1.1521 - accuracy: 0.7591\n",
      "51/51 [==============================] - 0s 979us/step - loss: 33.3421 - accuracy: 0.4850\n",
      "51/51 [==============================] - 0s 800us/step - loss: 6.4732 - accuracy: 0.5031\n",
      "51/51 [==============================] - 0s 959us/step - loss: 15.7233 - accuracy: 0.4354\n",
      "51/51 [==============================] - 0s 780us/step - loss: 4.9053 - accuracy: 0.3908\n",
      "51/51 [==============================] - 0s 939us/step - loss: 9.1862 - accuracy: 0.4655\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.4205 - accuracy: 0.5343\n",
      "51/51 [==============================] - 0s 919us/step - loss: 37.4255 - accuracy: 0.5305\n",
      "51/51 [==============================] - 0s 760us/step - loss: 9.4619 - accuracy: 0.5993\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 4.7709 - accuracy: 0.3947\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 2.2352 - accuracy: 0.3021\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 5.1326 - accuracy: 0.4391\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.4547 - accuracy: 0.4145\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 42.5942 - accuracy: 0.4808\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 13.4665 - accuracy: 0.5830\n",
      "51/51 [==============================] - 0s 946us/step - loss: 21.4498 - accuracy: 0.5207\n",
      "51/51 [==============================] - 0s 740us/step - loss: 8.9468 - accuracy: 0.5655\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.7590512037277222\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 1.152073860168457\n",
      "51/51 [==============================] - 0s 940us/step - loss: 16.1585 - accuracy: 0.5213\n",
      "51/51 [==============================] - 0s 860us/step - loss: 3.8640 - accuracy: 0.6205\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 4.1810 - accuracy: 0.6798\n",
      "51/51 [==============================] - 0s 959us/step - loss: 1.1893 - accuracy: 0.7066\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 23.4653 - accuracy: 0.5299\n",
      "51/51 [==============================] - 0s 840us/step - loss: 4.4372 - accuracy: 0.4732\n",
      "51/51 [==============================] - 0s 999us/step - loss: 13.3974 - accuracy: 0.5447\n",
      "51/51 [==============================] - 0s 780us/step - loss: 3.8158 - accuracy: 0.4744\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 7.1793 - accuracy: 0.5129\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.0429 - accuracy: 0.5019\n",
      "51/51 [==============================] - 1s 3ms/step - loss: 38.4040 - accuracy: 0.5598\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 10.2081 - accuracy: 0.5830\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 5.8259 - accuracy: 0.4328\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 2.2638 - accuracy: 0.3633\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 4.5617 - accuracy: 0.3561\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.6102 - accuracy: 0.4257\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 58.5334 - accuracy: 0.4564\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 20.8451 - accuracy: 0.5194\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 21.0065 - accuracy: 0.5222\n",
      "51/51 [==============================] - 0s 780us/step - loss: 8.9657 - accuracy: 0.5680\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 14.9305 - accuracy: 0.6643\n",
      "51/51 [==============================] - 0s 959us/step - loss: 3.7201 - accuracy: 0.6742\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 4.2543 - accuracy: 0.6486\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.1572 - accuracy: 0.7441\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 31.9664 - accuracy: 0.4628\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 6.2607 - accuracy: 0.5044\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 18.0493 - accuracy: 0.4937\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 6.8906 - accuracy: 0.4157\n",
      "51/51 [==============================] - 0s 880us/step - loss: 9.0148 - accuracy: 0.5007\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.3769 - accuracy: 0.5156\n",
      "51/51 [==============================] - 1s 899us/step - loss: 40.5872 - accuracy: 0.5355\n",
      "51/51 [==============================] - 0s 860us/step - loss: 9.7504 - accuracy: 0.6030\n",
      "51/51 [==============================] - 0s 899us/step - loss: 5.3271 - accuracy: 0.4345\n",
      "51/51 [==============================] - 0s 799us/step - loss: 2.2940 - accuracy: 0.3758\n",
      "51/51 [==============================] - 0s 900us/step - loss: 4.3130 - accuracy: 0.3449\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.4623 - accuracy: 0.4282\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 42.7438 - accuracy: 0.4807\n",
      "51/51 [==============================] - 0s 840us/step - loss: 13.5903 - accuracy: 0.5818\n",
      "51/51 [==============================] - 0s 979us/step - loss: 21.2108 - accuracy: 0.5579\n",
      "51/51 [==============================] - 0s 840us/step - loss: 8.9928 - accuracy: 0.5655\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 937us/step - loss: 17.3732 - accuracy: 0.5952\n",
      "51/51 [==============================] - 0s 839us/step - loss: 4.4899 - accuracy: 0.6255\n",
      "51/51 [==============================] - 0s 939us/step - loss: 4.2678 - accuracy: 0.6453\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.1984 - accuracy: 0.7091\n",
      "51/51 [==============================] - 0s 939us/step - loss: 40.2106 - accuracy: 0.4685\n",
      "51/51 [==============================] - 0s 720us/step - loss: 8.3190 - accuracy: 0.5256\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 17.5594 - accuracy: 0.4927\n",
      "51/51 [==============================] - 0s 919us/step - loss: 7.3640 - accuracy: 0.4032\n",
      "51/51 [==============================] - 0s 939us/step - loss: 5.8744 - accuracy: 0.4758\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.8557 - accuracy: 0.5331\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 39.2993 - accuracy: 0.5656\n",
      "51/51 [==============================] - 0s 848us/step - loss: 9.8636 - accuracy: 0.6042\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 4.1430 - accuracy: 0.4740\n",
      "51/51 [==============================] - 0s 958us/step - loss: 2.0245 - accuracy: 0.3683\n",
      "51/51 [==============================] - 0s 839us/step - loss: 3.9916 - accuracy: 0.3041\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.5312 - accuracy: 0.4170\n",
      "51/51 [==============================] - 0s 860us/step - loss: 60.3925 - accuracy: 0.4581\n",
      "51/51 [==============================] - 0s 869us/step - loss: 21.1447 - accuracy: 0.5705\n",
      "51/51 [==============================] - 0s 959us/step - loss: 23.1564 - accuracy: 0.5130\n",
      "51/51 [==============================] - 0s 843us/step - loss: 9.8099 - accuracy: 0.5643\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 979us/step - loss: 17.5830 - accuracy: 0.6663\n",
      "51/51 [==============================] - 0s 899us/step - loss: 3.9047 - accuracy: 0.6804\n",
      "51/51 [==============================] - 0s 979us/step - loss: 5.0253 - accuracy: 0.7024\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.7167 - accuracy: 0.7029\n",
      "51/51 [==============================] - 0s 899us/step - loss: 35.7865 - accuracy: 0.4939\n",
      "51/51 [==============================] - 0s 780us/step - loss: 7.2948 - accuracy: 0.5306\n",
      "51/51 [==============================] - 0s 860us/step - loss: 36.5245 - accuracy: 0.4505\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 16.0548 - accuracy: 0.4669\n",
      "51/51 [==============================] - 0s 780us/step - loss: 11.7855 - accuracy: 0.4519\n",
      "51/51 [==============================] - 0s 680us/step - loss: 2.0460 - accuracy: 0.4345\n",
      "51/51 [==============================] - 0s 820us/step - loss: 40.3971 - accuracy: 0.5632\n",
      "51/51 [==============================] - 0s 820us/step - loss: 10.0752 - accuracy: 0.5930\n",
      "51/51 [==============================] - 0s 860us/step - loss: 5.6986 - accuracy: 0.4678\n",
      "51/51 [==============================] - 0s 700us/step - loss: 2.3729 - accuracy: 0.3558\n",
      "51/51 [==============================] - 0s 920us/step - loss: 4.2579 - accuracy: 0.3737\n",
      "51/51 [==============================] - 0s 680us/step - loss: 1.5713 - accuracy: 0.4320\n",
      "51/51 [==============================] - 0s 820us/step - loss: 6.3964 - accuracy: 0.5462\n",
      "51/51 [==============================] - 0s 740us/step - loss: 0.8537 - accuracy: 0.4856\n",
      "51/51 [==============================] - 0s 887us/step - loss: 21.5150 - accuracy: 0.5454\n",
      "51/51 [==============================] - 0s 700us/step - loss: 9.0370 - accuracy: 0.5730\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 820us/step - loss: 11.3420 - accuracy: 0.6150\n",
      "51/51 [==============================] - 0s 800us/step - loss: 2.0797 - accuracy: 0.5905\n",
      "51/51 [==============================] - 0s 760us/step - loss: 4.5092 - accuracy: 0.7470\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.5367 - accuracy: 0.7453\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 38.5868 - accuracy: 0.4640\n",
      "51/51 [==============================] - 0s 800us/step - loss: 7.8257 - accuracy: 0.5431\n",
      "51/51 [==============================] - 0s 840us/step - loss: 34.3078 - accuracy: 0.4346\n",
      "51/51 [==============================] - 0s 700us/step - loss: 15.0246 - accuracy: 0.4919\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 8.8264 - accuracy: 0.4138\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.8881 - accuracy: 0.4769\n",
      "51/51 [==============================] - 0s 840us/step - loss: 40.7472 - accuracy: 0.5535\n",
      "51/51 [==============================] - 0s 940us/step - loss: 10.6469 - accuracy: 0.5943\n",
      "51/51 [==============================] - 0s 840us/step - loss: 7.3754 - accuracy: 0.4888\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.9223 - accuracy: 0.4831\n",
      "51/51 [==============================] - 0s 790us/step - loss: 4.5123 - accuracy: 0.3957\n",
      "51/51 [==============================] - 0s 840us/step - loss: 1.6258 - accuracy: 0.4132\n",
      "51/51 [==============================] - 0s 820us/step - loss: 5.4914 - accuracy: 0.5538\n",
      "51/51 [==============================] - 0s 740us/step - loss: 0.6971 - accuracy: 0.5381\n",
      "51/51 [==============================] - 1s 999us/step - loss: 23.1364 - accuracy: 0.5501\n",
      "51/51 [==============================] - 0s 680us/step - loss: 9.4213 - accuracy: 0.5968\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 880us/step - loss: 16.6011 - accuracy: 0.6491\n",
      "51/51 [==============================] - ETA: 5s - loss: 2.8113 - accuracy: 0.68 - 0s 700us/step - loss: 3.7608 - accuracy: 0.6804\n",
      "51/51 [==============================] - 0s 820us/step - loss: 5.2851 - accuracy: 0.7098\n",
      "51/51 [==============================] - 0s 860us/step - loss: 1.7982 - accuracy: 0.7790\n",
      "51/51 [==============================] - 0s 940us/step - loss: 36.8322 - accuracy: 0.4818\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 7.6429 - accuracy: 0.5418\n",
      "51/51 [==============================] - 0s 800us/step - loss: 34.1174 - accuracy: 0.4231\n",
      "51/51 [==============================] - 0s 780us/step - loss: 14.8175 - accuracy: 0.4931\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 7.8993 - accuracy: 0.4449\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.7041 - accuracy: 0.4969\n",
      "51/51 [==============================] - 0s 999us/step - loss: 40.8359 - accuracy: 0.5328\n",
      "51/51 [==============================] - 0s 711us/step - loss: 10.8218 - accuracy: 0.6005\n",
      "51/51 [==============================] - 0s 859us/step - loss: 16.4135 - accuracy: 0.6540\n",
      "51/51 [==============================] - 0s 800us/step - loss: 2.8894 - accuracy: 0.4831\n",
      "51/51 [==============================] - 0s 800us/step - loss: 4.6075 - accuracy: 0.3726\n",
      "51/51 [==============================] - 0s 660us/step - loss: 1.6222 - accuracy: 0.4245\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 6.2153 - accuracy: 0.5489\n",
      "51/51 [==============================] - 0s 859us/step - loss: 0.6804 - accuracy: 0.5543\n",
      "51/51 [==============================] - 0s 881us/step - loss: 22.2975 - accuracy: 0.5481\n",
      "51/51 [==============================] - 0s 680us/step - loss: 9.6316 - accuracy: 0.6005\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.5543071031570435\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.6804012656211853\n",
      "\n",
      "******\n",
      "\n",
      "51/51 [==============================] - 0s 880us/step - loss: 14.1249 - accuracy: 0.7061\n",
      "51/51 [==============================] - 0s 740us/step - loss: 3.3477 - accuracy: 0.6667\n",
      "51/51 [==============================] - 0s 853us/step - loss: 4.6067 - accuracy: 0.7306\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.6257 - accuracy: 0.7453\n",
      "51/51 [==============================] - 0s 820us/step - loss: 40.2929 - accuracy: 0.4878\n",
      "51/51 [==============================] - 0s 700us/step - loss: 11.9392 - accuracy: 0.4919\n",
      "51/51 [==============================] - 0s 820us/step - loss: 33.1835 - accuracy: 0.4319\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 14.8002 - accuracy: 0.4931\n",
      "51/51 [==============================] - 0s 919us/step - loss: 7.8335 - accuracy: 0.4478\n",
      "51/51 [==============================] - 0s 853us/step - loss: 1.7460 - accuracy: 0.4757\n",
      "51/51 [==============================] - 0s 999us/step - loss: 55.9411 - accuracy: 0.4910\n",
      "51/51 [==============================] - 0s 720us/step - loss: 17.0981 - accuracy: 0.5655\n",
      "51/51 [==============================] - 0s 860us/step - loss: 14.5024 - accuracy: 0.6726\n",
      "51/51 [==============================] - 0s 680us/step - loss: 3.3980 - accuracy: 0.4757\n",
      "51/51 [==============================] - 0s 880us/step - loss: 4.3593 - accuracy: 0.3442\n",
      "51/51 [==============================] - 0s 680us/step - loss: 1.5898 - accuracy: 0.4232\n",
      "51/51 [==============================] - 0s 840us/step - loss: 12.2395 - accuracy: 0.5552\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.9046 - accuracy: 0.6017\n",
      "51/51 [==============================] - 0s 861us/step - loss: 21.3079 - accuracy: 0.4970\n",
      "51/51 [==============================] - 0s 782us/step - loss: 9.6273 - accuracy: 0.5493\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 880us/step - loss: 16.0354 - accuracy: 0.6444\n",
      "51/51 [==============================] - 0s 767us/step - loss: 3.6845 - accuracy: 0.6841\n",
      "51/51 [==============================] - 0s 859us/step - loss: 36.1535 - accuracy: 0.6827\n",
      "51/51 [==============================] - 0s 780us/step - loss: 8.9774 - accuracy: 0.7728\n",
      "51/51 [==============================] - 0s 800us/step - loss: 37.9490 - accuracy: 0.4927\n",
      "51/51 [==============================] - 0s 700us/step - loss: 8.1679 - accuracy: 0.5406\n",
      "51/51 [==============================] - 0s 836us/step - loss: 27.3198 - accuracy: 0.4407\n",
      "51/51 [==============================] - 0s 740us/step - loss: 10.9537 - accuracy: 0.5256\n",
      "51/51 [==============================] - 0s 820us/step - loss: 8.1626 - accuracy: 0.4246\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.8546 - accuracy: 0.4744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 760us/step - loss: 42.4654 - accuracy: 0.5338\n",
      "51/51 [==============================] - 0s 635us/step - loss: 11.2294 - accuracy: 0.5955\n",
      "51/51 [==============================] - 0s 800us/step - loss: 14.5990 - accuracy: 0.6545\n",
      "51/51 [==============================] - 0s 740us/step - loss: 3.0534 - accuracy: 0.4707\n",
      "51/51 [==============================] - 0s 860us/step - loss: 4.3794 - accuracy: 0.3685\n",
      "51/51 [==============================] - 0s 781us/step - loss: 1.5598 - accuracy: 0.4345\n",
      "51/51 [==============================] - 0s 819us/step - loss: 12.5357 - accuracy: 0.5530\n",
      "51/51 [==============================] - 0s 660us/step - loss: 0.8515 - accuracy: 0.6055\n",
      "51/51 [==============================] - 0s 840us/step - loss: 23.5213 - accuracy: 0.5620\n",
      "51/51 [==============================] - 0s 640us/step - loss: 9.4572 - accuracy: 0.5893\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 836us/step - loss: 9.9903 - accuracy: 0.5677\n",
      "51/51 [==============================] - 0s 760us/step - loss: 1.9993 - accuracy: 0.7803\n",
      "51/51 [==============================] - 0s 859us/step - loss: 30.8510 - accuracy: 0.6974\n",
      "51/51 [==============================] - 0s 780us/step - loss: 7.1378 - accuracy: 0.7853\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 36.9004 - accuracy: 0.5090\n",
      "51/51 [==============================] - 0s 760us/step - loss: 8.1122 - accuracy: 0.5031\n",
      "51/51 [==============================] - 0s 780us/step - loss: 26.1710 - accuracy: 0.5142\n",
      "51/51 [==============================] - 0s 720us/step - loss: 9.9546 - accuracy: 0.5481\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 10.4692 - accuracy: 0.4751\n",
      "51/51 [==============================] - 0s 880us/step - loss: 2.9737 - accuracy: 0.4020\n",
      "51/51 [==============================] - 0s 740us/step - loss: 47.9063 - accuracy: 0.5162\n",
      "51/51 [==============================] - 0s 700us/step - loss: 14.9352 - accuracy: 0.5830\n",
      "51/51 [==============================] - 0s 740us/step - loss: 11.3704 - accuracy: 0.6760\n",
      "51/51 [==============================] - 0s 720us/step - loss: 2.6315 - accuracy: 0.3783\n",
      "51/51 [==============================] - 0s 820us/step - loss: 4.6133 - accuracy: 0.4449\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.3038 - accuracy: 0.4245\n",
      "51/51 [==============================] - 0s 800us/step - loss: 7.7942 - accuracy: 0.5441\n",
      "51/51 [==============================] - 0s 640us/step - loss: 0.7918 - accuracy: 0.4769\n",
      "51/51 [==============================] - 0s 852us/step - loss: 21.9641 - accuracy: 0.5523\n",
      "51/51 [==============================] - 0s 680us/step - loss: 9.3430 - accuracy: 0.5980\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 880us/step - loss: 9.6562 - accuracy: 0.5231\n",
      "51/51 [==============================] - 0s 660us/step - loss: 1.9219 - accuracy: 0.7903\n",
      "51/51 [==============================] - 0s 900us/step - loss: 2.1934 - accuracy: 0.6134\n",
      "51/51 [==============================] - 0s 692us/step - loss: 0.4610 - accuracy: 0.6105\n",
      "51/51 [==============================] - 0s 899us/step - loss: 40.4586 - accuracy: 0.4891\n",
      "51/51 [==============================] - 0s 700us/step - loss: 8.2471 - accuracy: 0.5456\n",
      "51/51 [==============================] - 1s 840us/step - loss: 29.1535 - accuracy: 0.5381\n",
      "51/51 [==============================] - 0s 780us/step - loss: 12.1471 - accuracy: 0.5493\n",
      "51/51 [==============================] - 0s 840us/step - loss: 8.3893 - accuracy: 0.4663\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.8780 - accuracy: 0.3970\n",
      "51/51 [==============================] - 0s 840us/step - loss: 46.1141 - accuracy: 0.5318\n",
      "51/51 [==============================] - 0s 720us/step - loss: 11.7623 - accuracy: 0.6005\n",
      "51/51 [==============================] - 0s 880us/step - loss: 14.4603 - accuracy: 0.6354\n",
      "51/51 [==============================] - 0s 681us/step - loss: 2.9335 - accuracy: 0.4757\n",
      "51/51 [==============================] - 0s 874us/step - loss: 4.3757 - accuracy: 0.3626\n",
      "51/51 [==============================] - 0s 640us/step - loss: 1.5342 - accuracy: 0.4307\n",
      "51/51 [==============================] - 0s 859us/step - loss: 11.9247 - accuracy: 0.5497\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.9079 - accuracy: 0.6017\n",
      "51/51 [==============================] - 0s 776us/step - loss: 21.6070 - accuracy: 0.5722\n",
      "51/51 [==============================] - 0s 720us/step - loss: 9.4619 - accuracy: 0.5980\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.6104868650436401\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.4609706699848175\n",
      "\n",
      "******\n",
      "\n",
      "51/51 [==============================] - 0s 999us/step - loss: 10.2387 - accuracy: 0.5194\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.9260 - accuracy: 0.7703\n",
      "51/51 [==============================] - 1s 2ms/step - loss: 2.2256 - accuracy: 0.6230\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.6042\n",
      "51/51 [==============================] - 1s 1ms/step - loss: 33.1149 - accuracy: 0.4892\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 5.9679 - accuracy: 0.5119\n",
      "51/51 [==============================] - 0s 827us/step - loss: 23.9435 - accuracy: 0.4920\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 10.3405 - accuracy: 0.5431\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 11.2953 - accuracy: 0.4578\n",
      "51/51 [==============================] - 0s 740us/step - loss: 2.2879 - accuracy: 0.3908\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 44.7381 - accuracy: 0.5269\n",
      "51/51 [==============================] - 0s 760us/step - loss: 11.6247 - accuracy: 0.5955\n",
      "51/51 [==============================] - 0s 840us/step - loss: 17.7678 - accuracy: 0.6555\n",
      "51/51 [==============================] - 0s 720us/step - loss: 3.6322 - accuracy: 0.5144\n",
      "51/51 [==============================] - 0s 860us/step - loss: 5.8033 - accuracy: 0.4709\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.4418 - accuracy: 0.3770\n",
      "51/51 [==============================] - 0s 859us/step - loss: 14.9669 - accuracy: 0.5503\n",
      "51/51 [==============================] - 0s 700us/step - loss: 0.9267 - accuracy: 0.6267\n",
      "51/51 [==============================] - 0s 740us/step - loss: 23.5097 - accuracy: 0.5822\n",
      "51/51 [==============================] - 0s 860us/step - loss: 9.8200 - accuracy: 0.5968\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 799us/step - loss: 9.4668 - accuracy: 0.5218\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.9517 - accuracy: 0.7903\n",
      "51/51 [==============================] - 0s 839us/step - loss: 2.0997 - accuracy: 0.6057\n",
      "51/51 [==============================] - 0s 760us/step - loss: 0.4686 - accuracy: 0.6042\n",
      "51/51 [==============================] - 0s 799us/step - loss: 40.2545 - accuracy: 0.4693\n",
      "51/51 [==============================] - 0s 820us/step - loss: 8.3254 - accuracy: 0.5443\n",
      "51/51 [==============================] - 0s 860us/step - loss: 28.2650 - accuracy: 0.4899\n",
      "51/51 [==============================] - 0s 780us/step - loss: 11.2256 - accuracy: 0.5518\n",
      "51/51 [==============================] - 0s 820us/step - loss: 8.9351 - accuracy: 0.4338\n",
      "51/51 [==============================] - 0s 759us/step - loss: 2.0038 - accuracy: 0.3920\n",
      "51/51 [==============================] - 0s 840us/step - loss: 41.5443 - accuracy: 0.5393\n",
      "51/51 [==============================] - 0s 800us/step - loss: 11.0821 - accuracy: 0.6005\n",
      "51/51 [==============================] - 1s 820us/step - loss: 16.9312 - accuracy: 0.6514\n",
      "51/51 [==============================] - 0s 760us/step - loss: 3.4927 - accuracy: 0.5156\n",
      "51/51 [==============================] - 0s 860us/step - loss: 8.9821 - accuracy: 0.4875\n",
      "51/51 [==============================] - 0s 660us/step - loss: 0.8338 - accuracy: 0.5993\n",
      "51/51 [==============================] - 0s 860us/step - loss: 15.9654 - accuracy: 0.5229\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.0075 - accuracy: 0.5918\n",
      "51/51 [==============================] - 0s 920us/step - loss: 78.8051 - accuracy: 0.5291\n",
      "51/51 [==============================] - 0s 720us/step - loss: 41.7308 - accuracy: 0.5406\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 820us/step - loss: 9.6045 - accuracy: 0.6373\n",
      "51/51 [==============================] - 0s 620us/step - loss: 1.4959 - accuracy: 0.7478\n",
      "51/51 [==============================] - 0s 840us/step - loss: 1.8693 - accuracy: 0.6032\n",
      "51/51 [==============================] - 0s 720us/step - loss: 0.4150 - accuracy: 0.6080\n",
      "51/51 [==============================] - 0s 800us/step - loss: 31.0450 - accuracy: 0.5111\n",
      "51/51 [==============================] - 0s 640us/step - loss: 6.1454 - accuracy: 0.4632\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 48.8463 - accuracy: 0.4738\n",
      "51/51 [==============================] - 0s 760us/step - loss: 25.0403 - accuracy: 0.4894\n",
      "51/51 [==============================] - 0s 740us/step - loss: 8.4250 - accuracy: 0.4491\n",
      "51/51 [==============================] - 0s 720us/step - loss: 2.6602 - accuracy: 0.3695\n",
      "51/51 [==============================] - 0s 800us/step - loss: 44.8997 - accuracy: 0.5260\n",
      "51/51 [==============================] - 0s 700us/step - loss: 12.1614 - accuracy: 0.5605\n",
      "51/51 [==============================] - 0s 800us/step - loss: 18.5401 - accuracy: 0.6648\n",
      "51/51 [==============================] - 0s 720us/step - loss: 3.5744 - accuracy: 0.5156\n",
      "51/51 [==============================] - 0s 837us/step - loss: 8.0950 - accuracy: 0.4730\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.7882 - accuracy: 0.5855\n",
      "51/51 [==============================] - 0s 779us/step - loss: 13.0145 - accuracy: 0.5584\n",
      "51/51 [==============================] - 0s 700us/step - loss: 1.1015 - accuracy: 0.5955\n",
      "51/51 [==============================] - 0s 860us/step - loss: 69.7769 - accuracy: 0.5487\n",
      "51/51 [==============================] - 0s 660us/step - loss: 35.7849 - accuracy: 0.5443\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 900us/step - loss: 9.9277 - accuracy: 0.5113\n",
      "51/51 [==============================] - 0s 700us/step - loss: 1.9372 - accuracy: 0.7915\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.7249 - accuracy: 0.6060\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.3924 - accuracy: 0.5993\n",
      "51/51 [==============================] - 0s 979us/step - loss: 40.6412 - accuracy: 0.4570\n",
      "51/51 [==============================] - 0s 720us/step - loss: 8.4153 - accuracy: 0.5368\n",
      "51/51 [==============================] - 0s 860us/step - loss: 25.1947 - accuracy: 0.5094\n",
      "51/51 [==============================] - 0s 720us/step - loss: 11.0491 - accuracy: 0.5518\n",
      "51/51 [==============================] - 0s 778us/step - loss: 5.1133 - accuracy: 0.4583\n",
      "51/51 [==============================] - 0s 780us/step - loss: 1.3391 - accuracy: 0.5755\n",
      "51/51 [==============================] - 0s 780us/step - loss: 41.9443 - accuracy: 0.5047\n",
      "51/51 [==============================] - 0s 880us/step - loss: 11.1399 - accuracy: 0.6017\n",
      "51/51 [==============================] - 0s 879us/step - loss: 15.2103 - accuracy: 0.6893\n",
      "51/51 [==============================] - 0s 680us/step - loss: 3.5213 - accuracy: 0.4819\n",
      "51/51 [==============================] - 0s 800us/step - loss: 186.9596 - accuracy: 0.5518\n",
      "51/51 [==============================] - 0s 680us/step - loss: 66.3139 - accuracy: 0.6255\n",
      "51/51 [==============================] - 0s 839us/step - loss: 14.4079 - accuracy: 0.5792\n",
      "51/51 [==============================] - 0s 640us/step - loss: 1.2957 - accuracy: 0.6217\n",
      "51/51 [==============================] - 0s 820us/step - loss: 62.8292 - accuracy: 0.5648\n",
      "51/51 [==============================] - 0s 677us/step - loss: 34.0670 - accuracy: 0.5418\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_TWO_FITNESS IS %.2f : \n",
      " 0.5992509126663208\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 0.392398476600647\n",
      "\n",
      "******\n",
      "\n",
      "51/51 [==============================] - 0s 800us/step - loss: 15.3865 - accuracy: 0.5259\n",
      "51/51 [==============================] - 0s 720us/step - loss: 2.9985 - accuracy: 0.7029\n",
      "51/51 [==============================] - 0s 800us/step - loss: 1.8543 - accuracy: 0.6001\n",
      "51/51 [==============================] - 0s 680us/step - loss: 0.4026 - accuracy: 0.6192\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 49.1331 - accuracy: 0.4650\n",
      "51/51 [==============================] - 0s 720us/step - loss: 11.2384 - accuracy: 0.5206\n",
      "51/51 [==============================] - 0s 920us/step - loss: 24.2980 - accuracy: 0.5123\n",
      "51/51 [==============================] - 0s 720us/step - loss: 10.5378 - accuracy: 0.5593\n",
      "51/51 [==============================] - 0s 920us/step - loss: 5.8167 - accuracy: 0.4310\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.7231 - accuracy: 0.5119\n",
      "51/51 [==============================] - 0s 860us/step - loss: 31.8808 - accuracy: 0.6007\n",
      "51/51 [==============================] - 0s 704us/step - loss: 7.1529 - accuracy: 0.6130\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 16.0030 - accuracy: 0.6754\n",
      "51/51 [==============================] - 0s 720us/step - loss: 3.2104 - accuracy: 0.4806\n",
      "51/51 [==============================] - 0s 939us/step - loss: 172.8975 - accuracy: 0.5555\n",
      "51/51 [==============================] - 0s 999us/step - loss: 63.5511 - accuracy: 0.6230\n",
      "51/51 [==============================] - 0s 840us/step - loss: 13.0823 - accuracy: 0.6449\n",
      "51/51 [==============================] - 0s 700us/step - loss: 2.1723 - accuracy: 0.6704\n",
      "51/51 [==============================] - 1s 820us/step - loss: 69.8965 - accuracy: 0.5560\n",
      "51/51 [==============================] - 0s 700us/step - loss: 36.9879 - accuracy: 0.5506\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 860us/step - loss: 9.0613 - accuracy: 0.5366\n",
      "51/51 [==============================] - 0s 700us/step - loss: 1.9425 - accuracy: 0.7915\n",
      "51/51 [==============================] - 0s 858us/step - loss: 3.5672 - accuracy: 0.5565\n",
      "51/51 [==============================] - 0s 660us/step - loss: 0.9672 - accuracy: 0.4757\n",
      "51/51 [==============================] - 0s 840us/step - loss: 24.8786 - accuracy: 0.5483\n",
      "51/51 [==============================] - 0s 841us/step - loss: 7.8518 - accuracy: 0.5243\n",
      "51/51 [==============================] - 0s 780us/step - loss: 24.8657 - accuracy: 0.5059\n",
      "51/51 [==============================] - 0s 780us/step - loss: 10.5602 - accuracy: 0.5493\n",
      "51/51 [==============================] - 0s 840us/step - loss: 5.7687 - accuracy: 0.4490\n",
      "51/51 [==============================] - 0s 780us/step - loss: 1.3454 - accuracy: 0.6055\n",
      "51/51 [==============================] - 0s 939us/step - loss: 10.1335 - accuracy: 0.6478\n",
      "51/51 [==============================] - 0s 740us/step - loss: 1.6318 - accuracy: 0.6155\n",
      "51/51 [==============================] - 0s 880us/step - loss: 16.2991 - accuracy: 0.6745\n",
      "51/51 [==============================] - 0s 660us/step - loss: 3.4729 - accuracy: 0.5019\n",
      "51/51 [==============================] - 0s 760us/step - loss: 189.7606 - accuracy: 0.5912\n",
      "51/51 [==============================] - 0s 820us/step - loss: 67.4822 - accuracy: 0.6255\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 15.4345 - accuracy: 0.6160\n",
      "51/51 [==============================] - 0s 820us/step - loss: 2.3380 - accuracy: 0.6767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 879us/step - loss: 68.3755 - accuracy: 0.5790\n",
      "51/51 [==============================] - 0s 740us/step - loss: 37.0534 - accuracy: 0.5506\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 781us/step - loss: 8.5266 - accuracy: 0.5557\n",
      "51/51 [==============================] - 0s 640us/step - loss: 1.5540 - accuracy: 0.7503\n",
      "51/51 [==============================] - 0s 820us/step - loss: 4.8484 - accuracy: 0.5564\n",
      "51/51 [==============================] - 0s 700us/step - loss: 1.0288 - accuracy: 0.5031\n",
      "51/51 [==============================] - 0s 880us/step - loss: 19.8228 - accuracy: 0.5394\n",
      "51/51 [==============================] - 0s 640us/step - loss: 6.5802 - accuracy: 0.5194\n",
      "51/51 [==============================] - 0s 860us/step - loss: 22.1509 - accuracy: 0.4811\n",
      "51/51 [==============================] - 0s 640us/step - loss: 9.2630 - accuracy: 0.5531\n",
      "51/51 [==============================] - 0s 840us/step - loss: 8.7846 - accuracy: 0.4484\n",
      "51/51 [==============================] - 0s 640us/step - loss: 2.0028 - accuracy: 0.3159\n",
      "51/51 [==============================] - 0s 899us/step - loss: 6.8056 - accuracy: 0.6178\n",
      "51/51 [==============================] - 0s 700us/step - loss: 1.3725 - accuracy: 0.6030\n",
      "51/51 [==============================] - 0s 820us/step - loss: 13.4146 - accuracy: 0.6721\n",
      "51/51 [==============================] - 0s 640us/step - loss: 2.9881 - accuracy: 0.4357\n",
      "51/51 [==============================] - 0s 820us/step - loss: 179.1076 - accuracy: 0.5814\n",
      "51/51 [==============================] - 0s 603us/step - loss: 62.5431 - accuracy: 0.6305\n",
      "51/51 [==============================] - 0s 780us/step - loss: 10.9513 - accuracy: 0.6390\n",
      "51/51 [==============================] - 0s 680us/step - loss: 2.0283 - accuracy: 0.6529\n",
      "51/51 [==============================] - 0s 820us/step - loss: 69.2962 - accuracy: 0.6003\n",
      "51/51 [==============================] - 0s 779us/step - loss: 38.1576 - accuracy: 0.5630\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 959us/step - loss: 9.6225 - accuracy: 0.5245\n",
      "51/51 [==============================] - 0s 680us/step - loss: 1.9493 - accuracy: 0.7915\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 3.0265 - accuracy: 0.5310\n",
      "51/51 [==============================] - 0s 700us/step - loss: 0.7950 - accuracy: 0.3945\n",
      "51/51 [==============================] - 0s 919us/step - loss: 21.2347 - accuracy: 0.5708\n",
      "51/51 [==============================] - 0s 700us/step - loss: 6.8097 - accuracy: 0.5281\n",
      "51/51 [==============================] - 0s 863us/step - loss: 42.1486 - accuracy: 0.5067\n",
      "51/51 [==============================] - 0s 700us/step - loss: 16.5554 - accuracy: 0.4794\n",
      "51/51 [==============================] - 0s 780us/step - loss: 59.6042 - accuracy: 0.6456\n",
      "51/51 [==============================] - 0s 720us/step - loss: 15.8429 - accuracy: 0.6567\n",
      "51/51 [==============================] - 0s 800us/step - loss: 9.3093 - accuracy: 0.6365\n",
      "51/51 [==============================] - 0s 680us/step - loss: 1.6354 - accuracy: 0.6117\n",
      "51/51 [==============================] - 0s 800us/step - loss: 104.7009 - accuracy: 0.6572\n",
      "51/51 [==============================] - 0s 660us/step - loss: 52.4481 - accuracy: 0.6479\n",
      "51/51 [==============================] - 0s 819us/step - loss: 184.5371 - accuracy: 0.5709\n",
      "51/51 [==============================] - 0s 760us/step - loss: 82.5649 - accuracy: 0.5918\n",
      "51/51 [==============================] - 0s 880us/step - loss: 13.3498 - accuracy: 0.6143\n",
      "51/51 [==============================] - 0s 700us/step - loss: 2.2772 - accuracy: 0.6704\n",
      "51/51 [==============================] - 0s 859us/step - loss: 75.1193 - accuracy: 0.5599\n",
      "51/51 [==============================] - 0s 963us/step - loss: 39.6183 - accuracy: 0.5618\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 860us/step - loss: 10.0516 - accuracy: 0.5455\n",
      "51/51 [==============================] - 0s 720us/step - loss: 1.9970 - accuracy: 0.7903\n",
      "51/51 [==============================] - 0s 860us/step - loss: 3.5862 - accuracy: 0.5222\n",
      "51/51 [==============================] - 0s 701us/step - loss: 0.8661 - accuracy: 0.4232\n",
      "51/51 [==============================] - 0s 820us/step - loss: 20.8858 - accuracy: 0.5716\n",
      "51/51 [==============================] - 0s 760us/step - loss: 6.5589 - accuracy: 0.4881\n",
      "51/51 [==============================] - 1s 820us/step - loss: 42.6882 - accuracy: 0.5002\n",
      "51/51 [==============================] - 0s 720us/step - loss: 20.9221 - accuracy: 0.6042\n",
      "51/51 [==============================] - 0s 740us/step - loss: 70.4492 - accuracy: 0.6077\n",
      "51/51 [==============================] - 0s 720us/step - loss: 18.3822 - accuracy: 0.5768\n",
      "51/51 [==============================] - 0s 800us/step - loss: 11.5176 - accuracy: 0.5845\n",
      "51/51 [==============================] - 0s 680us/step - loss: 2.0463 - accuracy: 0.6380\n",
      "51/51 [==============================] - 0s 820us/step - loss: 93.0927 - accuracy: 0.6412\n",
      "51/51 [==============================] - 0s 660us/step - loss: 51.6628 - accuracy: 0.6479\n",
      "51/51 [==============================] - 0s 939us/step - loss: 183.1234 - accuracy: 0.5834\n",
      "51/51 [==============================] - 0s 640us/step - loss: 81.1306 - accuracy: 0.5905\n",
      "51/51 [==============================] - 0s 860us/step - loss: 7.8916 - accuracy: 0.6284\n",
      "51/51 [==============================] - 0s 640us/step - loss: 2.5202 - accuracy: 0.5518\n",
      "51/51 [==============================] - 0s 939us/step - loss: 58.9536 - accuracy: 0.5611\n",
      "51/51 [==============================] - 0s 640us/step - loss: 29.0075 - accuracy: 0.5668\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "51/51 [==============================] - 0s 979us/step - loss: 16.7457 - accuracy: 0.5271\n",
      "51/51 [==============================] - 0s 700us/step - loss: 2.9067 - accuracy: 0.5131\n",
      "51/51 [==============================] - 0s 800us/step - loss: 3.0404 - accuracy: 0.4977\n",
      "51/51 [==============================] - 0s 720us/step - loss: 0.7633 - accuracy: 0.4457\n",
      "51/51 [==============================] - 0s 900us/step - loss: 23.1529 - accuracy: 0.5312\n",
      "51/51 [==============================] - 0s 720us/step - loss: 7.2957 - accuracy: 0.5231\n",
      "51/51 [==============================] - 0s 840us/step - loss: 45.5060 - accuracy: 0.5321\n",
      "51/51 [==============================] - 0s 861us/step - loss: 21.1688 - accuracy: 0.6017\n",
      "51/51 [==============================] - 0s 840us/step - loss: 61.1874 - accuracy: 0.6611\n",
      "51/51 [==============================] - 0s 760us/step - loss: 16.5742 - accuracy: 0.6467\n",
      "51/51 [==============================] - 0s 780us/step - loss: 22.5936 - accuracy: 0.5951\n",
      "51/51 [==============================] - 0s 861us/step - loss: 2.7648 - accuracy: 0.7253\n",
      "51/51 [==============================] - 0s 820us/step - loss: 104.7064 - accuracy: 0.6362\n",
      "51/51 [==============================] - 0s 680us/step - loss: 53.7952 - accuracy: 0.6554\n",
      "51/51 [==============================] - 0s 859us/step - loss: 181.9620 - accuracy: 0.5645\n",
      "51/51 [==============================] - 0s 660us/step - loss: 82.2282 - accuracy: 0.5880\n",
      "51/51 [==============================] - 0s 800us/step - loss: 13.4790 - accuracy: 0.6327\n",
      "51/51 [==============================] - 0s 640us/step - loss: 2.2402 - accuracy: 0.6692\n",
      "51/51 [==============================] - 0s 780us/step - loss: 55.1080 - accuracy: 0.5801\n",
      "51/51 [==============================] - 0s 700us/step - loss: 27.8637 - accuracy: 0.5705\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "CS最优loss为:%.5f! 0.392398476600647\n",
      "CS最优fit为：%.5f! 0.5992509126663208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "low = -3*np.ones(numsum)\n",
    "upp = 3*np.ones(numsum)\n",
    "best_nestloss, best_loss,fit = cuckoo_search(10,numsum, low,upp, step_size = 0.1)\n",
    "best_nest = best_nestloss\n",
    "best_fitness = best_loss\n",
    "print('CS最优loss为:%.5f!',best_loss),print('CS最优fit为：%.5f!',fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = best_nest\n",
    "w1 = chrom[:inputnum*hiddennum]\n",
    "w1 = w1.reshape(inputnum,hiddennum)\n",
    "b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "w2 = w2.reshape(hiddennum,outputnum)\n",
    "b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "WB_layer1 = (w1,b1)\n",
    "WB_layer2 = (w2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用CS优化初始化阈值\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(hiddennum,name='layer1',activation='relu'),\n",
    "    keras.layers.Dense(outputnum,name='layer2')\n",
    "])\n",
    "\n",
    "\n",
    "model.build(input_shape=[None,inputnum])\n",
    "#model.summary()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "            loss='mse',\n",
    "            metrics=['accuracy'])\n",
    "#model.load_weights('my_model_fun.h5')\n",
    "\n",
    "# layer1 = model.get_layer('layer1')\n",
    "# layer2 = model.get_layer('layer2')\n",
    "# layer1.set_weights(WB_layer1)\n",
    "# layer2.set_weights(WB_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.13086653,  0.03057694, -0.38599274, -0.4662123 , -0.23397201,\n",
       "         -0.32942742,  0.24489188, -0.52898884],\n",
       "        [ 0.36489242, -0.12090456, -0.05657113,  0.46751302, -0.3722663 ,\n",
       "         -0.49596182,  0.7225271 , -0.16739637],\n",
       "        [ 0.00138348,  0.4688838 ,  0.31937784, -0.5728076 ,  0.27132112,\n",
       "          0.4114464 ,  0.0528149 ,  0.51227456]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.33648154, -0.5708447 ],\n",
       "        [-0.5618688 , -0.5848658 ],\n",
       "        [-0.50321555, -0.64501333],\n",
       "        [-0.14935964, -0.6706779 ],\n",
       "        [-0.01105446, -0.04416525],\n",
       "        [-0.6693312 , -0.4226696 ],\n",
       "        [-0.7020977 , -0.45910567],\n",
       "        [-0.54173607,  0.0832271 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型参数\n",
    "la1 = model.get_layer('layer1')\n",
    "la2 = model.get_layer('layer2')\n",
    "(k1,b1) = la1.get_weights()\n",
    "(k2,b2) = la2.get_weights()\n",
    "k1,b1,k2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.5351 - accuracy: 0.3626\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.2348 - accuracy: 0.4590\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 940us/step - loss: 0.2045 - accuracy: 0.6885\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.6897\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.7716 - val_loss: 0.1797 - val_accuracy: 0.8367\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 820us/step - loss: 0.1696 - accuracy: 0.8047\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.1578 - accuracy: 0.8076\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 820us/step - loss: 0.1370 - accuracy: 0.8562\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.8213\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.8706 - val_loss: 0.1300 - val_accuracy: 0.9184\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1255 - accuracy: 0.8880\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1265 - accuracy: 0.8833\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.1275 - accuracy: 0.8642\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.86 - 0s 1ms/step - loss: 0.1294 - accuracy: 0.8618\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.8885 - val_loss: 0.0986 - val_accuracy: 0.8980\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.1136 - accuracy: 0.8868\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.1186 - accuracy: 0.8878\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1121 - accuracy: 0.8744\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.1194 - accuracy: 0.8795\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.8490 - val_loss: 0.0887 - val_accuracy: 0.9388\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1265 - accuracy: 0.8545\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1126 - accuracy: 0.8813\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.8835\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1107 - accuracy: 0.8810\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.8796 - val_loss: 0.0885 - val_accuracy: 0.9184\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.8473\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.1257 - accuracy: 0.8538\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8851\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 979us/step - loss: 0.1199 - accuracy: 0.8591\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.8771 - val_loss: 0.0834 - val_accuracy: 0.9184\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.8624\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.1142 - accuracy: 0.8816\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.8837\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1214 - accuracy: 0.8494\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.8740 - val_loss: 0.0842 - val_accuracy: 0.9184\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.8696\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8804\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.8718\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.1215 - accuracy: 0.8593\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.8829 - val_loss: 0.0933 - val_accuracy: 0.8980\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.1127 - accuracy: 0.8689\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1191 - accuracy: 0.8530\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.8383\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 999us/step - loss: 0.1108 - accuracy: 0.8625\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.8720 - val_loss: 0.0943 - val_accuracy: 0.9184\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.1152 - accuracy: 0.8506\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1107 - accuracy: 0.8754\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1120 - accuracy: 0.8827\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8689\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.8694 - val_loss: 0.0941 - val_accuracy: 0.9184\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.1085 - accuracy: 0.8718\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.1103 - accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.8852\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.1147 - accuracy: 0.8634\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9027 - val_loss: 0.0947 - val_accuracy: 0.8980\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 740us/step - loss: 0.1036 - accuracy: 0.8865\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.1161 - accuracy: 0.8546\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 780us/step - loss: 0.1150 - accuracy: 0.8586\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 800us/step - loss: 0.1210 - accuracy: 0.8581\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8718 - val_loss: 0.0919 - val_accuracy: 0.8980\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.8752\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 959us/step - loss: 0.1126 - accuracy: 0.8691\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.1100 - accuracy: 0.8761\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.1124 - accuracy: 0.8778\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.8556 - val_loss: 0.0970 - val_accuracy: 0.8776\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.8665\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.1238 - accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 820us/step - loss: 0.1141 - accuracy: 0.8492\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 820us/step - loss: 0.1070 - accuracy: 0.8864\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8721 - val_loss: 0.0975 - val_accuracy: 0.9184\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.1123 - accuracy: 0.8776\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.1127 - accuracy: 0.8736\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.1092 - accuracy: 0.8813\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.8666\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.8683 - val_loss: 0.1029 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 860us/step - loss: 0.1182 - accuracy: 0.8512\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.8572\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.8710\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1058 - accuracy: 0.8763\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.8674 - val_loss: 0.0981 - val_accuracy: 0.8980\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 780us/step - loss: 0.1102 - accuracy: 0.8748\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 899us/step - loss: 0.1123 - accuracy: 0.8605\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 840us/step - loss: 0.0952 - accuracy: 0.8975\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1093 - accuracy: 0.8690\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.8514 - val_loss: 0.0958 - val_accuracy: 0.9184\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 780us/step - loss: 0.1189 - accuracy: 0.8640\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 919us/step - loss: 0.1093 - accuracy: 0.8737\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 820us/step - loss: 0.1200 - accuracy: 0.8318\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 859us/step - loss: 0.1037 - accuracy: 0.8772\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.8742 - val_loss: 0.0969 - val_accuracy: 0.9184\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.1098 - accuracy: 0.8804\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1057 - accuracy: 0.8903\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 880us/step - loss: 0.1124 - accuracy: 0.8777\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 879us/step - loss: 0.1180 - accuracy: 0.8589\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.8683 - val_loss: 0.0985 - val_accuracy: 0.9184\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 939us/step - loss: 0.1140 - accuracy: 0.8691\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 780us/step - loss: 0.1228 - accuracy: 0.8391\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 900us/step - loss: 0.1065 - accuracy: 0.8693\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 800us/step - loss: 0.1092 - accuracy: 0.8772\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.8686 - val_loss: 0.0952 - val_accuracy: 0.9184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x266e37ba288>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "model.fit(db,epochs=100,validation_data=ds_val,validation_freq=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9184\n",
      "\n",
      "test loss 0.09522389620542526\n",
      "accuracy 0.918367326259613\n"
     ]
    }
   ],
   "source": [
    "# 评估模型,不输出预测结果\n",
    "loss,accuracy = model.evaluate(ds_val)\n",
    "print('\\ntest loss',loss)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1], dtype=int64)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型预测,输入测试集,输出预测结果\n",
    "y_pred = model.predict(TestX)\n",
    "y_pred = tf.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = tf.argmax(TestY_onehot,axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X)\n",
    "y_pred_train = tf.argmax(y_pred_train,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tf.argmax(Y_onehot,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestfit)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fitness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestFit', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = y_pred - test_y\n",
    "x = list(range(0,len(error)))\n",
    "fig = sns.lineplot(x,error,color=\"b\")\n",
    "plt.xlabel(\"Test Data Num\")\n",
    "plt.ylabel(\"error\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./Error_Num', dpi = 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestloss,color=\"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"lossness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestLoss', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns主题风格  darkgrid  whitegrid  dark  white  ticks\n",
    "sns.set_style(\"ticks\")  #设置主题风格\n",
    "sns.color_palette(\"hls\",8)  #设置颜色空间种类（几种可用颜色）\n",
    "data=np.random.normal(size=(20,8)) + np.arange(8) /2\n",
    "sns.boxplot(data = data,palette = sns.color_palette(\"hls\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描述两个变量的关系 最好用散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mean,cov = [0,1],[(1,.5),(.5,1)]\n",
    "data = np.random.multivariate_normal(mean,cov,200)\n",
    "df = pd.DataFrame(data,columns=[\"x\",\"y\"])\n",
    "#绘制散点图\n",
    "sns.jointplot(x=\"x\",y=\"y\",data = df,color=\"r\")  #如果点很多，用颜色深度表示数量 kind=\"hex\" ,可以单独传x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移植STM32准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testx = X / X.max().max()\n",
    "Testx = np.array(Testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Testx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-158e708c3fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTestx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Testx' is not defined"
     ]
    }
   ],
   "source": [
    "aa = []\n",
    "aa.append(list(Testx[0]))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3447314, 0.6587833]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_sig=model.predict(aa)\n",
    "pre_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmax(pre_sig,axis=None)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "796    0\n",
       "797    1\n",
       "798    0\n",
       "799    0\n",
       "800    1\n",
       "Name: 0, Length: 801, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Env.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a2c956a6c57c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Env.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(load_model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"Env.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #建立一个测试模型\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(5,), name='dense_xiaoming',\n",
    "          kernel_initializer='zeros',  # 全部初始化为0\n",
    "          bias_initializer='ones'),  # 全部初始化为1\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(shape=(8, 5))  # 创建测试数据\n",
    "y = model(x)\n",
    "layer = model.get_layer('dense_xiaoming')  # 通过层的名字得到层\n",
    "(k, b) = layer.get_weights()  # 查看层的初始化权重值和偏置项\n",
    "print(k)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
