{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS_BP预处理部分"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author：GZU_QLL\n",
    "time：2021/09/30\n",
    "version：1.5\n",
    "language：python、jupyter\n",
    "主要修改先放在下方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改版（改进如下）其中1,4为核心点，已完成；2,3不打算搞了，意义不大。\n",
    "1：使用反向学习和混沌初始化解决随机初始化种群在整个搜索空间分布不均的问题，整加初始种群的表达能力\n",
    "2：局部优化的时候随机生成反向的两组，增加局部收敛速度,\n",
    "3：局部优化修改原始的随机淘汰一部分nest的方式，使用每隔一段周期，计算在在些周期过去之后适应度进化程度百分比最低的nest，因为这些nests很有可能陷入了局部最优。新的位置选择随机两组较优nest之间，保证算法的全局收敛能力。\n",
    "4:引入adaboost,组合多个CS-BP模型，其中每个CS的nests初始化使用tent初始化，对于tent的初值不再靠实验，而是产生多个足够有差异CS-BP，最后组合优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sc_special\n",
    "import tensorflow as tf \n",
    "from \ttensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers,metrics,layers,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据以及预处理\n",
    "data = pd.read_csv('GY_AIR.csv',sep=',',header=0,usecols=[1,2,3,4,5,6,7])\n",
    "X = data.iloc[:400,1:]\n",
    "Y = data.iloc[:400,0]\n",
    "TestX = data.iloc[400:,1:]\n",
    "TestY = data.iloc[400:,0]\n",
    "\n",
    "inputnum = 6\n",
    "hiddennum = 10\n",
    "outputnum = 3\n",
    "numsum = inputnum*hiddennum+hiddennum+hiddennum*outputnum+outputnum #6*10+10+10*3+3=103\n",
    "bestfit = []  #保存CS迭代过程中的loss、acc，画图用\n",
    "bestloss = []\n",
    "LossArr = []\n",
    "\n",
    "\n",
    "n_train = X.shape[0]\n",
    "#弱分类器数量\n",
    "M = 5\n",
    "\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32) #/ X.max().max()\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=3)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 6) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "\n",
    "#零均值处理\n",
    "X.iloc[:,0] -= np.mean(X,axis=0)[0]  \n",
    "X.iloc[:,1] -= np.mean(X,axis=0)[1]\n",
    "X.iloc[:,2] -= np.mean(X,axis=0)[2]\n",
    "X.iloc[:,3] -= np.mean(X,axis=0)[3]  \n",
    "X.iloc[:,4] -= np.mean(X,axis=0)[4]\n",
    "X.iloc[:,5] -= np.mean(X,axis=0)[5]\n",
    "#归一化\n",
    "X.iloc[:,0] /= np.max(np.abs(X),axis=0)[0]\n",
    "X.iloc[:,1] /= np.max(np.abs(X),axis=0)[1]\n",
    "X.iloc[:,2] /= np.max(np.abs(X),axis=0)[2]\n",
    "X.iloc[:,3] /= np.max(np.abs(X),axis=0)[3]  \n",
    "X.iloc[:,4] /= np.max(np.abs(X),axis=0)[4]\n",
    "X.iloc[:,5] /= np.max(np.abs(X),axis=0)[5]\n",
    "#零均值处理\n",
    "TestX.iloc[:,0] -= np.mean(TestX,axis=0)[0]  \n",
    "TestX.iloc[:,1] -= np.mean(TestX,axis=0)[1]\n",
    "TestX.iloc[:,2] -= np.mean(TestX,axis=0)[2]\n",
    "TestX.iloc[:,3] -= np.mean(TestX,axis=0)[3]  \n",
    "TestX.iloc[:,4] -= np.mean(TestX,axis=0)[4]\n",
    "TestX.iloc[:,5] -= np.mean(TestX,axis=0)[5]\n",
    "#归一化\n",
    "TestX.iloc[:,0] /= np.max(np.abs(TestX),axis=0)[0]\n",
    "TestX.iloc[:,1] /= np.max(np.abs(TestX),axis=0)[1]\n",
    "TestX.iloc[:,2] /= np.max(np.abs(TestX),axis=0)[2]\n",
    "TestX.iloc[:,3] /= np.max(np.abs(TestX),axis=0)[3]  \n",
    "TestX.iloc[:,4] /= np.max(np.abs(TestX),axis=0)[4]\n",
    "TestX.iloc[:,5] /= np.max(np.abs(TestX),axis=0)[5]\n",
    "batchsz = 32\n",
    "db = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "db = db.map(preprocess).batch(batchsz)#.shuffle(60000)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((TestX,TestY))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape,sample[1].shape)\n",
    "Y_onehot = tf.one_hot(Y,depth=3)\n",
    "TestY_onehot = tf.one_hot(TestY,depth=3)\n",
    "X = tf.cast(X,dtype=tf.float32)# / 203.\n",
    "TestX = tf.cast(TestX,dtype=tf.float32) #/ 203."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#n：布谷鸟数  m：布谷鸟的维度\n",
    "def cuckoo_search(n, m, lower_boundary, upper_boundary, iter_num = 20,pa = 0.25, beta = 1.5, step_size = 0.1,alpha=0.77,xn=0.33):\n",
    "\n",
    "    num=1\n",
    "    # get initial nests' locations \n",
    "    nests,best_nest,best_fitness,lossness = generate_nests(n, m,alpha,xn) #alpha,xn用于tent初始化阈值和初值设置\n",
    "    \n",
    "    # get the best nest and record it\n",
    "    bestfit.append(best_fitness) #全局变量，保存每代最佳适应度值\n",
    "    \n",
    "\n",
    "    print('\\r\\n BEST_LOSSNESS IS %.2f : \\r\\n',best_fitness)\n",
    "\n",
    "    for _ in range(iter_num):\n",
    "        \n",
    "        print('\\r\\n******************************************************第 %d 代开始迭代优化************************************************************\\r\\n'%num)\n",
    "        nests = update_nests(lower_boundary, upper_boundary, nests, best_nest, lossness, step_size,best_fitness)\n",
    "        nests = abandon_nests(nests, lower_boundary, upper_boundary, pa)\n",
    "        \n",
    "        print('\\r\\n*****************************************************第 %d 次迭代，计算适应度********************************************************\\r\\n'%num)\n",
    "        fitness,lossness,_ = calc_fitness( nests)\n",
    "        print('\\r\\n*********************************************************第 %d 次迭代结束************************************************************\\r\\n'%num)\n",
    "        \n",
    "        min_loss_index = np.argmin(lossness)\n",
    "        min_loss = lossness[min_loss_index]\n",
    "        min_loss_fit = fitness[min_loss_index]\n",
    "        min_nestloss = nests[min_loss_index]\n",
    "        LossArr.append(min_loss)\n",
    "            \n",
    "        if min_loss < best_fitness  : #and  min_loss_fit > best_two_fitness\n",
    "            best_nest = min_nestloss\n",
    "            best_fitness = min_loss\n",
    "            best_acc = min_loss_fit\n",
    "            print('\\r\\n******')\n",
    "            print('\\r\\n 第 %d 次迭代最优Loss是 %.2f : \\r\\n'%(num,best_fitness))\n",
    "            print('\\r\\n******\\r\\n')\n",
    "        num+=1\n",
    "\n",
    "    return (best_nest, best_fitness,best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nests(n, m,alpha,xn):\n",
    "\n",
    "#随机生成nest\n",
    "#     lower_boundary = np.array(lower_boundary)\n",
    "#     upper_boundary = np.array(upper_boundary)\n",
    "#     nests = np.empty((n, m))\n",
    "\n",
    "#     for each_nest in range(n):\n",
    "#         nests[each_nest] = lower_boundary + np.array([np.random.rand() for _ in range(m)]) * (upper_boundary - lower_boundary)\n",
    "\n",
    "#Tent混沌反向初始化\n",
    "\n",
    "#混沌初始化\n",
    "    nests = np.empty((n, m))\n",
    "    sig_nest = np.empty(m)\n",
    "    alpha = alpha\n",
    "    xn = xn\n",
    "    for i in range(0,n):   #*2 值域为【-1,1】 *6 值域为[-3,3]\n",
    "        for j in range(0,m):\n",
    "            if 0<=xn<alpha:\n",
    "                xn = xn/alpha\n",
    "                sig_nest[j]=(xn-0.5)*6\n",
    "            elif alpha <= xn <= 1:\n",
    "                xn = (1-xn)/(1-alpha)\n",
    "                sig_nest[j] = (xn-0.5)*6\n",
    "            nests[i] = sig_nest\n",
    "            \n",
    "#反向初始化            \n",
    "    renests = -1 * nests   #定义：Pi = ai + bi - pi  生成反向nests\n",
    "    \n",
    "#拼接两个初始化nests\n",
    "    nests = np.vstack((nests,renests))  #拼接nests和renests 准备计算适应度选择最优的n个nest\n",
    "    \n",
    "#计算适应度\n",
    "    fitness,lossness,_ = calc_fitness( nests) \n",
    "    \n",
    "#根据loss值排序\n",
    "    arrIndex = np.argsort(lossness)   #获得排序数组  从小到大\n",
    "    lossness = lossness[arrIndex]     #将lossness数组按照从小到大排序\n",
    "    nests = nests[arrIndex]    #将nests也按照相同序列进行排序，保证和lossness对齐\n",
    "    \n",
    "#删除多余的n组nest，这里从最底下开始一个个删，因为已经排好序了，所以删除的为效果最差的\n",
    "    for i in range(n):\n",
    "        nests = np.delete(nests,-1,0)\n",
    "        lossness = np.delete(lossness,-1,0)\n",
    "#现在的nests是按照loss排序的，第一个loss最小\n",
    "\n",
    "    return nests,nests[0],lossness[0],lossness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nests(lower_boundary, upper_boundary, nests, best_nest, lossness, step_coefficient,bestfitness):\n",
    "\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    # 莱维飞行生成步长：较长时间的短步长和较短时间的长步长\n",
    "    #生成的步长的shape也是n*m，保证所有元素得到更新\n",
    "    #这个步长通过step_size来控制大小\n",
    "    steps = levy_flight(n, m, 1.5)\n",
    "    new_nests = nests.copy()\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        # coefficient 0.01 is to avoid levy flights becoming too aggresive\n",
    "        # and (nest[each_nest] - best_nest) 保留了最佳nest，但会导致局部最优\n",
    "        step_size = step_coefficient * steps[each_nest] # * (nests[each_nest] - best_nest)\n",
    "        step_direction = np.random.rand(m) #0-1均匀概率分布生成方向\n",
    "        #新的布谷鸟在原来的基础上加上步长和方向\n",
    "        new_nests[each_nest] += step_size * step_direction  \n",
    "        # apply boundary condtions\n",
    "        new_nests[each_nest][new_nests[each_nest] < lower_boundary] = lower_boundary[new_nests[each_nest] < lower_boundary]\n",
    "        new_nests[each_nest][new_nests[each_nest] > upper_boundary] = upper_boundary[new_nests[each_nest] > upper_boundary]\n",
    "\n",
    "    new_fitness,new_losses,new_nests = calc_fitness(new_nests)\n",
    "    #适应度更好的才更新过去\n",
    "    \n",
    "    nests[new_losses < lossness] = new_nests[new_losses < lossness] \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abandon_nests(nests, lower_boundary, upper_boundary, pa):\n",
    "\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    for each_nest in range(n):  \n",
    "        #pa概率抛弃，抛弃后重新生成\n",
    "        if (np.random.rand() < pa):\n",
    "            #局部随机行走生成步长\n",
    "            #随机两个种群相差*一个0-1的随机数\n",
    "            step_size = np.random.rand() * (nests[np.random.randint(0, n)] - nests[np.random.randint(0, n)])\n",
    "            nests[each_nest] += step_size\n",
    "            # apply boundary condtions\n",
    "            nests[each_nest][nests[each_nest] < lower_boundary] = lower_boundary[nests[each_nest] < lower_boundary]\n",
    "            nests[each_nest][nests[each_nest] > upper_boundary] = upper_boundary[nests[each_nest] > upper_boundary]\n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(n, m, beta):\n",
    "\n",
    "    sigma_u = (sc_special.gamma(1+beta)*np.sin(np.pi*beta/2)/(sc_special.gamma((1+beta)/2)*beta*(2**((beta-1)/2))))**(1/beta)\n",
    "    sigma_v = 1\n",
    "\n",
    "    u =  np.random.normal(0, sigma_u, (n, m))\n",
    "    v = np.random.normal(0, sigma_v, (n, m))\n",
    "\n",
    "    steps = u/((np.abs(v))**(1/beta))\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(nests):\n",
    "    \n",
    "    n, m = nests.shape\n",
    "    fitness = np.empty(n)\n",
    "    lossness = np.empty(n)\n",
    "    new_nests = nests\n",
    "    for Sig_nest in range(n):\n",
    "        chrom = nests[Sig_nest]\n",
    "        #分解模型参数\n",
    "        w1 = chrom[:inputnum*hiddennum]\n",
    "        w1 = w1.reshape(inputnum,hiddennum)\n",
    "        b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "        w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "        w2 = w2.reshape(hiddennum,outputnum)\n",
    "        b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "        WB_l1 = (w1,b1)\n",
    "        WB_l2 = (w2,b2)\n",
    "        #创建模型，并赋予参数\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(hiddennum,activation='relu',name='l1'),\n",
    "            keras.layers.Dense(outputnum,name='l2')\n",
    "        ])\n",
    "        model.build(input_shape=[None,inputnum])\n",
    "        \n",
    "        #model.summary()\n",
    "        model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                    loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        layer1 = model.get_layer('l1')\n",
    "        layer2 = model.get_layer('l2')\n",
    "        layer1.set_weights(WB_l1)\n",
    "        layer2.set_weights(WB_l2)\n",
    "        \n",
    "        #训练模型\n",
    "        #model.fit(db,epochs=1,validation_data=ds_val,validation_freq=1)\n",
    "        model.fit(db,epochs=2,validation_data=ds_val,validation_freq=1)\n",
    "        loss,acc = model.evaluate(db)  #这里是用验证集评估，其实应该用测试集吧 evaluate产生两个结果，前面是损失，后面是准确率\n",
    "        lossness[Sig_nest] = loss\n",
    "        fitness[Sig_nest] = acc  #将模型评估正确率作为适应度返回\n",
    "        \n",
    "        (k1,y1) = layer1.get_weights()  #获取训练后的神经网络权值，并赋值给c\n",
    "        (k2,y2) = layer2.get_weights()\n",
    "        c=k1.reshape(1,-1).tolist()[0] + y1.reshape(1,-1).tolist()[0] + k2.reshape(1,-1).tolist()[0] + y2.reshape(1,-1).tolist()[0]\n",
    "        new_nests[Sig_nest] = c\n",
    "        \n",
    "        \n",
    "#         if(acc>bestfitness): #在计算适应度的过程当中，发现有更好的适应度就把参数保存\n",
    "#             #model.save_weights('my_model_fun.h5')\n",
    "#             bestfitness = acc\n",
    "    return fitness,lossness,new_nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%.2f 0.11\n",
      "%.2f 0.33\n",
      "%.2f 0.55\n",
      "%.2f 0.77\n",
      "%.2f 0.93\n"
     ]
    }
   ],
   "source": [
    "for i in range(M):\n",
    "    print(\"%.2f\",alpha[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 个CS算法开始\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 29.1108 - accuracy: 0.0634 - val_loss: 29.5711 - val_accuracy: 0.1400\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 17.0022 - accuracy: 0.2053 - val_loss: 17.5701 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.0662 - accuracy: 0.2975\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 1s 26ms/step - loss: 32.4893 - accuracy: 0.8024 - val_loss: 52.5070 - val_accuracy: 0.7800\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.2287 - accuracy: 0.8146 - val_loss: 35.9769 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.1291 - accuracy: 0.8500\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 1s 23ms/step - loss: 536.5329 - accuracy: 0.5203 - val_loss: 481.8652 - val_accuracy: 0.4000\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 415.6569 - accuracy: 0.5093 - val_loss: 379.9071 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 263.6363 - accuracy: 0.5275\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 100.4588 - accuracy: 0.5412 - val_loss: 78.4614 - val_accuracy: 0.5400\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 67.5331 - accuracy: 0.5364 - val_loss: 55.8687 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 32.6527 - accuracy: 0.5725\n",
      "Epoch 1/2\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 6.8194 - accuracy: 0.0030 - val_loss: 5.2301 - val_accuracy: 0.0200\n",
      "Epoch 2/2\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.1762 - accuracy: 0.0341 - val_loss: 3.7234 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4014 - accuracy: 0.1375\n",
      "Epoch 1/2\n",
      " 1/13 [=>............................] - ETA: 4s - loss: 10.6555 - accuracy: 0.2500"
     ]
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "low = -3*np.ones(numsum)\n",
    "upp = 3*np.ones(numsum)\n",
    "i = 0\n",
    "j = 0\n",
    "best_nest = [] #保存每次CS最佳loss对应的nest，用于赋值给不同神经网络构成多个弱分类器\n",
    "best_loss = []\n",
    "best_fitness = []\n",
    "alpha = [0.11,0.33,0.55,0.77,0.93]  #alpha不取0.5,0<alpha<1\n",
    "xn = [0.18,0.29,0.40,0.69,0.88]  #xn值不能和alpha值相同，否则将演化为周期系统，就不是混沌系统了\n",
    "for i in range(M):\n",
    "    print('第 %d 个CS算法开始'%(i+1))\n",
    "    nest,loss,fitness = cuckoo_search(20,numsum, low,upp, step_size = 0.4,alpha=alpha[i],xn=xn[i])\n",
    "    best_nest.append(nest)\n",
    "    best_loss.append(loss)\n",
    "    best_fitness.append(fitness)\n",
    "for j in range(M):    \n",
    "    print('第 %d 个CS最优loss为:%.5f!'%(j+1,best_loss[j]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2310 - accuracy: 0.1164\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3042 - accuracy: 0.2579\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.0420 - accuracy: 0.4625\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3122 - accuracy: 0.5616\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8971 - accuracy: 0.5969 - val_loss: 1.7712 - val_accuracy: 0.4600\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.6387\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6921\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7491\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7616\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.7674 - val_loss: 1.1518 - val_accuracy: 0.6200\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7712\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7838\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.7883\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8127\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.8253 - val_loss: 0.8683 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8317\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8364\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8371\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8418\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2691 - accuracy: 0.8365 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8534\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.8620\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8598\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.8733\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2113 - accuracy: 0.8789 - val_loss: 0.5430 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.8862\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.8869\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.8964\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.8964\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1703 - accuracy: 0.8991 - val_loss: 0.4492 - val_accuracy: 0.6200\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.8995\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9046\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9046\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.9119 - val_loss: 0.3895 - val_accuracy: 0.6800\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9119\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9078\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9078\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9104\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9140 - val_loss: 0.3463 - val_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9114\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9114\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9114\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9186\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9186 - val_loss: 0.3094 - val_accuracy: 0.7000\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9186\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9186\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9186\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9226\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.9196 - val_loss: 0.2664 - val_accuracy: 0.7200\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9161\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9161\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9161\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9161\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9151 - val_loss: 0.2317 - val_accuracy: 0.7800\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9125\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9125\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9125 - val_loss: 0.2037 - val_accuracy: 0.7800\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9125\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9130\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9130\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9130\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0643 - accuracy: 0.9130 - val_loss: 0.1813 - val_accuracy: 0.7800\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9130\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9130\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9130\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9130\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0604 - accuracy: 0.9125 - val_loss: 0.1656 - val_accuracy: 0.7800\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9125\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9125\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9125\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9125\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0577 - accuracy: 0.9125 - val_loss: 0.1551 - val_accuracy: 0.7800\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9125\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9125\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9125\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9125\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9125 - val_loss: 0.1471 - val_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9125\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9125\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9125\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9125\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9125 - val_loss: 0.1413 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9125\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9125\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9125\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9125\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9125 - val_loss: 0.1361 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9125\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9125\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9125\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9125\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9125 - val_loss: 0.1320 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9125\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9125\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9125\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9147\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9147 - val_loss: 0.1278 - val_accuracy: 0.8400\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.5569\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.5006\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.5182\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.5769\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.5164 - accuracy: 0.5862 - val_loss: 0.9445 - val_accuracy: 0.7600\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.5965\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.6108\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.6149\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.6355\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3402 - accuracy: 0.6381 - val_loss: 0.6966 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.6610\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.6724\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.7105\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.7343\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.7370 - val_loss: 0.4983 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.7514\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.7786\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.7901\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7893\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1721 - accuracy: 0.8016 - val_loss: 0.3754 - val_accuracy: 0.8800\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.8176\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.8418\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.8404\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.8495\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.8573 - val_loss: 0.2912 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.8588\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.8683\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.8668\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.8597\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.8594 - val_loss: 0.2478 - val_accuracy: 0.8800\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.8643\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.8755\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.8733\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.8781\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.8811 - val_loss: 0.2219 - val_accuracy: 0.8800\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.8811\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.8811\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.8811\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.8806\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.8854 - val_loss: 0.2051 - val_accuracy: 0.8800\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.8832\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.8899\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.8899 - val_loss: 0.1919 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.8889\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.8889\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.8889 - val_loss: 0.1836 - val_accuracy: 0.8600\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.8889 - val_loss: 0.1772 - val_accuracy: 0.8600\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.8863\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.8863\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.8936\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.8936\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.0714 - accuracy: 0.8936 - val_loss: 0.1724 - val_accuracy: 0.8600\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.8936\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.8936\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.8936\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.8936\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.8975 - val_loss: 0.1685 - val_accuracy: 0.8400\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.8975\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.84 - 0s 2ms/step - loss: 0.0699 - accuracy: 0.8975\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.8975\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.8975\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.8975 - val_loss: 0.1656 - val_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.8975\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.8957\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.8957\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.8957\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.8957 - val_loss: 0.1625 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.8957\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.8947\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.8947\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.8947\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.8947 - val_loss: 0.1598 - val_accuracy: 0.8400\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.8947\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.8947\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.8947\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.8947\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.8947 - val_loss: 0.1578 - val_accuracy: 0.8600\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.8947\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.8947\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.8947\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.8947\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.8947 - val_loss: 0.1567 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.8947\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.8947\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.8947\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.8947\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.8875 - val_loss: 0.1561 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.8947\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.8875\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.8848\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.8875\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.8875 - val_loss: 0.1561 - val_accuracy: 0.8400\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4626 - accuracy: 0.4242\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1311 - accuracy: 0.6055\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6665\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7603 - accuracy: 0.6759\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6500 - accuracy: 0.6960 - val_loss: 0.6628 - val_accuracy: 0.6400\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7128\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7363\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7495\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.7642\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.7747 - val_loss: 0.4436 - val_accuracy: 0.7400\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.7950\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.7940\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8089\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.8082 - val_loss: 0.3491 - val_accuracy: 0.7400\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.8158\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.8164\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.8164\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.8267\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1784 - accuracy: 0.8317 - val_loss: 0.2910 - val_accuracy: 0.7400\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.8368\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.8400\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.8421\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.8494\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.8546 - val_loss: 0.2510 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.8546\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.8546\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.8641\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.8754\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.8826 - val_loss: 0.2210 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.8826\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8826\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8826\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.8841\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1055 - accuracy: 0.8841 - val_loss: 0.1986 - val_accuracy: 0.7800\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.8823\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.8938\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.8977\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.9050 - val_loss: 0.1816 - val_accuracy: 0.7600\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9050\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9072\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9072\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9021\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9018 - val_loss: 0.1692 - val_accuracy: 0.7800\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9018\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9068\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9068\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9086\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9152 - val_loss: 0.1599 - val_accuracy: 0.7800\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9225\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9275\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9275\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9236\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9271 - val_loss: 0.1529 - val_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9261\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9261\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9261\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9283\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0695 - accuracy: 0.9333 - val_loss: 0.1477 - val_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9373\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9373\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9373\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9358 - val_loss: 0.1434 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9324\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9324\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9324\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9324\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.9324 - val_loss: 0.1385 - val_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9324\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9324\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9324\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9324\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0598 - accuracy: 0.9324 - val_loss: 0.1347 - val_accuracy: 0.8200\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9324\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9324\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9251\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9251\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9251 - val_loss: 0.1313 - val_accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9251\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9251\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9251\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9251\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9251 - val_loss: 0.1292 - val_accuracy: 0.8200\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9251\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9251\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9251\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9251\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 0.9241 - val_loss: 0.1274 - val_accuracy: 0.8200\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9241\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9241\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9268\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9268\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0531 - accuracy: 0.9268 - val_loss: 0.1267 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9268\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9268\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9268\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9268\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9268 - val_loss: 0.1254 - val_accuracy: 0.8200\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.0284\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.0276\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.0379\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.0379\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3036 - accuracy: 0.1713 - val_loss: 0.3170 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.5515\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.5515\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.5515\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.5515\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.5515 - val_loss: 0.2259 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.5515\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.37 - 0s 2ms/step - loss: 0.1734 - accuracy: 0.5515\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.5515\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.5515\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.5515 - val_loss: 0.2182 - val_accuracy: 0.6200\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.5515\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.5515\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.5515\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.5515\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.5515 - val_loss: 0.2194 - val_accuracy: 0.6200\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.5515\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.5515\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.5515\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.5515\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.5515 - val_loss: 0.2186 - val_accuracy: 0.6200\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.5515\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.5515\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.5515\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.5515\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.5515 - val_loss: 0.2154 - val_accuracy: 0.6200\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.5515\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.5522\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.5522\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.5522\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.5522 - val_loss: 0.2050 - val_accuracy: 0.6200\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.5522\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.5522\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.5522\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.5522\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1630 - accuracy: 0.5522 - val_loss: 0.2029 - val_accuracy: 0.6200\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.5522\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.5522\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.5522\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.5522\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.5522 - val_loss: 0.1935 - val_accuracy: 0.6200\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.5522\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.5522\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.5522\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.5522\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1622 - accuracy: 0.5522 - val_loss: 0.1915 - val_accuracy: 0.6200\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.5522\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.5522\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.5522\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.5522\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.5522 - val_loss: 0.1895 - val_accuracy: 0.6200\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.5522\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.5522\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.5522\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.5522\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.5522 - val_loss: 0.1877 - val_accuracy: 0.6200\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1619 - accuracy: 0.5522 - val_loss: 0.1861 - val_accuracy: 0.6200\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.5522\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1618 - accuracy: 0.5522 - val_loss: 0.1844 - val_accuracy: 0.6200\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.5522 - val_loss: 0.1831 - val_accuracy: 0.6200\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.5522\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1617 - accuracy: 0.5522 - val_loss: 0.1819 - val_accuracy: 0.6200\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1617 - accuracy: 0.5522 - val_loss: 0.1808 - val_accuracy: 0.6200\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.5522\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.5522 - val_loss: 0.1800 - val_accuracy: 0.6200\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.5522\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1616 - accuracy: 0.5522 - val_loss: 0.1779 - val_accuracy: 0.6200\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.5522\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.5522\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.5522\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.5522\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1615 - accuracy: 0.5522 - val_loss: 0.1777 - val_accuracy: 0.6200\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.5432\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.5432\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.5432\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.5443\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1668 - accuracy: 0.5521 - val_loss: 0.3341 - val_accuracy: 0.6600\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.5566\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.5591\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.5597\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.5597\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.5604 - val_loss: 0.3515 - val_accuracy: 0.6400\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.5615\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.5670\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.5706\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.5711\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.5706 - val_loss: 0.2790 - val_accuracy: 0.5800\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.5762\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.5783\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.5803\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.5874\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1491 - accuracy: 0.5865 - val_loss: 0.1781 - val_accuracy: 0.5800\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.5874\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.5885\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.5873\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.5848\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.5848 - val_loss: 0.1469 - val_accuracy: 0.5800\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.5848\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.6307\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.7597\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.7824\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1092 - accuracy: 0.8024 - val_loss: 0.1212 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.8173\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.8290\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8399\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.8399\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.8420 - val_loss: 0.0975 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.8516\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.8804\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.8890\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.8986\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.8981 - val_loss: 0.0842 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.8986\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.8981\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9055\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9049\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9147 - val_loss: 0.0764 - val_accuracy: 0.8800\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9049\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9214\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9124\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9232\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.9272 - val_loss: 0.0771 - val_accuracy: 0.8400\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9323\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9338\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9323\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9323\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9324 - val_loss: 0.0750 - val_accuracy: 0.8400\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9323\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9314\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9323\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9314\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9323 - val_loss: 0.0781 - val_accuracy: 0.8400\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9276\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9323\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9262\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9323\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9250 - val_loss: 0.0727 - val_accuracy: 0.8400\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9363\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9314\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9363\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9314\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9378 - val_loss: 0.0769 - val_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9314\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9378\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9314\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9378\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9314 - val_loss: 0.0760 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9378\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9314\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9363\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9323 - val_loss: 0.0797 - val_accuracy: 0.8400\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9412\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9323\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9412\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9338\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9412 - val_loss: 0.0742 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9378\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9412\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9338\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9412\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9323 - val_loss: 0.0797 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9412\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9323\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9456\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9323\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9456 - val_loss: 0.0759 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9323\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9456\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9323\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9465\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9323 - val_loss: 0.0793 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "#用CS优化初始化阈值\n",
    "Models = []\n",
    "for i in range(0,M):\n",
    "    chrom = best_nest[i]\n",
    "    w1 = chrom[:inputnum*hiddennum]\n",
    "    w1 = w1.reshape(inputnum,hiddennum)\n",
    "    b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "    w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "    w2 = w2.reshape(hiddennum,outputnum)\n",
    "    b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "    WB_layer1 = (w1,b1)\n",
    "    WB_layer2 = (w2,b2)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(hiddennum,name='layer1',activation='relu'),\n",
    "        keras.layers.Dense(outputnum,name='layer2')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.build(input_shape=[None,inputnum])\n",
    "    #model.summary()\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                loss='mse',\n",
    "                metrics=['accuracy'])\n",
    "    #model.load_weights('my_model_fun.h5')\n",
    "\n",
    "    layer1 = model.get_layer('layer1')\n",
    "    layer2 = model.get_layer('layer2')\n",
    "    layer1.set_weights(WB_layer1)\n",
    "    layer2.set_weights(WB_layer2)\n",
    "\n",
    "    #训练模型\n",
    "    model.fit(db,epochs=100,validation_data=ds_val,validation_freq=5)\n",
    "    Models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 个模型的预测结果为：\n",
      "\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.8400\n",
      "test loss is : 0.12784\n",
      "accuracy is : 0.84000\n",
      "\n",
      "第 2 个模型的预测结果为：\n",
      "\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1561 - accuracy: 0.8400\n",
      "test loss is : 0.15613\n",
      "accuracy is : 0.84000\n",
      "\n",
      "第 3 个模型的预测结果为：\n",
      "\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.8200\n",
      "test loss is : 0.12542\n",
      "accuracy is : 0.82000\n",
      "\n",
      "第 4 个模型的预测结果为：\n",
      "\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.6200\n",
      "test loss is : 0.17772\n",
      "accuracy is : 0.62000\n",
      "\n",
      "第 5 个模型的预测结果为：\n",
      "\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.8400\n",
      "test loss is : 0.07925\n",
      "accuracy is : 0.84000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 评估模型,不输出预测结果\n",
    "for i in range(0,M):\n",
    "    print('第 %d 个模型的预测结果为：\\r\\n'%(i+1))\n",
    "    loss,accuracy = Models[i].evaluate(ds_val)\n",
    "    print('test loss is : %.5f'%(loss))\n",
    "    print('accuracy is : %.5f\\r\\n'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看模型参数\n",
    "# la1 = model.get_layer('layer1')\n",
    "# la2 = model.get_layer('layer2')\n",
    "# (k1,b1) = la1.get_weights()\n",
    "# (k2,b2) = la2.get_weights()\n",
    "# k1,b1,k2,b2\n",
    "# a=k1.reshape(1,-1).tolist()\n",
    "# b=b1.reshape(1,-1).tolist()\n",
    "# c = a[0] + b[0]\n",
    "# len(k1.reshape(1,-1).tolist()[0] + b1.reshape(1,-1).tolist()[0] + k2.reshape(1,-1).tolist()[0] + b2.reshape(1,-1).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_train = []\n",
    "# 初始化数据权重\n",
    "w_data = np.ones(n_train) / n_train\n",
    "# 初始化模型权重\n",
    "w_model = np.zeros(M)\n",
    "train_y = tf.argmax(Y_onehot,axis=1)  #train_y保存了原始训练集中标签经过onehot编码后的结果\n",
    "k = 3 #分类数量\n",
    "for i in range(M):\n",
    "    \n",
    "    #求第i个弱分类器训练集结果\n",
    "    y_pred_train = Models[i].predict(db)\n",
    "    y_pred_train = tf.argmax(y_pred_train,axis=1)\n",
    "    \n",
    "    #求第i个弱分类器误差\n",
    "    miss = [int(x) for x in (y_pred_train != train_y)]  #不相等则保存1，相等则保存0\n",
    "    error =np.dot(w_data, miss) #累加识别错误的样本权重，得到分类器误差\n",
    "    \n",
    "    #求第i个弱分类器权值，保存到w_model中\n",
    "    #a = 1/2 * log(1-e/e) + log(k-1),当k = 2 时为二分类更新权值公式不用修改，否则为多分类，算法准确率大于1/k即可\n",
    "    #该函数若准确率大于0.5（1-error）则值为正，否则为负值，越大说明模型分类越好\n",
    "    w_model[i] = 0.5 * np.log((1-error)/error) + np.log(k - 1)  \n",
    "    \n",
    "    # 更新数据权重 \n",
    "    #分类结果和真实的结果一致，那么结果是−w_model[m]，是一个负值，\n",
    "    #那么exp(-w_model[m]*train_y[i]*y_pred_train[i]) 结果小于1。也就是说该数据集的样本权重降低。否则该数据样本的权重增高。\n",
    "    #通过这种计算就可以让那些容易分错的样本的权重升高，容易分对的样本权重降低。继续迭代就会导致对难分的样本能分对的模型的权重上涨。\n",
    "    #最终，达到一个强分类器的目的。\n",
    "    #注意，这里只适合二分类【1，-1】\n",
    "    #多分类公式修改 wt = wt-1 * exp(at * (y_true!=y_pred)) \n",
    "    miss1 = np.array(miss)\n",
    "    miss1 = w_model[i]*miss1\n",
    "    for j in range(n_train):\n",
    "        w_data[j] = w_data[j] * np.exp(miss1[j])  #*train_y[i]*y_pred_train[i] #二分类时用这个\n",
    "    \n",
    "    #正则化数据权值\n",
    "    Z = np.sum(w_data)\n",
    "    for j in range(n_train):\n",
    "        w_data[j] /= Z\n",
    "\n",
    "#结果这个模块以后将得到每个模型的权值，保存在w_model中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37686984, 0.2316323 , 0.14973035, 0.05116786, 0.19059966])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#弱分类器权值归一化\n",
    "w_model = np.array(w_model / np.sum(w_model))\n",
    "w_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "        2, 2, 1, 2, 2, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "        2, 2, 1, 2, 2, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 1, 2, 2, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 1, 2, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取弱分类器分类结果\n",
    "models_pre_ds = np.array([tf.argmax(Models[m].predict(ds_val),axis = 1) for m in range(M)])\n",
    "models_pre_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强分类器测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.19059966, 1.        ,\n",
       "       1.        , 1.        , 1.56746949, 1.79910179, 1.94883214,\n",
       "       1.94883214, 1.94883214, 1.19059966, 1.        , 1.79910179,\n",
       "       1.62313016, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.79910179, 1.        , 1.        , 1.71719985,\n",
       "       1.94883214, 1.94883214, 1.71719985, 1.64937144, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.34033001, 1.94883214, 1.94883214, 1.7683677 , 2.        ,\n",
       "       1.94883214, 1.        , 1.94883214, 1.94883214, 1.94883214])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最终的预测\n",
    "result = w_model[0]*models_pre_ds[0]\n",
    "\n",
    "for i in range(1,M):\n",
    "    result += w_model[i] * models_pre_ds[i]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.round(result)\n",
    "result= result.astype(int)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 1, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = tf.argmax(TestY_onehot,axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestfit)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fitness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestFit', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = y_pred - test_y\n",
    "x = list(range(0,len(error)))\n",
    "fig = sns.lineplot(x,error,color=\"b\")\n",
    "plt.xlabel(\"Test Data Num\")\n",
    "plt.ylabel(\"error\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./Error_Num', dpi = 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 8)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bestloss),len(bestfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(0,len(bestloss)))\n",
    "fig = sns.lineplot(x,bestloss,color=\"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"lossness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestLoss', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns主题风格  darkgrid  whitegrid  dark  white  ticks\n",
    "sns.set_style(\"ticks\")  #设置主题风格\n",
    "sns.color_palette(\"hls\",8)  #设置颜色空间种类（几种可用颜色）\n",
    "data=np.random.normal(size=(20,8)) + np.arange(8) /2\n",
    "sns.boxplot(data = data,palette = sns.color_palette(\"hls\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描述两个变量的关系 最好用散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mean,cov = [0,1],[(1,.5),(.5,1)]\n",
    "data = np.random.multivariate_normal(mean,cov,200)\n",
    "df = pd.DataFrame(data,columns=[\"x\",\"y\"])\n",
    "#绘制散点图\n",
    "sns.jointplot(x=\"x\",y=\"y\",data = df,color=\"r\")  #如果点很多，用颜色深度表示数量 kind=\"hex\" ,可以单独传x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移植STM32准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testx = X / X.max().max()\n",
    "Testx = np.array(Testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "aa.append(list(Testx[0]))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sig=model.predict(aa)\n",
    "pre_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(pre_sig,axis=None)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Env.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(load_model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"level_check.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #建立一个测试模型\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(5,), name='dense_xiaoming',\n",
    "          kernel_initializer='zeros',  # 全部初始化为0\n",
    "          bias_initializer='ones'),  # 全部初始化为1\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(shape=(8, 5))  # 创建测试数据\n",
    "y = model(x)\n",
    "layer = model.get_layer('dense_xiaoming')  # 通过层的名字得到层\n",
    "(k, b) = layer.get_weights()  # 查看层的初始化权重值和偏置项\n",
    "print(k)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
