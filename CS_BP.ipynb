{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS_BP预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sc_special\n",
    "import tensorflow as tf \n",
    "from \ttensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers,metrics,layers,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据以及预处理\n",
    "data = pd.read_csv('DATASETS/GY_AIR.csv',sep=',',header=0,usecols=[1,2,3,4,5,6,7])\n",
    "X = data.iloc[:400,1:]\n",
    "Y = data.iloc[:400,0]\n",
    "TestX = data.iloc[400:,1:]\n",
    "TestY = data.iloc[400:,0]\n",
    "\n",
    "inputnum = 6\n",
    "hiddennum = 12\n",
    "outputnum = 3\n",
    "numsum = inputnum*hiddennum+hiddennum+hiddennum*outputnum+outputnum #6*10+10+10*3+3=103\n",
    "bestfit = []\n",
    "bestloss = []\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=3)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.8075"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X,axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "#零均值处理\n",
    "X.iloc[:,0] -= np.mean(X,axis=0)[0]  \n",
    "X.iloc[:,1] -= np.mean(X,axis=0)[1]\n",
    "X.iloc[:,2] -= np.mean(X,axis=0)[2]\n",
    "X.iloc[:,3] -= np.mean(X,axis=0)[3]  \n",
    "X.iloc[:,4] -= np.mean(X,axis=0)[4]\n",
    "X.iloc[:,5] -= np.mean(X,axis=0)[5]\n",
    "#归一化\n",
    "X.iloc[:,0] /= np.max(np.abs(X),axis=0)[0]\n",
    "X.iloc[:,1] /= np.max(np.abs(X),axis=0)[1]\n",
    "X.iloc[:,2] /= np.max(np.abs(X),axis=0)[2]\n",
    "X.iloc[:,3] /= np.max(np.abs(X),axis=0)[3]  \n",
    "X.iloc[:,4] /= np.max(np.abs(X),axis=0)[4]\n",
    "X.iloc[:,5] /= np.max(np.abs(X),axis=0)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#零均值处理\n",
    "TestX.iloc[:,0] -= np.mean(TestX,axis=0)[0]  \n",
    "TestX.iloc[:,1] -= np.mean(TestX,axis=0)[1]\n",
    "TestX.iloc[:,2] -= np.mean(TestX,axis=0)[2]\n",
    "TestX.iloc[:,3] -= np.mean(TestX,axis=0)[3]  \n",
    "TestX.iloc[:,4] -= np.mean(TestX,axis=0)[4]\n",
    "TestX.iloc[:,5] -= np.mean(TestX,axis=0)[5]\n",
    "#归一化\n",
    "TestX.iloc[:,0] /= np.max(np.abs(TestX),axis=0)[0]\n",
    "TestX.iloc[:,1] /= np.max(np.abs(TestX),axis=0)[1]\n",
    "TestX.iloc[:,2] /= np.max(np.abs(TestX),axis=0)[2]\n",
    "TestX.iloc[:,3] /= np.max(np.abs(TestX),axis=0)[3]  \n",
    "TestX.iloc[:,4] /= np.max(np.abs(TestX),axis=0)[4]\n",
    "TestX.iloc[:,5] /= np.max(np.abs(TestX),axis=0)[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 6) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 32\n",
    "db = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((TestX,TestY))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape,sample[1].shape)\n",
    "TestY_onehot = tf.one_hot(TestY,depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#n：布谷鸟数  m：布谷鸟的维度\n",
    "def cuckoo_search(n, m, lower_boundary, upper_boundary, iter_num = 20,pa = 0.25, beta = 1.5, step_size = 0.1):\n",
    "    \"\"\"\n",
    "    Cuckoo search function\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        iter_num: Number of iterations (default: 100) \n",
    "        pa: Possibility that hosts find cuckoos' eggs (default: 0.25)\n",
    "        beta: Power law index (note: 1 < beta < 2) (default: 1.5)\n",
    "        step_size:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        The best solution and its value\n",
    "    \"\"\"\n",
    "    # get initial nests' locations \n",
    "    nests = generate_nests(n, m, lower_boundary, upper_boundary)\n",
    "    fitness,lossness,_ = calc_fitness( nests,0.5) #包含所有的适应度  用列表存储\n",
    "    \n",
    "    # get the best nest and record it\n",
    "    best_nest_index = np.argmin(lossness)\n",
    "    best_fitness = lossness[best_nest_index]\n",
    "    best_nest = nests[best_nest_index].copy()\n",
    "    best_acc = 0\n",
    "    bestfit.append(best_fitness) #全局变量，保存每代最佳适应度值\n",
    "    \n",
    "\n",
    "    print('\\r\\n BEST_TWO_LOSSNESS IS %.2f : \\r\\n',best_fitness)\n",
    "\n",
    "    for _ in range(iter_num):\n",
    "        nests = update_nests(lower_boundary, upper_boundary, nests, best_nest, lossness, step_size,best_fitness)\n",
    "        nests = abandon_nests(nests, lower_boundary, upper_boundary, pa)\n",
    "        print('\\r\\n*******************************************************一轮迭代后开始计算适应度*************************************************************\\r\\n')\n",
    "        fitness,lossness,_ = calc_fitness( nests,best_fitness)\n",
    "        print('\\r\\n*****************************************************************结束************************************************************\\r\\n')\n",
    "        \n",
    "        \n",
    "        min_loss_index = np.argmin(lossness)\n",
    "        min_loss = lossness[min_loss_index]\n",
    "        min_loss_fit = fitness[min_loss_index]\n",
    "        min_nestloss = nests[min_loss_index]\n",
    "        LossArr.append(min_loss)\n",
    "            \n",
    "        if min_loss < best_fitness  : #and  min_loss_fit > best_two_fitness\n",
    "            best_nest = min_nestloss\n",
    "            best_fitness = min_loss\n",
    "            best_acc = min_loss_fit\n",
    "            print('\\r\\n******')\n",
    "            print('\\r\\n BEST_LOSSNESS IS %.2f : \\r\\n',best_fitness)\n",
    "            print('\\r\\n******\\r\\n')\n",
    "\n",
    "    return (best_nest, best_fitness,best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nests(n, m, lower_boundary, upper_boundary):\n",
    "    \"\"\"\n",
    "    Generate the nests' locations\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of nests\n",
    "        m: Number of dimensions\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "    Output:\n",
    "        generated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    nests = np.empty((n, m))\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        nests[each_nest] = lower_boundary + np.array([np.random.rand() for _ in range(m)]) * (upper_boundary - lower_boundary)\n",
    "\n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nests(lower_boundary, upper_boundary, nests, best_nest, lossness, step_coefficient,bestfitness):\n",
    "    \"\"\"\n",
    "    This function is to get new nests' locations and use new better one to replace the old nest\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        fit_func: User defined fitness evaluative function\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        nests: Old nests' locations \n",
    "        best_nest: Nest with best fitness\n",
    "        fitness: Every nest's fitness\n",
    "        step_coefficient:  Step size scaling factor related to the problem's scale (default: 0.1)\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    # 莱维飞行生成步长：较长时间的短步长和较短时间的长步长\n",
    "    #生成的步长的shape也是n*m，保证所有元素得到更新\n",
    "    #这个步长通过step_size来控制大小\n",
    "    steps = levy_flight(n, m, 1.5)\n",
    "    new_nests = nests.copy()\n",
    "\n",
    "    for each_nest in range(n):\n",
    "        # coefficient 0.01 is to avoid levy flights becoming too aggresive\n",
    "        # and (nest[each_nest] - best_nest) 保留了最佳nest，但会导致局部最优\n",
    "        step_size = step_coefficient * steps[each_nest] # * (nests[each_nest] - best_nest)\n",
    "        step_direction = np.random.rand(m) #0-1均匀概率分布生成方向\n",
    "        #新的布谷鸟在原来的基础上加上步长和方向\n",
    "        new_nests[each_nest] += step_size * step_direction  \n",
    "        # apply boundary condtions\n",
    "        new_nests[each_nest][new_nests[each_nest] < lower_boundary] = lower_boundary[new_nests[each_nest] < lower_boundary]\n",
    "        new_nests[each_nest][new_nests[each_nest] > upper_boundary] = upper_boundary[new_nests[each_nest] > upper_boundary]\n",
    "\n",
    "    new_fitness,new_losses,new_nests = calc_fitness(new_nests,bestfitness)\n",
    "    #适应度更好的才更新过去\n",
    "    \n",
    "    nests[new_losses < lossness] = new_nests[new_losses < lossness] \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abandon_nests(nests, lower_boundary, upper_boundary, pa):\n",
    "    \"\"\"\n",
    "    Some cuckoos' eggs are found by hosts, and are abandoned.So cuckoos need to find new nests.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        nests: Current nests' locations\n",
    "        lower_boundary: Lower bounary (example: lower_boundary = (-2, -2, -2))\n",
    "        upper_boundary: Upper boundary (example: upper_boundary = (2, 2, 2))\n",
    "        pa: Possibility that hosts find cuckoos' eggs\n",
    "    Output:\n",
    "        Updated nests' locations\n",
    "    \"\"\"\n",
    "    lower_boundary = np.array(lower_boundary)\n",
    "    upper_boundary = np.array(upper_boundary)\n",
    "    n, m = nests.shape\n",
    "    for each_nest in range(n):  \n",
    "        #pa概率抛弃，抛弃后重新生成\n",
    "        if (np.random.rand() < pa):\n",
    "            #局部随机行走生成步长\n",
    "            #随机两个种群相差*一个0-1的随机数\n",
    "            step_size = np.random.rand() * (nests[np.random.randint(0, n)] - nests[np.random.randint(0, n)])\n",
    "            nests[each_nest] += step_size\n",
    "            # apply boundary condtions\n",
    "            nests[each_nest][nests[each_nest] < lower_boundary] = lower_boundary[nests[each_nest] < lower_boundary]\n",
    "            nests[each_nest][nests[each_nest] > upper_boundary] = upper_boundary[nests[each_nest] > upper_boundary]\n",
    "    \n",
    "    return nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_flight(n, m, beta):\n",
    "    \"\"\"\n",
    "    This function implements Levy's flight.\n",
    "    ---------------------------------------------------\n",
    "    Input parameters:\n",
    "        n: Number of steps \n",
    "        m: Number of dimensions\n",
    "        beta: Power law index (note: 1 < beta < 2)\n",
    "    Output:\n",
    "        'n' levy steps in 'm' dimension\n",
    "    \"\"\"\n",
    "    sigma_u = (sc_special.gamma(1+beta)*np.sin(np.pi*beta/2)/(sc_special.gamma((1+beta)/2)*beta*(2**((beta-1)/2))))**(1/beta)\n",
    "    sigma_v = 1\n",
    "\n",
    "    u =  np.random.normal(0, sigma_u, (n, m))\n",
    "    v = np.random.normal(0, sigma_v, (n, m))\n",
    "\n",
    "    steps = u/((np.abs(v))**(1/beta))\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(nests,best_nest):\n",
    "    \n",
    "    n, m = nests.shape\n",
    "    fitness = np.empty(n)\n",
    "    lossness = np.empty(n)\n",
    "    new_nests = nests\n",
    "    for Sig_nest in range(n):\n",
    "        chrom = nests[Sig_nest]\n",
    "        #分解模型参数\n",
    "        w1 = chrom[:inputnum*hiddennum]\n",
    "        w1 = w1.reshape(inputnum,hiddennum)\n",
    "        b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "        w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "        w2 = w2.reshape(hiddennum,outputnum)\n",
    "        b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "        WB_l1 = (w1,b1)\n",
    "        WB_l2 = (w2,b2)\n",
    "        #创建模型，并赋予参数\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(hiddennum,activation='relu',name='l1'),\n",
    "            keras.layers.Dense(outputnum,name='l2')\n",
    "        ])\n",
    "        model.build(input_shape=[None,inputnum])\n",
    "        \n",
    "        #model.summary()\n",
    "        model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                    loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        layer1 = model.get_layer('l1')\n",
    "        layer2 = model.get_layer('l2')\n",
    "        layer1.set_weights(WB_l1)\n",
    "        layer2.set_weights(WB_l2)\n",
    "        \n",
    "        #训练模型\n",
    "        #model.fit(db,epochs=1,validation_data=ds_val,validation_freq=1)\n",
    "        model.fit(db,epochs=1,validation_data=ds_val,validation_freq=1)\n",
    "        loss,acc = model.evaluate(db)  #这里是用验证集评估，其实应该用测试集吧 evaluate产生两个结果，前面是损失，后面是准确率\n",
    "        lossness[Sig_nest] = loss\n",
    "        fitness[Sig_nest] = acc  #将模型评估正确率作为适应度返回\n",
    "        \n",
    "        (k1,y1) = layer1.get_weights()\n",
    "        (k2,y2) = layer2.get_weights()\n",
    "        c=k1.reshape(1,-1).tolist()[0] + b1.reshape(1,-1).tolist()[0] + k2.reshape(1,-1).tolist()[0] + b2.reshape(1,-1).tolist()[0]\n",
    "        new_nests[Sig_nest] = c\n",
    "        \n",
    "        \n",
    "#         if(acc>bestfitness): #在计算适应度的过程当中，发现有更好的适应度就把参数保存\n",
    "#             #model.save_weights('my_model_fun.h5')\n",
    "#             bestfitness = acc\n",
    "    return fitness,lossness,new_nests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 26ms/step - loss: 37.1289 - accuracy: 0.3737 - val_loss: 31.3298 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 20.5796 - accuracy: 0.3550\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 49.8170 - accuracy: 0.7068 - val_loss: 52.7687 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 36.4502 - accuracy: 0.6925\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 21.8532 - accuracy: 0.1409 - val_loss: 18.6817 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.4642 - accuracy: 0.1575\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 121.8126 - accuracy: 0.3407 - val_loss: 90.1285 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 85.6624 - accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 54.6328 - accuracy: 0.1888 - val_loss: 36.7430 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 34.5576 - accuracy: 0.2075\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 29.8428 - accuracy: 0.4856 - val_loss: 40.4741 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.1922 - accuracy: 0.4700\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 35.1464 - accuracy: 0.1527 - val_loss: 37.3659 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 26.6285 - accuracy: 0.1475\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 21.0082 - accuracy: 0.5839 - val_loss: 13.7350 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.6189 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 37.3456 - accuracy: 0.0563 - val_loss: 25.5304 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 22.3813 - accuracy: 0.1725\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 65.1654 - accuracy: 0.3364 - val_loss: 53.4491 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 47.4360 - accuracy: 0.3375\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 22.4362 - accuracy: 0.0745 - val_loss: 19.1781 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 14.5563 - accuracy: 0.1275\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 88.7162 - accuracy: 0.2625 - val_loss: 83.2870 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 915us/step - loss: 69.6671 - accuracy: 0.2350\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 170.7417 - accuracy: 0.0633 - val_loss: 157.9126 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 121.6838 - accuracy: 0.0575\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 13.5185 - accuracy: 0.5359 - val_loss: 6.8843 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.3475 - accuracy: 0.5150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 100.5573 - accuracy: 0.3780 - val_loss: 89.2928 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 80.3015 - accuracy: 0.3650\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 140.6692 - accuracy: 0.0219 - val_loss: 110.3394 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 96.4973 - accuracy: 0.0175\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 40.4138 - accuracy: 0.0972 - val_loss: 33.1863 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.0611 - accuracy: 0.0250\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 52.5868 - accuracy: 0.5982 - val_loss: 32.4920 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 30.2351 - accuracy: 0.5625\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 56.9754 - accuracy: 0.0381 - val_loss: 44.7676 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 36.7388 - accuracy: 0.0550\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 27.7919 - accuracy: 0.5936 - val_loss: 32.6332 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 16.9817 - accuracy: 0.5900\n",
      "\n",
      " BEST_TWO_LOSSNESS IS %.2f : \n",
      " 6.3474531173706055\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 26.4309 - accuracy: 0.3703 - val_loss: 19.1240 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.6149 - accuracy: 0.3500\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 52.2120 - accuracy: 0.6674 - val_loss: 50.8169 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 37.2084 - accuracy: 0.6300\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 9.7714 - accuracy: 0.1389 - val_loss: 8.1575 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1549 - accuracy: 0.2275\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 70.9986 - accuracy: 0.2997 - val_loss: 47.6434 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 45.7542 - accuracy: 0.3275\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 64.2061 - accuracy: 0.1975 - val_loss: 43.5345 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 43.6362 - accuracy: 0.1800\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 14.4330 - accuracy: 0.4864 - val_loss: 22.2057 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.4980 - accuracy: 0.4425\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 42.9666 - accuracy: 0.1399 - val_loss: 39.9769 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 33.5360 - accuracy: 0.1325\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 34.1388 - accuracy: 0.6040 - val_loss: 22.3422 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.7193 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 20.5267 - accuracy: 0.3144 - val_loss: 18.5089 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.9883 - accuracy: 0.3900\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 38.5488 - accuracy: 0.3729 - val_loss: 34.2384 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 998us/step - loss: 27.7269 - accuracy: 0.3500\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 23.9521 - accuracy: 0.0288 - val_loss: 14.4432 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 14.4360 - accuracy: 0.0650\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 57.9913 - accuracy: 0.1861 - val_loss: 51.1179 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 44.3408 - accuracy: 0.1875\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 109.2574 - accuracy: 0.0914 - val_loss: 97.0498 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 73.4886 - accuracy: 0.0925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 24.1730 - accuracy: 0.6698 - val_loss: 8.4845 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.5792 - accuracy: 0.6525\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 71.0799 - accuracy: 0.3806 - val_loss: 61.6844 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 52.4794 - accuracy: 0.3800\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 126.0971 - accuracy: 0.0124 - val_loss: 95.3404 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 87.6393 - accuracy: 0.0175\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 33.3689 - accuracy: 0.1854 - val_loss: 25.1440 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.4551 - accuracy: 0.1525\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 45.3832 - accuracy: 0.6335 - val_loss: 25.3209 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.6424 - accuracy: 0.6025\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 40.4447 - accuracy: 0.1154 - val_loss: 38.3716 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 27.8083 - accuracy: 0.1550\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 16.0359 - accuracy: 0.4949 - val_loss: 20.9616 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 9.6610 - accuracy: 0.3325\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 16.1750 - accuracy: 0.3467 - val_loss: 10.3139 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 917us/step - loss: 6.7729 - accuracy: 0.3425\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 39.6504 - accuracy: 0.7251 - val_loss: 38.7801 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.9419 - accuracy: 0.6900\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 7.2543 - accuracy: 0.2066 - val_loss: 5.4147 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7430 - accuracy: 0.3375\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 51.5022 - accuracy: 0.2527 - val_loss: 31.4882 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 29.6148 - accuracy: 0.3125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 36.6421 - accuracy: 0.1968 - val_loss: 20.5324 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.1124 - accuracy: 0.1900\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 8.5296 - accuracy: 0.4283 - val_loss: 14.3276 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6676 - accuracy: 0.4125\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 109.4954 - accuracy: 0.1674 - val_loss: 127.8099 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 90.5705 - accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 14.0902 - accuracy: 0.6046 - val_loss: 8.6108 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.8117 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 13.6732 - accuracy: 0.4192 - val_loss: 12.8096 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2470 - accuracy: 0.4750\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 30.1319 - accuracy: 0.3753 - val_loss: 26.0542 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 21.2722 - accuracy: 0.3450\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 16.1075 - accuracy: 0.0634 - val_loss: 8.2510 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.5125 - accuracy: 0.1375\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 48.5668 - accuracy: 0.1899 - val_loss: 40.1946 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.9109 - accuracy: 0.2225\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 77.5852 - accuracy: 0.1199 - val_loss: 64.3031 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 50.3766 - accuracy: 0.1200\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 7.5521 - accuracy: 0.5365 - val_loss: 4.5158 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.2315 - accuracy: 0.4700\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 55.1897 - accuracy: 0.3940 - val_loss: 47.4060 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 42.0133 - accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 91.6806 - accuracy: 0.0138 - val_loss: 64.9873 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 62.8167 - accuracy: 0.0175\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 22.8092 - accuracy: 0.1280 - val_loss: 18.6326 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.0284 - accuracy: 0.1200\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 30.0648 - accuracy: 0.5690 - val_loss: 13.9288 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 15.8690 - accuracy: 0.6025\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 26.9126 - accuracy: 0.0704 - val_loss: 23.6278 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.0986 - accuracy: 0.1100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 9.8478 - accuracy: 0.4681 - val_loss: 12.6611 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1916 - accuracy: 0.3250\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 3.2314765453338623\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 16.7257 - accuracy: 0.3432 - val_loss: 10.9765 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 6.6074 - accuracy: 0.2625\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 35.9172 - accuracy: 0.7259 - val_loss: 33.9884 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.7247 - accuracy: 0.6925\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 5.1246 - accuracy: 0.1957 - val_loss: 5.3033 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 2.5024 - accuracy: 0.3925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 33.5806 - accuracy: 0.5477 - val_loss: 19.1385 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 17.6207 - accuracy: 0.5250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 46.4251 - accuracy: 0.2735 - val_loss: 26.8942 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 30.2553 - accuracy: 0.1975\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 8.2923 - accuracy: 0.2377 - val_loss: 12.3509 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.0828 - accuracy: 0.3525\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 78.7330 - accuracy: 0.0141 - val_loss: 79.4449 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 62.7650 - accuracy: 0.0300\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 7.1239 - accuracy: 0.5861 - val_loss: 3.4885 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7544 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 16.6592 - accuracy: 0.1775 - val_loss: 13.6458 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.4190 - accuracy: 0.2525\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 39.6363 - accuracy: 0.2779 - val_loss: 32.9417 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 28.5524 - accuracy: 0.2950\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 15.0000 - accuracy: 0.0331 - val_loss: 5.6264 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.0732 - accuracy: 0.0875\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 36.4328 - accuracy: 0.4812 - val_loss: 24.3189 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.7085 - accuracy: 0.4700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 64.1791 - accuracy: 0.1891 - val_loss: 47.3325 - val_accuracy: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 41.0721 - accuracy: 0.1625\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.8117 - accuracy: 0.6356 - val_loss: 5.3999 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.7599 - accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 87.3549 - accuracy: 0.4064 - val_loss: 63.0399 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 63.7843 - accuracy: 0.3875\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 73.1259 - accuracy: 0.0191 - val_loss: 51.5006 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 45.9584 - accuracy: 0.0175\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 11.3601 - accuracy: 0.1419 - val_loss: 9.0331 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6052 - accuracy: 0.1650\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 16.1857 - accuracy: 0.3365 - val_loss: 9.0066 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 7.2148 - accuracy: 0.2825\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 24.2166 - accuracy: 0.3914 - val_loss: 16.8730 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.0720 - accuracy: 0.3725\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.7439 - accuracy: 0.4469 - val_loss: 7.4004 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.8280 - accuracy: 0.4775\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 9.0250 - accuracy: 0.2787 - val_loss: 5.4729 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1918 - accuracy: 0.2300\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 24.3008 - accuracy: 0.7284 - val_loss: 23.1959 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 16.2330 - accuracy: 0.6525\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.5975 - accuracy: 0.3367 - val_loss: 3.1253 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5723 - accuracy: 0.5725\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 19.0399 - accuracy: 0.4977 - val_loss: 11.1868 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.0950 - accuracy: 0.5100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 21.5501 - accuracy: 0.2072 - val_loss: 11.5151 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.5674 - accuracy: 0.1950\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 6.1650 - accuracy: 0.4603 - val_loss: 9.9757 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.1464 - accuracy: 0.4425\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 64.8592 - accuracy: 0.0178 - val_loss: 68.1517 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 54.1237 - accuracy: 0.0350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2774 - accuracy: 0.6190 - val_loss: 2.2827 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0829 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.6487 - accuracy: 0.4303 - val_loss: 9.9221 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7889 - accuracy: 0.5675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 24.0594 - accuracy: 0.3266 - val_loss: 19.3760 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.1436 - accuracy: 0.3500\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 9.0125 - accuracy: 0.0625 - val_loss: 3.6596 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0485 - accuracy: 0.2225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 26.7953 - accuracy: 0.4145 - val_loss: 16.3418 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.9500 - accuracy: 0.3725\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 79.6270 - accuracy: 0.2864 - val_loss: 54.2017 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 52.1719 - accuracy: 0.2250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 19.5622 - accuracy: 0.0210 - val_loss: 14.4052 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.2963 - accuracy: 0.0625\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 71.7707 - accuracy: 0.1800 - val_loss: 60.0863 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 46.1029 - accuracy: 0.2225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 113.4592 - accuracy: 0.0064 - val_loss: 85.9768 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 78.7626 - accuracy: 0.0125\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 15.2849 - accuracy: 0.3131 - val_loss: 9.4076 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 7.2450 - accuracy: 0.3025\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 7.7249 - accuracy: 0.4738 - val_loss: 4.6571 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0727 - accuracy: 0.4375\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 16.8008 - accuracy: 0.3496 - val_loss: 9.8196 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.7372 - accuracy: 0.3625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9524 - accuracy: 0.4341 - val_loss: 4.0661 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3631 - accuracy: 0.4875\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 1.5723295211791992\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.8237 - accuracy: 0.3691 - val_loss: 7.3674 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0281 - accuracy: 0.4050\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 19.5221 - accuracy: 0.3573 - val_loss: 12.6223 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 10.4090 - accuracy: 0.4575\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 5.4805 - accuracy: 0.5812 - val_loss: 3.9459 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1101 - accuracy: 0.5025\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 11.0582 - accuracy: 0.3686 - val_loss: 10.7728 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 7.5431 - accuracy: 0.3800\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 18.1015 - accuracy: 0.2195 - val_loss: 11.2977 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.7676 - accuracy: 0.2375\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 5.3078 - accuracy: 0.4204 - val_loss: 9.1122 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6955 - accuracy: 0.4700\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 69.6441 - accuracy: 0.0488 - val_loss: 73.3308 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 58.6408 - accuracy: 0.0325\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 5.0254 - accuracy: 0.5553 - val_loss: 2.8112 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 2.7357 - accuracy: 0.5125\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 33.0164 - accuracy: 0.3818 - val_loss: 23.4251 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 16.0400 - accuracy: 0.5525\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 59.6293 - accuracy: 0.3567 - val_loss: 40.7851 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 40.5368 - accuracy: 0.3750\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 6.0213 - accuracy: 0.0682 - val_loss: 3.9028 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 943us/step - loss: 2.6430 - accuracy: 0.2375\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 6.3488 - accuracy: 0.2164 - val_loss: 5.1436 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.5696 - accuracy: 0.1625\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 139.4040 - accuracy: 0.5795 - val_loss: 99.6298 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 917us/step - loss: 100.0418 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 10.4198 - accuracy: 0.0700 - val_loss: 8.5312 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.2725 - accuracy: 0.2150\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 50.3986 - accuracy: 0.2680 - val_loss: 62.1695 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 34.6756 - accuracy: 0.3000\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 59.3195 - accuracy: 0.0213 - val_loss: 43.8849 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.0202 - accuracy: 0.0525\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 19.5498 - accuracy: 0.4423 - val_loss: 10.3869 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 9.5026 - accuracy: 0.3975\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.3938 - accuracy: 0.5364 - val_loss: 4.2394 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5591 - accuracy: 0.6575\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 13.7589 - accuracy: 0.2474 - val_loss: 7.5755 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9093 - accuracy: 0.3000\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 7.4974 - accuracy: 0.5533 - val_loss: 8.2975 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3569 - accuracy: 0.4225\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.4416 - accuracy: 0.2723 - val_loss: 2.8581 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6570 - accuracy: 0.2775\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 10.7711 - accuracy: 0.4143 - val_loss: 7.5191 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6243 - accuracy: 0.6250\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 124.6685 - accuracy: 0.6053 - val_loss: 130.1974 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 97.8615 - accuracy: 0.6175\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.9384 - accuracy: 0.3828 - val_loss: 8.4286 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 4.9739 - accuracy: 0.3575\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 12.2416 - accuracy: 0.2369 - val_loss: 8.9163 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 6.2865 - accuracy: 0.2375\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.6375 - accuracy: 0.5222 - val_loss: 6.8842 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7153 - accuracy: 0.5825\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 109.6285 - accuracy: 0.0229 - val_loss: 101.0524 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 78.1049 - accuracy: 0.0225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.4946 - accuracy: 0.6107 - val_loss: 1.4913 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0105 - accuracy: 0.6425\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 4.5733 - accuracy: 0.5627 - val_loss: 7.6976 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.2928 - accuracy: 0.6175\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 17.5872 - accuracy: 0.3747 - val_loss: 14.1259 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.9961 - accuracy: 0.3425\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 12.1088 - accuracy: 0.4224 - val_loss: 15.7887 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 8.1481 - accuracy: 0.4500\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6888 - accuracy: 0.1913 - val_loss: 3.6368 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 992us/step - loss: 2.3758 - accuracy: 0.1775\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 56.0690 - accuracy: 0.3074 - val_loss: 35.7798 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 34.8902 - accuracy: 0.2200\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 5.5853 - accuracy: 0.1479 - val_loss: 5.5335 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4330 - accuracy: 0.2500\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 57.3587 - accuracy: 0.6236 - val_loss: 61.3432 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 33.6691 - accuracy: 0.5900\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 40.0459 - accuracy: 0.0487 - val_loss: 32.2549 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 21.6873 - accuracy: 0.0700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 8.4508 - accuracy: 0.2816 - val_loss: 5.1877 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 4.1408 - accuracy: 0.2575\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 1.8569 - accuracy: 0.6377 - val_loss: 3.4733 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1395 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 8.9316 - accuracy: 0.3092 - val_loss: 4.9387 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7980 - accuracy: 0.3375\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2274 - accuracy: 0.4757 - val_loss: 2.4602 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5421 - accuracy: 0.5150\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 1.0104753971099854\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 5.2876 - accuracy: 0.4160 - val_loss: 3.3747 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.1545 - accuracy: 0.4175\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 6.3357 - accuracy: 0.7429 - val_loss: 5.5708 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6341 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 67.6445 - accuracy: 0.5513 - val_loss: 70.8794 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 48.2366 - accuracy: 0.4925\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 20.2022 - accuracy: 0.5839 - val_loss: 14.8580 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 915us/step - loss: 8.1148 - accuracy: 0.5175\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 7.0445 - accuracy: 0.5176 - val_loss: 8.3161 - val_accuracy: 0.0800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 4.1864 - accuracy: 0.1750\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 25.3182 - accuracy: 0.3565 - val_loss: 24.5742 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.6547 - accuracy: 0.3425\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 74.2313 - accuracy: 0.0196 - val_loss: 63.1240 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 53.4726 - accuracy: 0.0175\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 9.6215 - accuracy: 0.5484 - val_loss: 4.1772 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.5166 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 7.1380 - accuracy: 0.4030 - val_loss: 6.4580 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.3594 - accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 11.2021 - accuracy: 0.3885 - val_loss: 9.3753 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 896us/step - loss: 7.1048 - accuracy: 0.4250\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.4438 - accuracy: 0.4991 - val_loss: 9.1600 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.2180 - accuracy: 0.4950\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 4.1091 - accuracy: 0.5915 - val_loss: 3.2185 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 984us/step - loss: 2.3798 - accuracy: 0.5225\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 29.5355 - accuracy: 0.2408 - val_loss: 19.0690 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.4070 - accuracy: 0.2475\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 6.9335 - accuracy: 0.1156 - val_loss: 5.9598 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2077 - accuracy: 0.2150\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 31.8586 - accuracy: 0.5931 - val_loss: 32.0502 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.3605 - accuracy: 0.5750\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 41.9291 - accuracy: 0.0838 - val_loss: 31.1064 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 24.5760 - accuracy: 0.1100\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 20.7346 - accuracy: 0.1413 - val_loss: 12.7142 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 11.8258 - accuracy: 0.1525\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 46.1510 - accuracy: 0.3995 - val_loss: 37.7192 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 29.5416 - accuracy: 0.3825\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 14.5288 - accuracy: 0.0391 - val_loss: 7.1669 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 7.4203 - accuracy: 0.0900\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.8945 - accuracy: 0.3412 - val_loss: 3.1938 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6596 - accuracy: 0.3425\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.0273 - accuracy: 0.2689 - val_loss: 2.0644 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 998us/step - loss: 1.2361 - accuracy: 0.4800\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 14.2827 - accuracy: 0.3919 - val_loss: 5.0798 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.5618 - accuracy: 0.3450\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 49.3865 - accuracy: 0.5106 - val_loss: 51.8364 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 36.7657 - accuracy: 0.4475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.9120 - accuracy: 0.3491 - val_loss: 7.0827 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4208 - accuracy: 0.3525\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 45.8440 - accuracy: 0.0182 - val_loss: 40.1905 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.3995 - accuracy: 0.0025\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.6995 - accuracy: 0.6128 - val_loss: 5.1286 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.1012 - accuracy: 0.6100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 52.3790 - accuracy: 0.0110 - val_loss: 39.1446 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 33.7823 - accuracy: 0.0175\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.3357 - accuracy: 0.6410 - val_loss: 1.3784 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 936us/step - loss: 0.6271 - accuracy: 0.6225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.8348 - accuracy: 0.5805 - val_loss: 5.5107 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2526 - accuracy: 0.6425\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 7.9687 - accuracy: 0.4010 - val_loss: 6.5007 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9236 - accuracy: 0.5025\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.9011 - accuracy: 0.5005 - val_loss: 6.1593 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7891 - accuracy: 0.5150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.4917 - accuracy: 0.1704 - val_loss: 3.1305 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8021 - accuracy: 0.2625\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 17.4306 - accuracy: 0.2475 - val_loss: 10.6944 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.6468 - accuracy: 0.2600\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 2.8882 - accuracy: 0.2083 - val_loss: 3.4116 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 1.5938 - accuracy: 0.4450\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 21.7261 - accuracy: 0.6053 - val_loss: 19.5886 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.6876 - accuracy: 0.5500\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 24.0623 - accuracy: 0.0722 - val_loss: 24.7280 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.7237 - accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.8671 - accuracy: 0.2946 - val_loss: 3.0664 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.5081 - accuracy: 0.2050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.0407 - accuracy: 0.6379 - val_loss: 2.3517 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.8829 - accuracy: 0.6600\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 5.4013 - accuracy: 0.3456 - val_loss: 3.7928 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9527 - accuracy: 0.3775\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.5749 - accuracy: 0.4685 - val_loss: 1.8066 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.0837 - accuracy: 0.5500\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.627088189125061\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 13.4643 - accuracy: 0.1619 - val_loss: 5.1823 - val_accuracy: 0.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1000us/step - loss: 4.1865 - accuracy: 0.5150\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 20.0722 - accuracy: 0.3924 - val_loss: 8.5168 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3352 - accuracy: 0.4100\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 47.1518 - accuracy: 0.5257 - val_loss: 44.8217 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 32.6739 - accuracy: 0.4675\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 13.2119 - accuracy: 0.5765 - val_loss: 8.8867 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4713 - accuracy: 0.5400\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 17.2694 - accuracy: 0.1965 - val_loss: 18.0870 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.5094 - accuracy: 0.2350\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 8.5544 - accuracy: 0.1908 - val_loss: 8.8328 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9961 - accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 32.8675 - accuracy: 0.0192 - val_loss: 25.4333 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 986us/step - loss: 19.7210 - accuracy: 0.0250\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 1.7776 - accuracy: 0.4144 - val_loss: 2.3280 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8021 - accuracy: 0.4450\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.6728 - accuracy: 0.5168 - val_loss: 5.0432 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0756 - accuracy: 0.6500\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.5267 - accuracy: 0.3855 - val_loss: 2.9871 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0178 - accuracy: 0.6100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 13.6175 - accuracy: 0.3865 - val_loss: 9.3375 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6350 - accuracy: 0.4125\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.7727 - accuracy: 0.3033 - val_loss: 2.6455 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3789 - accuracy: 0.4325\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 6.5254 - accuracy: 0.3259 - val_loss: 5.0039 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.7878 - accuracy: 0.5225\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 15.8318 - accuracy: 0.3423 - val_loss: 13.8378 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.7716 - accuracy: 0.2775\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 17.9573 - accuracy: 0.4747 - val_loss: 15.4446 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.1510 - accuracy: 0.4850\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 15.7288 - accuracy: 0.1667 - val_loss: 18.4879 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.5737 - accuracy: 0.3550\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.9815 - accuracy: 0.3339 - val_loss: 5.1929 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.4355 - accuracy: 0.3325\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 2.8808 - accuracy: 0.4093 - val_loss: 2.4078 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.6363 - accuracy: 0.4825\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 14.9118 - accuracy: 0.3481 - val_loss: 7.6582 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 6.1778 - accuracy: 0.3025\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.5598 - accuracy: 0.3672 - val_loss: 1.4934 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9516 - accuracy: 0.5200\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1579 - accuracy: 0.4005 - val_loss: 1.7087 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 943us/step - loss: 0.8227 - accuracy: 0.5675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.4408 - accuracy: 0.5471 - val_loss: 2.6383 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3395 - accuracy: 0.6350\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 35.3452 - accuracy: 0.4745 - val_loss: 32.1796 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 24.2857 - accuracy: 0.3650\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.1557 - accuracy: 0.3619 - val_loss: 5.9814 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4470 - accuracy: 0.3975\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 10.3850 - accuracy: 0.2259 - val_loss: 10.8916 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 5.1004 - accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2201 - accuracy: 0.6001 - val_loss: 4.1927 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6567 - accuracy: 0.6150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 18.8229 - accuracy: 0.0344 - val_loss: 17.3276 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.7630 - accuracy: 0.1225\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 0.7458 - accuracy: 0.6825 - val_loss: 1.3334 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.5875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.9765 - accuracy: 0.6458 - val_loss: 3.7516 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3690 - accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.0302 - accuracy: 0.5842 - val_loss: 2.4189 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3684 - accuracy: 0.6325\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.5630 - accuracy: 0.4959 - val_loss: 4.5657 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7453 - accuracy: 0.5850\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1972 - accuracy: 0.4056 - val_loss: 2.2159 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 998us/step - loss: 1.0599 - accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.7489 - accuracy: 0.5406 - val_loss: 3.7733 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.5529 - accuracy: 0.6950\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.5322 - accuracy: 0.2964 - val_loss: 2.1189 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.1559 - accuracy: 0.5425\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 10.3567 - accuracy: 0.5130 - val_loss: 10.2087 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2925 - accuracy: 0.4950\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 233.8653 - accuracy: 0.4028 - val_loss: 247.7748 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 169.6940 - accuracy: 0.3450\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.7912 - accuracy: 0.2686 - val_loss: 2.0794 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 915us/step - loss: 1.5968 - accuracy: 0.2050\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8897 - accuracy: 0.6585 - val_loss: 1.9448 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.6825\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 3.1520 - accuracy: 0.3446 - val_loss: 3.6592 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.0018 - accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0061 - accuracy: 0.4292 - val_loss: 1.0779 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.5625\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.45604079961776733\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.8940 - accuracy: 0.5234 - val_loss: 2.3784 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2418 - accuracy: 0.3675\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.1535 - accuracy: 0.7164 - val_loss: 2.2378 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0225 - accuracy: 0.6450\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 51.1458 - accuracy: 0.6183 - val_loss: 41.4908 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 35.1204 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 9.7997 - accuracy: 0.0018 - val_loss: 6.8767 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 917us/step - loss: 3.5163 - accuracy: 0.0325\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.6767 - accuracy: 0.5784 - val_loss: 6.6655 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 3.5000 - accuracy: 0.4950\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 4.2916 - accuracy: 0.5446 - val_loss: 4.9409 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 879us/step - loss: 2.1657 - accuracy: 0.5200\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 11.1247 - accuracy: 0.4719 - val_loss: 17.4226 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.2037 - accuracy: 0.3475\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 3.5527 - accuracy: 0.2268 - val_loss: 2.2014 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5350 - accuracy: 0.2950\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 18.9083 - accuracy: 0.3827 - val_loss: 10.1613 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.3370 - accuracy: 0.4950\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.2917 - accuracy: 0.5884 - val_loss: 2.7409 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5908 - accuracy: 0.4550\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 9.0696 - accuracy: 0.7443 - val_loss: 5.1771 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 3.6866 - accuracy: 0.7650\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.2556 - accuracy: 0.5876 - val_loss: 2.8282 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 1.2321 - accuracy: 0.5425\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 2.6794 - accuracy: 0.4950 - val_loss: 3.9528 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.9683 - accuracy: 0.4650\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 34.8890 - accuracy: 0.5756 - val_loss: 16.3337 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 21.3152 - accuracy: 0.5700\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 24.2741 - accuracy: 0.4069 - val_loss: 17.2621 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.8980 - accuracy: 0.4425\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 163.5115 - accuracy: 0.2893 - val_loss: 163.4644 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 113.0131 - accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 29.3926 - accuracy: 0.2748 - val_loss: 25.4837 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 20.4909 - accuracy: 0.3025\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 20.1122 - accuracy: 0.5979 - val_loss: 13.7752 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 10.5401 - accuracy: 0.6125\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 3.1836 - accuracy: 0.3639 - val_loss: 3.7896 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 998us/step - loss: 1.8053 - accuracy: 0.3300\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.7031 - accuracy: 0.5917 - val_loss: 7.1566 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 5.4792 - accuracy: 0.5500\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.8220 - accuracy: 0.5180 - val_loss: 1.3957 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 49.1718 - accuracy: 0.6037 - val_loss: 38.7570 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 915us/step - loss: 32.0033 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 26.3630 - accuracy: 0.4041 - val_loss: 22.7908 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 17.6218 - accuracy: 0.3350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2675 - accuracy: 0.4008 - val_loss: 4.8089 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6997 - accuracy: 0.4400\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 139.9386 - accuracy: 0.1011 - val_loss: 152.8532 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 834us/step - loss: 103.2345 - accuracy: 0.1275\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.7994 - accuracy: 0.6274 - val_loss: 3.1964 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3132 - accuracy: 0.6575\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.6746 - accuracy: 0.5277 - val_loss: 15.1266 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.1079 - accuracy: 0.2375\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4490 - accuracy: 0.6047 - val_loss: 1.0754 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.6850\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 151.1062 - accuracy: 0.3122 - val_loss: 144.9378 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 117.2090 - accuracy: 0.3025\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.3122 - accuracy: 0.6473 - val_loss: 1.9178 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.9749 - accuracy: 0.6250\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 13.6788 - accuracy: 0.2482 - val_loss: 17.1156 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.7528 - accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0827 - accuracy: 0.5423 - val_loss: 1.6058 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8691 - accuracy: 0.5625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 20.0014 - accuracy: 0.3602 - val_loss: 16.4887 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 11.0095 - accuracy: 0.3900\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 1.2189 - accuracy: 0.4636 - val_loss: 1.5987 - val_accuracy: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 980us/step - loss: 0.7785 - accuracy: 0.5450\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 12.0526 - accuracy: 0.3966 - val_loss: 7.4582 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.9701 - accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 117.0756 - accuracy: 0.3079 - val_loss: 116.9402 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 833us/step - loss: 80.8627 - accuracy: 0.3350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.7723 - accuracy: 0.2807 - val_loss: 1.7017 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0937 - accuracy: 0.3225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.7279 - accuracy: 0.6261 - val_loss: 1.8156 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.5889 - accuracy: 0.6900\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.6476 - accuracy: 0.3538 - val_loss: 2.8781 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2986 - accuracy: 0.3350\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 0.6189 - accuracy: 0.5377 - val_loss: 0.7905 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.6325\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.31976577639579773\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.5961 - accuracy: 0.2615 - val_loss: 3.1985 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3847 - accuracy: 0.5375\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 35.7319 - accuracy: 0.6016 - val_loss: 23.2860 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.7073 - accuracy: 0.6075\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 32.8700 - accuracy: 0.1567 - val_loss: 27.7234 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.4461 - accuracy: 0.1700\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 21.9108 - accuracy: 0.0759 - val_loss: 28.4874 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.2862 - accuracy: 0.1225\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 107.4793 - accuracy: 0.0608 - val_loss: 91.3172 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 71.0765 - accuracy: 0.0850\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 4.8386 - accuracy: 0.6021 - val_loss: 3.3841 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1849 - accuracy: 0.4825\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 15.1231 - accuracy: 0.5189 - val_loss: 15.8021 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2690 - accuracy: 0.7150\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.0717 - accuracy: 0.4934 - val_loss: 0.9517 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.7175\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 126.6543 - accuracy: 0.2372 - val_loss: 94.1676 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 94.3636 - accuracy: 0.2450\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.3835 - accuracy: 0.6816 - val_loss: 3.4436 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1551 - accuracy: 0.6775\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 17.9640 - accuracy: 0.4414 - val_loss: 23.0993 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.9450 - accuracy: 0.4000\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 4.0819 - accuracy: 0.4699 - val_loss: 4.4066 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8408 - accuracy: 0.4650\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 18.4311 - accuracy: 0.3856 - val_loss: 13.9901 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 9.9556 - accuracy: 0.3825\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 2.7763 - accuracy: 0.3278 - val_loss: 1.7074 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3473 - accuracy: 0.5325\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 6.0544 - accuracy: 0.4567 - val_loss: 9.1145 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0336 - accuracy: 0.5550\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 114.1373 - accuracy: 0.2472 - val_loss: 101.8177 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 79.0855 - accuracy: 0.3125\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 16.7040 - accuracy: 0.4064 - val_loss: 9.2583 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.7935 - accuracy: 0.3925\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 10.4431 - accuracy: 0.0974 - val_loss: 9.1269 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9679 - accuracy: 0.2275\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.6252 - accuracy: 0.4533 - val_loss: 1.9867 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2897 - accuracy: 0.3825\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 4.4105 - accuracy: 0.5844 - val_loss: 1.6933 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5620 - accuracy: 0.4825\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6793 - accuracy: 0.5446 - val_loss: 1.2085 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.5210 - accuracy: 0.6225\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 22.7389 - accuracy: 0.5979 - val_loss: 16.5430 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 14.9608 - accuracy: 0.6225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 83.9371 - accuracy: 0.2335 - val_loss: 72.4262 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 55.8344 - accuracy: 0.3375\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 51.6361 - accuracy: 0.6161 - val_loss: 50.9965 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 31.0019 - accuracy: 0.6350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 71.8572 - accuracy: 0.0852 - val_loss: 59.5252 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 47.0890 - accuracy: 0.0900\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.3650 - accuracy: 0.6180 - val_loss: 2.5942 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0665 - accuracy: 0.6575\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8960 - accuracy: 0.4802 - val_loss: 13.9936 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0423 - accuracy: 0.4550\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.2504 - accuracy: 0.6182 - val_loss: 2.6500 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 915us/step - loss: 2.4925 - accuracy: 0.6075\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 181.8249 - accuracy: 0.3258 - val_loss: 132.8474 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 123.2526 - accuracy: 0.2650\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8965 - accuracy: 0.6905 - val_loss: 1.4831 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.6975\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.8392 - accuracy: 0.3461 - val_loss: 11.6604 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 982us/step - loss: 5.6365 - accuracy: 0.3925\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 42.5664 - accuracy: 0.4691 - val_loss: 28.8039 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 982us/step - loss: 28.4637 - accuracy: 0.4875\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 10.2911 - accuracy: 0.3808 - val_loss: 7.3087 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.6411 - accuracy: 0.4075\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 0.7292 - accuracy: 0.5713 - val_loss: 1.2507 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.5450\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 3.7225 - accuracy: 0.5129 - val_loss: 7.0410 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.6316 - accuracy: 0.5275\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 82.2245 - accuracy: 0.3321 - val_loss: 67.5005 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 52.5967 - accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1876 - accuracy: 0.3257 - val_loss: 1.4468 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8283 - accuracy: 0.3925\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.5645 - accuracy: 0.7039 - val_loss: 1.5391 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.4720 - accuracy: 0.7175\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.2431 - accuracy: 0.4939 - val_loss: 1.4410 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.9970 - accuracy: 0.3875\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 0.4538 - accuracy: 0.6318 - val_loss: 0.6638 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.3321 - accuracy: 0.7075\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.9905 - accuracy: 0.8466 - val_loss: 2.7840 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2506 - accuracy: 0.5550\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 35.4050 - accuracy: 0.4876 - val_loss: 21.8527 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 17.5052 - accuracy: 0.4425\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 34.7771 - accuracy: 0.4909 - val_loss: 32.1320 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 20.6345 - accuracy: 0.5075\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 25.8403 - accuracy: 0.4538 - val_loss: 18.5748 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.5197 - accuracy: 0.4475\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 101.9986 - accuracy: 0.0755 - val_loss: 82.8618 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 66.8465 - accuracy: 0.0900\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 15.4140 - accuracy: 0.3713 - val_loss: 11.5687 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.2532 - accuracy: 0.4350\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 8.2177 - accuracy: 0.3194 - val_loss: 11.5037 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0817 - accuracy: 0.4225\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.5560 - accuracy: 0.6313 - val_loss: 1.9837 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.4945 - accuracy: 0.6225\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 141.6924 - accuracy: 0.3185 - val_loss: 99.0660 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 91.5506 - accuracy: 0.3450\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 6.8288 - accuracy: 0.2815 - val_loss: 6.4088 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2306 - accuracy: 0.3775\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 14.5422 - accuracy: 0.3393 - val_loss: 16.2241 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3901 - accuracy: 0.3325\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 19.2288 - accuracy: 0.5605 - val_loss: 21.9678 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 12.6700 - accuracy: 0.5100\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.0278 - accuracy: 0.3648 - val_loss: 3.3459 - val_accuracy: 0.8800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.3346 - accuracy: 0.6450\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 5.3360 - accuracy: 0.6194 - val_loss: 4.2114 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 2.7303 - accuracy: 0.5875\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.4995 - accuracy: 0.4959 - val_loss: 12.1705 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7418 - accuracy: 0.3125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 70.8676 - accuracy: 0.1432 - val_loss: 52.7456 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 41.6924 - accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.8611 - accuracy: 0.4264 - val_loss: 2.3349 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3555 - accuracy: 0.4750\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 1.9879 - accuracy: 0.3622 - val_loss: 3.5941 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 976us/step - loss: 1.0469 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 2.1579 - accuracy: 0.4517 - val_loss: 1.9237 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3387 - accuracy: 0.4300\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.9884 - accuracy: 0.4225 - val_loss: 1.5730 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7075\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4956 - accuracy: 0.6560 - val_loss: 1.0491 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.4264 - accuracy: 0.6100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 16.0724 - accuracy: 0.6571 - val_loss: 12.5042 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 10.0456 - accuracy: 0.5775\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 22.8990 - accuracy: 0.4721 - val_loss: 20.2480 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 12.3457 - accuracy: 0.4675\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 14.8906 - accuracy: 0.2846 - val_loss: 20.6419 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.2189 - accuracy: 0.3350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 48.8664 - accuracy: 0.0570 - val_loss: 36.7628 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 29.0688 - accuracy: 0.0975\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0134 - accuracy: 0.6101 - val_loss: 2.1286 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8416 - accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.5795 - accuracy: 0.5138 - val_loss: 10.8863 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2612 - accuracy: 0.5350\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 1.6688 - accuracy: 0.6211 - val_loss: 1.4779 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9522 - accuracy: 0.6350\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 97.8013 - accuracy: 0.3478 - val_loss: 61.4164 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 60.6247 - accuracy: 0.2950\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.7618 - accuracy: 0.7022 - val_loss: 1.1235 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.5107 - accuracy: 0.7525\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 39.5001 - accuracy: 0.3509 - val_loss: 33.8592 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.2565 - accuracy: 0.3925\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 13.1071 - accuracy: 0.5144 - val_loss: 13.9993 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 7.7340 - accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.5090 - accuracy: 0.5246 - val_loss: 2.3362 - val_accuracy: 0.8400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8050 - accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5795 - accuracy: 0.5960 - val_loss: 1.0528 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.6350\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 2.5171 - accuracy: 0.4923 - val_loss: 5.4271 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8361 - accuracy: 0.5425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 44.4318 - accuracy: 0.2206 - val_loss: 34.7729 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.9437 - accuracy: 0.3125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8769 - accuracy: 0.3647 - val_loss: 1.2139 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.4675\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4520 - accuracy: 0.7165 - val_loss: 1.4666 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.7475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.9447 - accuracy: 0.4386 - val_loss: 1.1689 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3711 - accuracy: 0.7077 - val_loss: 0.5577 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.7525\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.2648499310016632\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 15.0565 - accuracy: 0.2078 - val_loss: 6.5828 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.8220 - accuracy: 0.6025\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 12.3509 - accuracy: 0.5770 - val_loss: 6.5034 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 998us/step - loss: 6.8442 - accuracy: 0.5300\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 18.5637 - accuracy: 0.4704 - val_loss: 15.9673 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.9690 - accuracy: 0.4525\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 11.2855 - accuracy: 0.3584 - val_loss: 16.5850 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8840 - accuracy: 0.4150\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 32.6952 - accuracy: 0.0998 - val_loss: 27.7006 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.6258 - accuracy: 0.1100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.4700 - accuracy: 0.6854 - val_loss: 1.8182 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8766 - accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.2967 - accuracy: 0.7008 - val_loss: 16.5847 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8106 - accuracy: 0.5650\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 9.8112 - accuracy: 0.0410 - val_loss: 6.2181 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 917us/step - loss: 5.5539 - accuracy: 0.0700\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 96.8231 - accuracy: 0.2445 - val_loss: 53.1038 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 833us/step - loss: 56.7023 - accuracy: 0.2200\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 9.9443 - accuracy: 0.7197 - val_loss: 4.0662 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 3.8483 - accuracy: 0.6975\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 31.5481 - accuracy: 0.3390 - val_loss: 26.7008 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.2673 - accuracy: 0.3475\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 7.3399 - accuracy: 0.6063 - val_loss: 9.7292 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.6180 - accuracy: 0.5950\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 15.4299 - accuracy: 0.2060 - val_loss: 6.3625 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 6.7828 - accuracy: 0.1950\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.8517 - accuracy: 0.5654 - val_loss: 1.2963 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5875\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 18.3560 - accuracy: 0.3655 - val_loss: 12.8168 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.1314 - accuracy: 0.3475\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 33.2703 - accuracy: 0.3230 - val_loss: 25.4678 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 17.6628 - accuracy: 0.3125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.4705 - accuracy: 0.1893 - val_loss: 1.5390 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8721 - accuracy: 0.4075\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.6296 - accuracy: 0.4144 - val_loss: 2.9527 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.9355 - accuracy: 0.6400\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 2.3442 - accuracy: 0.3498 - val_loss: 1.7540 - val_accuracy: 0.8200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0978 - accuracy: 0.5600\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 2.5293 - accuracy: 0.3497 - val_loss: 2.3248 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1674 - accuracy: 0.5275\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 0.4659 - accuracy: 0.6478 - val_loss: 0.8511 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.3670 - accuracy: 0.6775\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.3816 - accuracy: 0.5677 - val_loss: 5.4944 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 4.5631 - accuracy: 0.4875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 8.7725 - accuracy: 0.4634 - val_loss: 9.7093 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 4.3706 - accuracy: 0.3650\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 8.0171 - accuracy: 0.4279 - val_loss: 12.0639 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 6.1383 - accuracy: 0.4625\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 20.5829 - accuracy: 0.0861 - val_loss: 16.4997 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 11.3871 - accuracy: 0.1250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.8742 - accuracy: 0.6974 - val_loss: 1.9248 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.6933 - accuracy: 0.6900\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 41.9271 - accuracy: 0.0881 - val_loss: 45.1030 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 24.7418 - accuracy: 0.1825\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.2492 - accuracy: 0.6247 - val_loss: 1.0722 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.6667 - accuracy: 0.6300\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 63.4215 - accuracy: 0.2975 - val_loss: 30.6305 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 34.2406 - accuracy: 0.2325\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 0.4828 - accuracy: 0.7881 - val_loss: 0.8202 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 22.2088 - accuracy: 0.3223 - val_loss: 18.9778 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.6106 - accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.9886 - accuracy: 0.6360 - val_loss: 7.2719 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0278 - accuracy: 0.5575\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8417 - accuracy: 0.6505 - val_loss: 1.5723 - val_accuracy: 0.8600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.5644 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.4043 - accuracy: 0.6951 - val_loss: 0.8356 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.7225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1093 - accuracy: 0.4713 - val_loss: 3.7735 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3485 - accuracy: 0.5525\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 18.9495 - accuracy: 0.3493 - val_loss: 16.0523 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.8808 - accuracy: 0.3500\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.7253 - accuracy: 0.4503 - val_loss: 0.9340 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.5325\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4213 - accuracy: 0.7451 - val_loss: 1.2744 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.7775\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 93.1391 - accuracy: 0.5307 - val_loss: 144.4729 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 65.2925 - accuracy: 0.5525\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2927 - accuracy: 0.7117 - val_loss: 0.4219 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.2193 - accuracy: 0.7550\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.21933946013450623\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 8.4567 - accuracy: 0.5613 - val_loss: 4.9712 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.1259 - accuracy: 0.5500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 20.3733 - accuracy: 0.3796 - val_loss: 11.4117 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.6169 - accuracy: 0.4425\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 4.9577 - accuracy: 0.4157 - val_loss: 8.1476 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9248 - accuracy: 0.4525\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 8.2367 - accuracy: 0.4305 - val_loss: 9.6278 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 5.4617 - accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 15.3192 - accuracy: 0.1772 - val_loss: 10.1485 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 7.6676 - accuracy: 0.1225\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 1.8062 - accuracy: 0.5607 - val_loss: 2.1410 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8961 - accuracy: 0.5125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 30.3168 - accuracy: 0.1399 - val_loss: 31.9880 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 17.6054 - accuracy: 0.2500\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 5.8505 - accuracy: 0.6258 - val_loss: 4.4800 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.4700 - accuracy: 0.6975\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 41.5099 - accuracy: 0.2425 - val_loss: 20.3512 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.6950 - accuracy: 0.2450\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.5834 - accuracy: 0.1846 - val_loss: 1.1014 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.6925\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 26.2837 - accuracy: 0.3538 - val_loss: 18.7992 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 998us/step - loss: 14.5717 - accuracy: 0.3125\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 35.6724 - accuracy: 0.6026 - val_loss: 23.0585 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.2634 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 26ms/step - loss: 2.0591 - accuracy: 0.3374 - val_loss: 2.5147 - val_accuracy: 0.8200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8646 - accuracy: 0.7225\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 6.8453 - accuracy: 0.1919 - val_loss: 4.6771 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0908 - accuracy: 0.2950\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 2.4872 - accuracy: 0.4761 - val_loss: 3.6455 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.4623 - accuracy: 0.5475\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 24.4143 - accuracy: 0.6346 - val_loss: 20.3179 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 8.1210 - accuracy: 0.7400\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 3.1739 - accuracy: 0.4279 - val_loss: 2.4391 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.1200 - accuracy: 0.5675\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.4891 - accuracy: 0.1453 - val_loss: 1.8710 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 73.7625 - accuracy: 0.4583 - val_loss: 144.5761 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 55.8508 - accuracy: 0.5400\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 1.8827 - accuracy: 0.3809 - val_loss: 1.3477 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.5575\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3657 - accuracy: 0.6773 - val_loss: 0.7431 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.3097 - accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.9275 - accuracy: 0.4758 - val_loss: 4.6824 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 929us/step - loss: 3.2350 - accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.6528 - accuracy: 0.4299 - val_loss: 6.6108 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1227 - accuracy: 0.5350\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.3392 - accuracy: 0.3629 - val_loss: 7.5720 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3910 - accuracy: 0.4575\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 15.4744 - accuracy: 0.1435 - val_loss: 9.5503 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2493 - accuracy: 0.2125\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.6864 - val_loss: 1.5240 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.5634 - accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 21.0322 - accuracy: 0.1975 - val_loss: 25.2129 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.1617 - accuracy: 0.2675\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.7103 - accuracy: 0.6180 - val_loss: 0.6806 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.6350\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 22.6424 - accuracy: 0.2811 - val_loss: 11.0663 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.4779 - accuracy: 0.2675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3612 - accuracy: 0.7711 - val_loss: 0.6537 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.7975\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 14.9773 - accuracy: 0.2821 - val_loss: 13.6859 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.1029 - accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.1742 - accuracy: 0.6249 - val_loss: 5.5585 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.0147 - accuracy: 0.5250\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 12.2476 - accuracy: 0.3673 - val_loss: 7.7872 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1409 - accuracy: 0.3300\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3436 - accuracy: 0.7255 - val_loss: 0.7987 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.7975\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.2841 - accuracy: 0.5657 - val_loss: 3.3994 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.6025\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 10.7073 - accuracy: 0.7126 - val_loss: 10.2377 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.4386 - accuracy: 0.4550\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 105.1123 - accuracy: 0.3672 - val_loss: 80.9729 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 75.2862 - accuracy: 0.3775\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3269 - accuracy: 0.7649 - val_loss: 1.1079 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.8075\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 46.0595 - accuracy: 0.4911 - val_loss: 88.6247 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.2705 - accuracy: 0.5900\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 27.5348 - accuracy: 5.4315e-04 - val_loss: 16.8373 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 15.9923 - accuracy: 0.0025\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.7373 - accuracy: 0.3010 - val_loss: 1.9395 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.0976 - accuracy: 0.5200\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 4.5326 - accuracy: 0.3005 - val_loss: 2.6270 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.5932 - accuracy: 0.4050\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.7681 - accuracy: 0.4089 - val_loss: 8.6595 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4147 - accuracy: 0.4500\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.8843 - accuracy: 0.3760 - val_loss: 6.5249 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6470 - accuracy: 0.3500\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 9.7234 - accuracy: 0.2189 - val_loss: 10.2421 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.2310 - accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.0228 - accuracy: 0.1167 - val_loss: 1.7783 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2279 - accuracy: 0.3650\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 22.7273 - accuracy: 0.1169 - val_loss: 21.8435 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.4604 - accuracy: 0.2275\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1233 - accuracy: 0.6288 - val_loss: 0.6042 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.6200\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 13.9111 - accuracy: 0.2956 - val_loss: 9.6028 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.9638 - accuracy: 0.3550\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.8222 - accuracy: 0.5154 - val_loss: 3.6475 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6907 - accuracy: 0.6800\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 13.9310 - accuracy: 0.4115 - val_loss: 9.4539 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 7.6196 - accuracy: 0.5150\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 68.7278 - accuracy: 0.5778 - val_loss: 51.2232 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 45.7505 - accuracy: 0.6025\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 11.8190 - accuracy: 0.3075 - val_loss: 5.7594 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1842 - accuracy: 0.2575\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 3.3023 - accuracy: 0.6631 - val_loss: 2.3999 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.2414 - accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 18ms/step - loss: 5.2748 - accuracy: 0.7428 - val_loss: 3.1012 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.0882 - accuracy: 0.7175\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 6.8220 - accuracy: 0.3480 - val_loss: 6.6834 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7201 - accuracy: 0.4400\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 90.0014 - accuracy: 0.3358 - val_loss: 59.8538 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 59.9270 - accuracy: 0.3425\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 1.0996 - accuracy: 0.6953 - val_loss: 1.2060 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.7050\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 32.6754 - accuracy: 0.6828 - val_loss: 52.3964 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.7502 - accuracy: 0.6225\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 35.6946 - accuracy: 0.0065 - val_loss: 18.9569 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 20.4519 - accuracy: 0.0075\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.3074 - accuracy: 0.6610 - val_loss: 0.6281 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.7225\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.6237 - accuracy: 0.3731 - val_loss: 1.8062 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8220 - accuracy: 0.4675\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.8329 - accuracy: 0.5222 - val_loss: 5.1815 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.6359 - accuracy: 0.4950\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.0274 - accuracy: 0.4153 - val_loss: 6.3265 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6287 - accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.5977 - accuracy: 0.3041 - val_loss: 6.6370 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.3294 - accuracy: 0.4900\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 0.5102 - accuracy: 0.7409 - val_loss: 1.3445 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 13.0145 - accuracy: 0.2518 - val_loss: 14.9966 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.8094 - accuracy: 0.3900\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.6468 - val_loss: 0.6288 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.7050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 6.3954 - accuracy: 0.2901 - val_loss: 7.3659 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.7023 - accuracy: 0.5150\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.3128 - accuracy: 0.7828 - val_loss: 0.5384 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.8225\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 8.6166 - accuracy: 0.4144 - val_loss: 8.2136 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9207 - accuracy: 0.5775\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 2.0572 - accuracy: 0.5660 - val_loss: 4.0979 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4964 - accuracy: 0.4950\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 6.2552 - accuracy: 0.2885 - val_loss: 4.1270 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4096 - accuracy: 0.4100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2659 - accuracy: 0.8445 - val_loss: 0.7162 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.2295 - accuracy: 0.8200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.9843 - accuracy: 0.5728 - val_loss: 2.4918 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.7850 - accuracy: 0.6275\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.3943 - accuracy: 0.4588 - val_loss: 5.5333 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.8807 - accuracy: 0.5000\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 62.6381 - accuracy: 0.3459 - val_loss: 38.8737 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 41.4857 - accuracy: 0.3575\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.2445 - accuracy: 0.8052 - val_loss: 0.9316 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.8275\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 23.1508 - accuracy: 0.6256 - val_loss: 29.0263 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 14.6555 - accuracy: 0.6100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 19.0496 - accuracy: 0.0022 - val_loss: 10.5095 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.9072 - accuracy: 0.0025\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.21873772144317627\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 28.1845 - accuracy: 0.3347 - val_loss: 14.5847 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 13.4731 - accuracy: 0.3425\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 6.0307 - accuracy: 0.5662 - val_loss: 2.6973 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2912 - accuracy: 0.5750\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 3.5561 - accuracy: 0.4596 - val_loss: 7.1939 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.3197 - accuracy: 0.5850\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.4741 - accuracy: 0.4000 - val_loss: 6.1867 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5421 - accuracy: 0.3925\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 9.2174 - accuracy: 0.3337 - val_loss: 8.0429 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3271 - accuracy: 0.4225\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.0791 - accuracy: 0.1500 - val_loss: 2.1030 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.0021 - accuracy: 0.5350\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 34.0602 - accuracy: 0.5652 - val_loss: 29.3014 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 17.7850 - accuracy: 0.6425\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.1471 - accuracy: 0.6504 - val_loss: 3.1904 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.4144 - accuracy: 0.6250\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.1519 - accuracy: 0.4259 - val_loss: 6.8858 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6669 - accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 4.9958 - accuracy: 0.3474 - val_loss: 2.4551 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0575 - accuracy: 0.3800\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.9744 - accuracy: 0.6010 - val_loss: 5.4222 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0926 - accuracy: 0.6025\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 1.6479 - accuracy: 0.5038 - val_loss: 3.2736 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0204 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 18.1750 - accuracy: 0.5281 - val_loss: 12.7284 - val_accuracy: 0.8600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 10.5848 - accuracy: 0.6875\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.9187 - accuracy: 0.3705 - val_loss: 1.2420 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7200\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.4890 - accuracy: 0.3801 - val_loss: 6.3440 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5807 - accuracy: 0.4775\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.3813 - accuracy: 0.5275 - val_loss: 11.2278 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.8701 - accuracy: 0.6475\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 37.4260 - accuracy: 0.3843 - val_loss: 22.9566 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 23.4908 - accuracy: 0.3450\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.7781 - accuracy: 0.6074 - val_loss: 1.1994 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8200\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 16.4702 - accuracy: 0.6611 - val_loss: 13.9877 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.5699 - accuracy: 0.5050\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 17.0824 - accuracy: 0.1857 - val_loss: 12.2479 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 10.1706 - accuracy: 0.1925\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 6.3618 - accuracy: 0.6561 - val_loss: 4.2930 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.3224 - accuracy: 0.5325\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 1.7122 - accuracy: 0.4555 - val_loss: 1.1976 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3424 - accuracy: 0.4700\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.0273 - accuracy: 0.4876 - val_loss: 4.7202 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5611 - accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 12.2970 - accuracy: 0.3753 - val_loss: 13.7489 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 917us/step - loss: 8.9845 - accuracy: 0.4350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4011 - accuracy: 0.4205 - val_loss: 4.7327 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 2.4073 - accuracy: 0.5725\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.4832 - accuracy: 0.7389 - val_loss: 1.1574 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.7425\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 6.9853 - accuracy: 0.4346 - val_loss: 13.7258 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.1904 - accuracy: 0.4875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2340 - accuracy: 0.7373 - val_loss: 0.4801 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.8425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0108 - accuracy: 0.4921 - val_loss: 5.5423 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6353 - accuracy: 0.4700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.7637 - accuracy: 0.3740 - val_loss: 2.3707 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3632 - accuracy: 0.5050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1398 - accuracy: 0.5776 - val_loss: 4.5463 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.6719 - accuracy: 0.6025\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.0179 - accuracy: 0.6037 - val_loss: 2.5329 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.8382 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 3.2988 - accuracy: 0.3978 - val_loss: 4.2574 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6167 - accuracy: 0.5225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2312 - accuracy: 0.8582 - val_loss: 0.6262 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.1960 - accuracy: 0.8550\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.9106 - accuracy: 0.6446 - val_loss: 1.9909 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6850\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.7804 - accuracy: 0.4776 - val_loss: 5.0509 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4548 - accuracy: 0.5950\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 21.3512 - accuracy: 0.3752 - val_loss: 11.3421 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.1182 - accuracy: 0.4050\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 7.7927 - accuracy: 0.0958 - val_loss: 7.3001 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6368 - accuracy: 0.2650\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 197.7282 - accuracy: 0.2623 - val_loss: 242.8562 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 149.4363 - accuracy: 0.2625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 12.5081 - accuracy: 0.0024 - val_loss: 6.1921 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4617 - accuracy: 0.0075\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.1647230088710785\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 20.0988 - accuracy: 0.5110 - val_loss: 9.9490 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.1140 - accuracy: 0.3925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.9237 - accuracy: 0.5847 - val_loss: 1.1594 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.3266 - accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.1133 - accuracy: 0.5959 - val_loss: 5.3761 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0140 - accuracy: 0.4925\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 9.0901 - accuracy: 0.3691 - val_loss: 9.2839 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.6282 - accuracy: 0.4150\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.2670 - accuracy: 0.2858 - val_loss: 4.8578 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8330 - accuracy: 0.5350\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.6322 - accuracy: 0.3657 - val_loss: 3.0347 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.2881 - accuracy: 0.4675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 18ms/step - loss: 21.9201 - accuracy: 0.4575 - val_loss: 14.5528 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 978us/step - loss: 8.4279 - accuracy: 0.6825\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.5021 - accuracy: 0.6350 - val_loss: 0.7763 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.2155 - accuracy: 0.7875\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 8.2630 - accuracy: 0.6284 - val_loss: 9.3815 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1530 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 1.2719 - accuracy: 0.4325 - val_loss: 1.5686 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.5875\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.6030 - accuracy: 0.6846 - val_loss: 3.0896 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.2215 - accuracy: 0.6825\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.2426 - accuracy: 0.5079 - val_loss: 2.7158 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9785 - accuracy: 0.5325\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 7.2947 - accuracy: 0.1686 - val_loss: 3.8152 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0286 - accuracy: 0.4275\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.3253 - accuracy: 0.6100 - val_loss: 2.3201 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2552 - accuracy: 0.5775\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 3.2841 - accuracy: 0.1327 - val_loss: 3.2402 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9671 - accuracy: 0.5875\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 27.9017 - accuracy: 0.6754 - val_loss: 32.0779 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 833us/step - loss: 17.0449 - accuracy: 0.7350\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 15.6007 - accuracy: 0.7376 - val_loss: 7.8854 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3916 - accuracy: 0.7800\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 13.6795 - accuracy: 0.6381 - val_loss: 6.5519 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7874 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 209.6028 - accuracy: 0.2058 - val_loss: 226.7634 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 124.4527 - accuracy: 0.2425\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.3599 - accuracy: 0.0045 - val_loss: 4.9516 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6216 - accuracy: 0.0275\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.5452 - accuracy: 0.5929 - val_loss: 2.5569 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 1.1897 - accuracy: 0.5175\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1257 - accuracy: 0.5575 - val_loss: 2.1710 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8513 - accuracy: 0.6875\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 2.8036 - accuracy: 0.0528 - val_loss: 1.2925 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0228 - accuracy: 0.2525\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 39.9130 - accuracy: 0.3845 - val_loss: 34.4816 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 32.0298 - accuracy: 0.3875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.8415 - accuracy: 0.4516 - val_loss: 4.0027 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 1.3711 - accuracy: 0.6050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4533 - accuracy: 0.7344 - val_loss: 0.9414 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.3422 - accuracy: 0.7975\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 10.2736 - accuracy: 0.6228 - val_loss: 9.3374 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3885 - accuracy: 0.5875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1764 - accuracy: 0.8163 - val_loss: 0.3557 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.8600\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 2.2163 - accuracy: 0.4815 - val_loss: 3.8398 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9879 - accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.7546 - accuracy: 0.5637 - val_loss: 1.5107 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.5750 - accuracy: 0.7050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.0823 - accuracy: 0.6759 - val_loss: 2.8390 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.9374 - accuracy: 0.6525\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 91.2464 - accuracy: 0.0065 - val_loss: 107.7073 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 76.6245 - accuracy: 0.0175\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.7948 - accuracy: 0.5369 - val_loss: 3.9495 - val_accuracy: 0.8200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1744 - accuracy: 0.6425\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 0.2172 - accuracy: 0.8306 - val_loss: 0.6243 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.1766 - accuracy: 0.9025\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 0.6946 - val_loss: 1.5344 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7325\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1366 - accuracy: 0.5146 - val_loss: 3.9683 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 2.0562 - accuracy: 0.6225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 79.3209 - accuracy: 0.3975 - val_loss: 78.7625 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 946us/step - loss: 56.7370 - accuracy: 0.4475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.6089 - accuracy: 0.4937 - val_loss: 6.3214 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4864 - accuracy: 0.5625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 129.3698 - accuracy: 0.2183 - val_loss: 143.4959 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 81.9476 - accuracy: 0.2775\n",
      "13/13 [==============================] - 1s 35ms/step - loss: 3.5892 - accuracy: 0.0196 - val_loss: 4.3887 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2049 - accuracy: 0.2350\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.1305065006017685\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.9469 - accuracy: 0.2940 - val_loss: 2.4142 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.9497 - accuracy: 0.5475\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 6.4990 - accuracy: 0.3559 - val_loss: 4.7383 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7292 - accuracy: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 18ms/step - loss: 10.3812 - accuracy: 0.0174 - val_loss: 5.9497 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 5.3671 - accuracy: 0.0550\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 35.0131 - accuracy: 0.3332 - val_loss: 30.6427 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 28.0047 - accuracy: 0.3725\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 6.1415 - accuracy: 0.7609 - val_loss: 4.7189 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 3.2111 - accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.4035 - accuracy: 0.2543 - val_loss: 1.1020 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 917us/step - loss: 0.5520 - accuracy: 0.7050\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 23.3126 - accuracy: 0.6179 - val_loss: 10.2018 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.1087 - accuracy: 0.6475\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4672 - accuracy: 0.6413 - val_loss: 0.4114 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7525\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 4.4287 - accuracy: 0.5646 - val_loss: 5.0726 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.4083 - accuracy: 0.3900\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 4.5838 - accuracy: 0.1577 - val_loss: 3.9371 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.5909 - accuracy: 0.2225\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.4295 - accuracy: 0.3182 - val_loss: 2.1037 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.0249 - accuracy: 0.6675\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 64.2410 - accuracy: 0.0365 - val_loss: 69.7696 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 46.7206 - accuracy: 0.0300\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.1434 - accuracy: 0.3001 - val_loss: 3.2325 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 1.4297 - accuracy: 0.4300\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 1.8698 - accuracy: 0.3506 - val_loss: 4.1908 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.9342 - accuracy: 0.4375\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.6448 - accuracy: 0.6336 - val_loss: 2.2386 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9027 - accuracy: 0.6975\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.7316 - accuracy: 0.3907 - val_loss: 4.6138 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 991us/step - loss: 2.4839 - accuracy: 0.3275\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 52.1782 - accuracy: 0.4549 - val_loss: 54.1636 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.1608 - accuracy: 0.4850\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 3.3239 - accuracy: 0.2082 - val_loss: 4.6747 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.8625 - accuracy: 0.4575\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 91.9586 - accuracy: 0.3476 - val_loss: 119.0442 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 63.1677 - accuracy: 0.3575\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 2.0427 - accuracy: 0.3323 - val_loss: 4.4953 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0226 - accuracy: 0.4775\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1868 - accuracy: 0.4519 - val_loss: 1.7726 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.7550\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8617 - accuracy: 0.6787 - val_loss: 1.3129 - val_accuracy: 0.8400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1925 - accuracy: 0.1909 - val_loss: 0.9966 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.5350\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 37.6500 - accuracy: 0.3236 - val_loss: 39.7092 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 30.4679 - accuracy: 0.3375\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.2758 - accuracy: 0.5713 - val_loss: 2.9763 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 917us/step - loss: 1.0469 - accuracy: 0.5750\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 151.3902 - accuracy: 0.5350 - val_loss: 135.1582 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 111.6529 - accuracy: 0.5050\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.4014 - accuracy: 0.5674 - val_loss: 10.0501 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 994us/step - loss: 3.4535 - accuracy: 0.5050\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1327 - accuracy: 0.8600 - val_loss: 0.2812 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.8625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.9436 - accuracy: 0.6234 - val_loss: 3.3305 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6906 - accuracy: 0.4975\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.5780 - accuracy: 0.6948 - val_loss: 1.2099 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7400\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.8973 - accuracy: 0.6437 - val_loss: 2.5006 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.6825\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 34.8967 - accuracy: 0.0596 - val_loss: 25.0425 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.3528 - accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.1496 - accuracy: 0.6127 - val_loss: 2.9292 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8503 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1879 - accuracy: 0.8464 - val_loss: 0.5759 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.1612 - accuracy: 0.8950\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.5405 - accuracy: 0.7156 - val_loss: 1.2209 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7275\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 2.6118 - accuracy: 0.5147 - val_loss: 3.4374 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7642 - accuracy: 0.6425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 37.6818 - accuracy: 0.4818 - val_loss: 35.5668 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 23.8924 - accuracy: 0.4525\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.5138 - accuracy: 0.5740 - val_loss: 4.6008 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1217 - accuracy: 0.6475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 62.9861 - accuracy: 0.2998 - val_loss: 71.1412 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 39.6403 - accuracy: 0.3375\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.7899 - accuracy: 0.5050 - val_loss: 3.3755 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.7078 - accuracy: 0.6400\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.11136336624622345\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 3.2205 - accuracy: 0.5021 - val_loss: 2.7147 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 996us/step - loss: 1.5172 - accuracy: 0.5700\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.2230 - accuracy: 0.7168 - val_loss: 0.8995 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8758 - accuracy: 0.7425\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.6751 - accuracy: 0.6342 - val_loss: 1.1920 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8874 - accuracy: 0.5925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 49.9234 - accuracy: 0.0274 - val_loss: 50.7312 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 41.0853 - accuracy: 0.0275\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 19.2482 - accuracy: 0.4734 - val_loss: 23.4196 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 12.1426 - accuracy: 0.5075\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 106.4833 - accuracy: 0.4064 - val_loss: 97.5081 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 74.9402 - accuracy: 0.4075\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.4777 - accuracy: 0.2300 - val_loss: 9.2104 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 3.8443 - accuracy: 0.3225\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.4467 - accuracy: 0.1452 - val_loss: 0.8821 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.5243 - accuracy: 0.6125\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 7.5017 - accuracy: 0.2967 - val_loss: 5.8595 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.8449 - accuracy: 0.4000\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 0.9130 - accuracy: 0.6403 - val_loss: 1.1855 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.6775\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 3.5607 - accuracy: 0.1701 - val_loss: 4.2177 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4770 - accuracy: 0.3850\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 11.1285 - accuracy: 0.0927 - val_loss: 9.5210 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 5.0312 - accuracy: 0.1925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 32.0848 - accuracy: 0.0179 - val_loss: 25.8756 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 917us/step - loss: 20.8215 - accuracy: 0.0175\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 10.9544 - accuracy: 0.6916 - val_loss: 6.1142 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 5.2228 - accuracy: 0.6425\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 4.5659 - accuracy: 0.7347 - val_loss: 1.7392 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1598 - accuracy: 0.7900\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 6.9749 - accuracy: 0.2629 - val_loss: 3.8472 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 2.1382 - accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 56.8092 - accuracy: 0.4249 - val_loss: 46.4427 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 38.5198 - accuracy: 0.5250\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 7.1302 - accuracy: 0.5620 - val_loss: 6.9775 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.2101 - accuracy: 0.3475\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 45.1859 - accuracy: 0.1565 - val_loss: 39.3995 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 917us/step - loss: 26.1909 - accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.0647 - accuracy: 0.6326 - val_loss: 4.4017 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1794 - accuracy: 0.6275\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 0.6332 - accuracy: 0.6931 - val_loss: 1.2988 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.4491 - accuracy: 0.7425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 121.0268 - accuracy: 0.3487 - val_loss: 100.1674 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 833us/step - loss: 87.7129 - accuracy: 0.3825\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5254 - accuracy: 0.4268 - val_loss: 0.7399 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.6375\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 33.0565 - accuracy: 0.3670 - val_loss: 34.1522 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.2157 - accuracy: 0.3425\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.0296 - accuracy: 0.6097 - val_loss: 2.5186 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8239 - accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 214.8624 - accuracy: 0.0136 - val_loss: 204.4030 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 916us/step - loss: 170.5199 - accuracy: 0.0175\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.9999 - accuracy: 0.5274 - val_loss: 9.5843 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9450 - accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1168 - accuracy: 0.8686 - val_loss: 0.2499 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.8725\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 119.9936 - accuracy: 0.5930 - val_loss: 116.0244 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 67.2356 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 0.5486 - accuracy: 0.7253 - val_loss: 1.0025 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.7575\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.8055 - accuracy: 0.6763 - val_loss: 2.3543 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.6357 - accuracy: 0.7100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.1758 - accuracy: 0.1280 - val_loss: 6.4061 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6276 - accuracy: 0.4275\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.8413 - accuracy: 0.6038 - val_loss: 1.9827 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5700\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 23.9007 - accuracy: 0.7183 - val_loss: 23.2363 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 15.6967 - accuracy: 0.7675\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 43.9648 - accuracy: 0.3111 - val_loss: 26.1711 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 959us/step - loss: 23.4818 - accuracy: 0.3350\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 2.3524 - accuracy: 0.5967 - val_loss: 2.9160 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4601 - accuracy: 0.5900\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 25.8825 - accuracy: 0.4376 - val_loss: 24.2149 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 15.5989 - accuracy: 0.4450\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 26.5693 - accuracy: 0.6154 - val_loss: 21.3223 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.9343 - accuracy: 0.7875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 29.0190 - accuracy: 0.1713 - val_loss: 23.2849 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 998us/step - loss: 14.1362 - accuracy: 0.2225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.8509 - accuracy: 0.6035 - val_loss: 2.3738 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.6215 - accuracy: 0.6550\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.09585484862327576\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 4.6755 - accuracy: 0.0696 - val_loss: 3.1453 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.4900\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 43.8288 - accuracy: 0.3720 - val_loss: 43.3996 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 964us/step - loss: 28.3853 - accuracy: 0.3825\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.6273 - accuracy: 0.1227 - val_loss: 5.3070 - val_accuracy: 0.1400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6679 - accuracy: 0.1125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 25.0632 - accuracy: 0.2123 - val_loss: 35.1039 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.5502 - accuracy: 0.2250\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.4341 - accuracy: 0.5543 - val_loss: 6.5868 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 2.9841 - accuracy: 0.5450\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 107.1691 - accuracy: 0.0215 - val_loss: 101.9713 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 874us/step - loss: 81.5377 - accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 7.9705 - accuracy: 0.1998 - val_loss: 9.6364 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0878 - accuracy: 0.1675\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2846 - accuracy: 0.7200 - val_loss: 0.4781 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.8400\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 42.4840 - accuracy: 0.4770 - val_loss: 36.7771 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.7547 - accuracy: 0.4225\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 1.4552 - accuracy: 0.2810 - val_loss: 1.4583 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.7833 - accuracy: 0.4700\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.5808 - accuracy: 0.2541 - val_loss: 7.2985 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.0294 - accuracy: 0.2325\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.5487 - accuracy: 0.0857 - val_loss: 6.6470 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.7853 - accuracy: 0.2625\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 5.4536 - accuracy: 0.2960 - val_loss: 2.4316 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.3315 - accuracy: 0.4100\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 12.2214 - accuracy: 0.6807 - val_loss: 13.2137 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2687 - accuracy: 0.6950\n",
      "13/13 [==============================] - 1s 38ms/step - loss: 52.5597 - accuracy: 0.6406 - val_loss: 35.4519 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 33.2330 - accuracy: 0.6050\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.7283 - accuracy: 0.3045 - val_loss: 1.9761 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.2457 - accuracy: 0.4600\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 13.8393 - accuracy: 0.5951 - val_loss: 12.6526 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.2941 - accuracy: 0.5600\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 50.3291 - accuracy: 0.7576 - val_loss: 37.3002 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 999us/step - loss: 27.2926 - accuracy: 0.7525\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 17.9394 - accuracy: 0.1762 - val_loss: 14.5558 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.0111 - accuracy: 0.3450\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 74.2033 - accuracy: 0.6297 - val_loss: 50.1144 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 43.1767 - accuracy: 0.6200\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 110.4557 - accuracy: 0.3713 - val_loss: 74.9567 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 64.4431 - accuracy: 0.3750\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 31.1218 - accuracy: 0.4022 - val_loss: 29.9123 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.4043 - accuracy: 0.3825\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3802 - accuracy: 0.5759 - val_loss: 0.6330 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.2566 - accuracy: 0.7050\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 18.6010 - accuracy: 0.2176 - val_loss: 27.4960 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.6921 - accuracy: 0.2400\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 0.9387 - accuracy: 0.6203 - val_loss: 1.9920 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6625\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 88.5108 - accuracy: 0.0127 - val_loss: 83.2853 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 67.5860 - accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 26.5128 - accuracy: 0.2213 - val_loss: 21.5021 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.0643 - accuracy: 0.2700\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0970 - accuracy: 0.8780 - val_loss: 0.2239 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.8875\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 20.1622 - accuracy: 0.4785 - val_loss: 20.4930 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 6.8500 - accuracy: 0.4225\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4572 - accuracy: 0.7496 - val_loss: 0.8898 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.7800\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 0.6991 - accuracy: 0.7101 - val_loss: 1.9658 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 999us/step - loss: 0.5452 - accuracy: 0.7075\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.1454 - accuracy: 0.3242 - val_loss: 5.4765 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.9874 - accuracy: 0.5875\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6010 - accuracy: 0.5993 - val_loss: 1.5947 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.5917 - accuracy: 0.5775\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.4399 - accuracy: 0.6814 - val_loss: 9.3467 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9355 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 25.9836 - accuracy: 0.3134 - val_loss: 13.4136 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 12.1859 - accuracy: 0.3900\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.9791 - accuracy: 0.4672 - val_loss: 1.5566 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.8943 - accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.5822 - accuracy: 0.5713 - val_loss: 7.6111 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 3.4619 - accuracy: 0.5100\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 11.4270 - accuracy: 0.6997 - val_loss: 10.2540 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 5.0964 - accuracy: 0.7225\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 8.8222 - accuracy: 0.2505 - val_loss: 14.0788 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6947 - accuracy: 0.4075\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 33.5698 - accuracy: 0.5758 - val_loss: 37.0145 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.3001 - accuracy: 0.5175\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.09089828282594681\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 112.5451 - accuracy: 0.0444 - val_loss: 98.8124 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 70.2093 - accuracy: 0.0625\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 21.2138 - accuracy: 0.3959 - val_loss: 20.8896 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.6963 - accuracy: 0.3775\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.5224 - accuracy: 0.4838 - val_loss: 2.6213 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8762 - accuracy: 0.6350\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 21.5859 - accuracy: 0.3702 - val_loss: 21.7931 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 16.0205 - accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.7919 - accuracy: 0.5536 - val_loss: 4.5775 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.1266 - accuracy: 0.6775\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 109.1349 - accuracy: 0.0287 - val_loss: 100.5315 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 82.2249 - accuracy: 0.0200\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 30.4502 - accuracy: 0.6610 - val_loss: 23.2036 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.4249 - accuracy: 0.6850\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 0.5699 - accuracy: 0.7742 - val_loss: 0.2716 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.1552 - accuracy: 0.8125\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 10.8518 - accuracy: 0.4164 - val_loss: 11.5455 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.8018 - accuracy: 0.4075\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 1.2298 - accuracy: 0.7486 - val_loss: 1.5116 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 0.5900\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 23.2872 - accuracy: 0.6451 - val_loss: 14.1028 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 12.0002 - accuracy: 0.6950\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.9309 - accuracy: 0.3562 - val_loss: 5.2569 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0910 - accuracy: 0.4350\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.6082 - accuracy: 0.4617 - val_loss: 2.4535 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7736 - accuracy: 0.7175\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 13.7296 - accuracy: 0.7756 - val_loss: 12.9795 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2209 - accuracy: 0.6975\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 9.3991 - accuracy: 0.4349 - val_loss: 3.6353 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4119 - accuracy: 0.5150\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 16.0406 - accuracy: 0.6397 - val_loss: 5.1455 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 4.2416 - accuracy: 0.5675\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 9.7210 - accuracy: 0.3967 - val_loss: 6.9508 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 3.8479 - accuracy: 0.3925\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 16.1134 - accuracy: 0.8145 - val_loss: 8.4667 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.7245 - accuracy: 0.7175\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 6.5134 - accuracy: 0.2328 - val_loss: 12.8420 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7625 - accuracy: 0.3700\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 37.3853 - accuracy: 0.2752 - val_loss: 20.3360 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 14.6733 - accuracy: 0.3100\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 74.6084 - accuracy: 0.3871 - val_loss: 47.6723 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 40.8999 - accuracy: 0.3500\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 13.5669 - accuracy: 0.3865 - val_loss: 13.9369 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 7.8001 - accuracy: 0.3475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2796 - accuracy: 0.6789 - val_loss: 0.4689 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.7025\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 14.0011 - accuracy: 0.2244 - val_loss: 20.5504 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 9.6664 - accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 254.9506 - accuracy: 0.5921 - val_loss: 249.4840 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 915us/step - loss: 201.4544 - accuracy: 0.6275\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 72.2116 - accuracy: 0.0137 - val_loss: 67.1067 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 54.9867 - accuracy: 0.0200\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 19.6984 - accuracy: 0.3290 - val_loss: 16.7463 - val_accuracy: 0.1600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.0209 - accuracy: 0.3675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0956 - accuracy: 0.8704 - val_loss: 0.2159 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.0863 - accuracy: 0.8725\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.0539 - accuracy: 0.3908 - val_loss: 6.4583 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6194 - accuracy: 0.2775\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.7643 - val_loss: 0.8125 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.7500\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 76.9119 - accuracy: 0.2077 - val_loss: 70.6370 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 915us/step - loss: 47.4113 - accuracy: 0.1825\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.1033 - accuracy: 0.4687 - val_loss: 4.5453 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4863 - accuracy: 0.5650\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5537 - accuracy: 0.6464 - val_loss: 1.3282 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.4923 - accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.8850 - accuracy: 0.6488 - val_loss: 6.5301 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 967us/step - loss: 3.4292 - accuracy: 0.6725\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 152.7011 - accuracy: 0.3191 - val_loss: 296.8483 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 116.0252 - accuracy: 0.3800\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.2603 - accuracy: 0.6622 - val_loss: 0.2726 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.8875\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 89.8784 - accuracy: 0.3314 - val_loss: 101.3296 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 915us/step - loss: 75.0310 - accuracy: 0.3550\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 184.9045 - accuracy: 0.1526 - val_loss: 203.4866 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 833us/step - loss: 138.1000 - accuracy: 0.1925\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.4794 - accuracy: 0.3598 - val_loss: 9.9464 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 3.2929 - accuracy: 0.4750\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 13.9305 - accuracy: 0.5770 - val_loss: 17.5598 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1422 - accuracy: 0.3575\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.08628351241350174\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 52.4614 - accuracy: 0.3865 - val_loss: 33.7078 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.3339 - accuracy: 0.3075\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 10.6737 - accuracy: 0.3407 - val_loss: 8.5415 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3476 - accuracy: 0.3475\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 2.6662 - accuracy: 0.3308 - val_loss: 2.3774 - val_accuracy: 0.5400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.1177 - accuracy: 0.6100\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.5202 - accuracy: 0.2276 - val_loss: 15.5544 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 4.8000 - accuracy: 0.2800\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 170.2386 - accuracy: 0.6504 - val_loss: 186.9839 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 126.3540 - accuracy: 0.6600\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 60.8909 - accuracy: 0.0346 - val_loss: 57.7390 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 45.0309 - accuracy: 0.0425\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 17.1150 - accuracy: 0.5215 - val_loss: 17.0082 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3569 - accuracy: 0.4250\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.7494 - accuracy: 0.3371 - val_loss: 0.5272 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.7275\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 10.3833 - accuracy: 0.4378 - val_loss: 9.3414 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 3.1942 - accuracy: 0.5275\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 1.3346 - accuracy: 0.3804 - val_loss: 1.2463 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.4200\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 45.1438 - accuracy: 0.6099 - val_loss: 43.3852 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.4180 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.2074 - accuracy: 0.1388 - val_loss: 4.1271 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.2422 - accuracy: 0.3125\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1.1314 - accuracy: 0.5384 - val_loss: 1.9439 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 0.7183 - accuracy: 0.5350\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.2389 - accuracy: 0.6334 - val_loss: 4.7707 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1102 - accuracy: 0.5500\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 120.4849 - accuracy: 0.3985 - val_loss: 210.0954 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 82.2840 - accuracy: 0.4650\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 7.3522 - accuracy: 0.6149 - val_loss: 4.5055 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 3.8964 - accuracy: 0.6225\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 70.2005 - accuracy: 0.3873 - val_loss: 84.2425 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 59.6321 - accuracy: 0.3950\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 182.0270 - accuracy: 0.1062 - val_loss: 205.8892 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 917us/step - loss: 139.0614 - accuracy: 0.1450\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 11.3426 - accuracy: 0.2978 - val_loss: 6.5311 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 916us/step - loss: 4.7242 - accuracy: 0.3275\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 8.8381 - accuracy: 0.3160 - val_loss: 12.6556 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.2635 - accuracy: 0.3950\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 32.4061 - accuracy: 0.2908 - val_loss: 18.1780 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.1129 - accuracy: 0.2725\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 6.0785 - accuracy: 0.3310 - val_loss: 5.6747 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7464 - accuracy: 0.2875\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.2149 - accuracy: 0.7588 - val_loss: 0.4171 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.6875\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 5.2167 - accuracy: 0.2873 - val_loss: 13.8878 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.5753 - accuracy: 0.3825\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 136.0945 - accuracy: 0.6230 - val_loss: 139.8291 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 94.0083 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 49.0080 - accuracy: 0.0388 - val_loss: 44.2939 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.4049 - accuracy: 0.0425\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 10.2340 - accuracy: 0.5118 - val_loss: 16.3253 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6980 - accuracy: 0.5175\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 78.5595 - accuracy: 0.4346 - val_loss: 71.0837 - val_accuracy: 0.3200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 52.8484 - accuracy: 0.5100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.6901 - accuracy: 0.3650 - val_loss: 5.0549 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.6772 - accuracy: 0.4600\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 0.3509 - accuracy: 0.7949 - val_loss: 0.7785 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8050\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 28.6971 - accuracy: 0.6113 - val_loss: 28.1843 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.2622 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 1.5899 - accuracy: 0.5321 - val_loss: 4.1999 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2179 - accuracy: 0.6250\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.4706 - accuracy: 0.6354 - val_loss: 1.3708 - val_accuracy: 0.8200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.4135 - accuracy: 0.6625\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.6204 - accuracy: 0.6451 - val_loss: 4.4075 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 915us/step - loss: 3.5268 - accuracy: 0.7300\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 74.0524 - accuracy: 0.0100 - val_loss: 66.2296 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 983us/step - loss: 53.0814 - accuracy: 0.0125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1259 - accuracy: 0.8427 - val_loss: 0.1896 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.8825\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 65.2814 - accuracy: 0.4156 - val_loss: 67.7321 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 49.9003 - accuracy: 0.4050\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 138.5936 - accuracy: 0.1514 - val_loss: 148.8743 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 101.4275 - accuracy: 0.2100\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 159.4545 - accuracy: 0.1555 - val_loss: 103.8464 - val_accuracy: 0.1200\n",
      "13/13 [==============================] - 0s 750us/step - loss: 76.2445 - accuracy: 0.1150\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 4.0244 - accuracy: 0.3558 - val_loss: 10.5426 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2666 - accuracy: 0.4150\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 14.6405 - accuracy: 0.1271 - val_loss: 8.2398 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 7.5204 - accuracy: 0.1200\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 7.5865 - accuracy: 0.3719 - val_loss: 6.1524 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2675 - accuracy: 0.3475\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 7.2009 - accuracy: 0.3825 - val_loss: 3.4814 - val_accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 999us/step - loss: 3.4914 - accuracy: 0.3825\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 5.6514 - accuracy: 0.4413 - val_loss: 16.1852 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.9437 - accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 109.9114 - accuracy: 0.3633 - val_loss: 111.5784 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 998us/step - loss: 74.2320 - accuracy: 0.4375\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 45.4844 - accuracy: 0.0328 - val_loss: 37.8977 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 32.0941 - accuracy: 0.0275\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 12.3468 - accuracy: 0.2091 - val_loss: 12.1693 - val_accuracy: 0.2400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.6438 - accuracy: 0.4350\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 60.6152 - accuracy: 0.5191 - val_loss: 50.6696 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 46.0304 - accuracy: 0.5500\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 10.4306 - accuracy: 0.0272 - val_loss: 5.2797 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 917us/step - loss: 2.5197 - accuracy: 0.2525\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.0622 - accuracy: 0.1551 - val_loss: 1.8656 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8648 - accuracy: 0.3025\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 51.2327 - accuracy: 0.5707 - val_loss: 40.3506 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 31.1738 - accuracy: 0.6000\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 3.3723 - accuracy: 0.4136 - val_loss: 3.5315 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 1.3333 - accuracy: 0.5525\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 4.7287 - accuracy: 0.1794 - val_loss: 2.9533 - val_accuracy: 0.8000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5874 - accuracy: 0.6350\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 7.0286 - accuracy: 0.6341 - val_loss: 2.9546 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6385 - accuracy: 0.7325\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 42.9094 - accuracy: 0.0132 - val_loss: 34.8691 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 27.5243 - accuracy: 0.0175\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 0.4739 - accuracy: 0.3272 - val_loss: 0.1745 - val_accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.8425\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 55.9315 - accuracy: 0.4575 - val_loss: 59.8755 - val_accuracy: 0.4000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 46.9930 - accuracy: 0.4550\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 78.6356 - accuracy: 0.1741 - val_loss: 82.2873 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 52.7595 - accuracy: 0.2625\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 103.6009 - accuracy: 0.0863 - val_loss: 67.5822 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 55.7454 - accuracy: 0.0850\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 11.2311 - accuracy: 0.5531 - val_loss: 9.8623 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3282 - accuracy: 0.6350\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 7.8380 - accuracy: 0.1406 - val_loss: 6.9371 - val_accuracy: 0.2200\n",
      "13/13 [==============================] - 0s 792us/step - loss: 4.5391 - accuracy: 0.1675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.8613 - accuracy: 0.2650 - val_loss: 3.6857 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 1.8321 - accuracy: 0.3600\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.7691 - val_loss: 0.3631 - val_accuracy: 0.7000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.7375\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.0311 - accuracy: 0.3384 - val_loss: 12.3850 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9428 - accuracy: 0.4300\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 75.9964 - accuracy: 0.4070 - val_loss: 76.4414 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 49.7689 - accuracy: 0.4350\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 35.0416 - accuracy: 0.0191 - val_loss: 27.6109 - val_accuracy: 0.0800\n",
      "13/13 [==============================] - 0s 917us/step - loss: 24.1528 - accuracy: 0.0350\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.0390 - accuracy: 0.2970 - val_loss: 9.9076 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4885 - accuracy: 0.5625\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 49.7439 - accuracy: 0.5633 - val_loss: 38.5103 - val_accuracy: 0.5600\n",
      "13/13 [==============================] - 0s 916us/step - loss: 37.4870 - accuracy: 0.5425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.4990 - accuracy: 0.4706 - val_loss: 3.2874 - val_accuracy: 0.6600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.0927 - accuracy: 0.4675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.8031 - val_loss: 0.6803 - val_accuracy: 0.6200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 18.9658 - accuracy: 0.5848 - val_loss: 17.5161 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.4878 - accuracy: 0.5975\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 1.1211 - accuracy: 0.5719 - val_loss: 3.0884 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0080 - accuracy: 0.5125\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3938 - accuracy: 0.6552 - val_loss: 1.1905 - val_accuracy: 0.8400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.6975\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 9.9389 - accuracy: 0.6361 - val_loss: 8.9071 - val_accuracy: 0.4600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.2896 - accuracy: 0.6075\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 28.0165 - accuracy: 0.0157 - val_loss: 22.0112 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.4153 - accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.8527 - val_loss: 0.1622 - val_accuracy: 0.7600\n",
      "13/13 [==============================] - 0s 915us/step - loss: 0.0812 - accuracy: 0.8800\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 49.4113 - accuracy: 0.4574 - val_loss: 47.5675 - val_accuracy: 0.3800\n",
      "13/13 [==============================] - 0s 916us/step - loss: 38.7472 - accuracy: 0.4750\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 40.6009 - accuracy: 0.0826 - val_loss: 41.3217 - val_accuracy: 0.1800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 24.6507 - accuracy: 0.1125\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 62.7947 - accuracy: 0.0764 - val_loss: 38.5570 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 30.5795 - accuracy: 0.0675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.3036 - accuracy: 0.4233 - val_loss: 7.6992 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 2.4167 - accuracy: 0.3150\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.08122154325246811\n",
      "\n",
      "******\n",
      "\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 11.3822 - accuracy: 0.4868 - val_loss: 7.1231 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 4.9269 - accuracy: 0.2400\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 13.2484 - accuracy: 0.6382 - val_loss: 9.0776 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.2685 - accuracy: 0.6050\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 2.6862 - accuracy: 0.0560 - val_loss: 1.2971 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.5300\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 24.7598 - accuracy: 0.4019 - val_loss: 16.1124 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.5365 - accuracy: 0.3750\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 32.9626 - accuracy: 0.5893 - val_loss: 33.4643 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.3384 - accuracy: 0.6475\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 46.0340 - accuracy: 0.0193 - val_loss: 39.7513 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.4513 - accuracy: 0.0150\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 11.7013 - accuracy: 0.7515 - val_loss: 9.2545 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9655 - accuracy: 0.8025\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 51.5618 - accuracy: 0.5885 - val_loss: 37.9524 - val_accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 38.0905 - accuracy: 0.6000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 58.8585 - accuracy: 0.0173 - val_loss: 36.1454 - val_accuracy: 0.0200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 35.3688 - accuracy: 0.0125\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 10.5911 - accuracy: 0.4086 - val_loss: 4.9243 - val_accuracy: 0.5800\n",
      "13/13 [==============================] - 0s 999us/step - loss: 5.5090 - accuracy: 0.5025\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 14.9667 - accuracy: 0.6060 - val_loss: 10.1421 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.4635 - accuracy: 0.6375\n",
      "13/13 [==============================] - 1s 32ms/step - loss: 9.2756 - accuracy: 0.1518 - val_loss: 6.5638 - val_accuracy: 0.2000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 4.7369 - accuracy: 0.1725\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.7494 - accuracy: 0.2093 - val_loss: 1.9116 - val_accuracy: 0.4400\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.4057 - accuracy: 0.2375\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 11.2600 - accuracy: 0.7753 - val_loss: 10.3524 - val_accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 6.0179 - accuracy: 0.7325\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 20.0769 - accuracy: 0.0076 - val_loss: 14.4113 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 999us/step - loss: 12.2175 - accuracy: 0.0300\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.6880 - accuracy: 0.7493 - val_loss: 1.6105 - val_accuracy: 0.7800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 1.4490 - accuracy: 0.7275\n",
      "13/13 [==============================] - 1s 33ms/step - loss: 44.8055 - accuracy: 0.5153 - val_loss: 37.0479 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 916us/step - loss: 34.1472 - accuracy: 0.5325\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 26.3869 - accuracy: 0.0862 - val_loss: 27.0722 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 15.1688 - accuracy: 0.1675\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 53.0928 - accuracy: 0.1187 - val_loss: 35.7289 - val_accuracy: 0.0600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 24.6650 - accuracy: 0.1950\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 24.7225 - accuracy: 0.3406 - val_loss: 21.5644 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.3800 - accuracy: 0.3050\n",
      "\n",
      "*******************************************************一轮迭代后开始计算适应度*************************************************************\n",
      "\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2643 - accuracy: 0.1964 - val_loss: 6.6725 - val_accuracy: 0.2600\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0529 - accuracy: 0.2625\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 62.3971 - accuracy: 0.0772 - val_loss: 42.3034 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 46.6900 - accuracy: 0.1425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1824 - accuracy: 0.7445 - val_loss: 0.3104 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.7975\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.2113 - accuracy: 0.4373 - val_loss: 10.4260 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 917us/step - loss: 2.4219 - accuracy: 0.4750\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 21.2899 - accuracy: 0.6229 - val_loss: 23.1717 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.3036 - accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 26.9209 - accuracy: 0.0268 - val_loss: 19.4944 - val_accuracy: 0.1000\n",
      "13/13 [==============================] - 0s 833us/step - loss: 17.6924 - accuracy: 0.0450\n",
      "13/13 [==============================] - 1s 30ms/step - loss: 295.2015 - accuracy: 0.5920 - val_loss: 243.8988 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 222.3085 - accuracy: 0.5925\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 42.3430 - accuracy: 0.5095 - val_loss: 29.2669 - val_accuracy: 0.5200\n",
      "13/13 [==============================] - 0s 999us/step - loss: 30.3086 - accuracy: 0.5425\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.9233 - accuracy: 0.5393 - val_loss: 2.4335 - val_accuracy: 0.6800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8211 - accuracy: 0.5350\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2699 - accuracy: 0.8247 - val_loss: 0.5990 - val_accuracy: 0.6400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8475\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 8.2461 - accuracy: 0.6269 - val_loss: 6.6578 - val_accuracy: 0.4800\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 3.6892 - accuracy: 0.5675\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.0346 - accuracy: 0.5404 - val_loss: 2.7773 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8390 - accuracy: 0.5625\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.3323 - accuracy: 0.6807 - val_loss: 0.9257 - val_accuracy: 0.8400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.7200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.4672 - accuracy: 0.7505 - val_loss: 6.7708 - val_accuracy: 0.5000\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0223 - accuracy: 0.6650\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 13.3999 - accuracy: 0.0273 - val_loss: 9.5878 - val_accuracy: 0.3000\n",
      "13/13 [==============================] - 0s 902us/step - loss: 8.2181 - accuracy: 0.2150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0889 - accuracy: 0.9012 - val_loss: 0.1488 - val_accuracy: 0.7400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 37.8618 - accuracy: 0.5169 - val_loss: 28.8842 - val_accuracy: 0.4200\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 27.2879 - accuracy: 0.5475\n",
      "13/13 [==============================] - 1s 29ms/step - loss: 16.3452 - accuracy: 0.1450 - val_loss: 16.2520 - val_accuracy: 0.2800\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.6167 - accuracy: 0.2175\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 26.6105 - accuracy: 0.1095 - val_loss: 21.8913 - val_accuracy: 0.0400\n",
      "13/13 [==============================] - 0s 917us/step - loss: 12.2321 - accuracy: 0.2250\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2994 - accuracy: 0.3403 - val_loss: 8.1595 - val_accuracy: 0.3400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1322 - accuracy: 0.6075\n",
      "\n",
      "*****************************************************************结束************************************************************\n",
      "\n",
      "\n",
      "******\n",
      "\n",
      " BEST_LOSSNESS IS %.2f : \n",
      " 0.0768551379442215\n",
      "\n",
      "******\n",
      "\n",
      "CS最优loss为:%.5f! 0.0768551379442215\n"
     ]
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "low = -3*np.ones(numsum)\n",
    "upp = 3*np.ones(numsum)\n",
    "best_nest, best_loss,best_fitness = cuckoo_search(20,numsum, low,upp, step_size = 0.4)\n",
    " \n",
    "\n",
    "print('CS最优loss为:%.5f!',best_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom = best_nest\n",
    "w1 = chrom[:inputnum*hiddennum]\n",
    "w1 = w1.reshape(inputnum,hiddennum)\n",
    "b1 = chrom[inputnum*hiddennum:inputnum*hiddennum+hiddennum]\n",
    "w2 = chrom[inputnum*hiddennum+hiddennum:inputnum*hiddennum+hiddennum+hiddennum*outputnum]\n",
    "w2 = w2.reshape(hiddennum,outputnum)\n",
    "b2 = chrom[inputnum*hiddennum+hiddennum+hiddennum*outputnum:]\n",
    "\n",
    "WB_layer1 = (w1,b1)\n",
    "WB_layer2 = (w2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用CS优化初始化阈值\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(hiddennum,name='layer1',activation='relu'),\n",
    "    keras.layers.Dense(outputnum,name='layer2')\n",
    "])\n",
    "\n",
    "\n",
    "model.build(input_shape=[None,inputnum])\n",
    "#model.summary()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "            loss='mse',\n",
    "            metrics=['accuracy'])\n",
    "#model.load_weights('my_model_fun.h5')\n",
    "\n",
    "layer1 = model.get_layer('layer1')\n",
    "layer2 = model.get_layer('layer2')\n",
    "layer1.set_weights(WB_layer1)\n",
    "layer2.set_weights(WB_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看模型参数\n",
    "# la1 = model.get_layer('layer1')\n",
    "# la2 = model.get_layer('layer2')\n",
    "# (k1,b1) = la1.get_weights()\n",
    "# (k2,b2) = la2.get_weights()\n",
    "# k1,b1,k2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=k1.reshape(1,-1).tolist()\n",
    "b=b1.reshape(1,-1).tolist()\n",
    "c = a[0] + b[0]\n",
    "len(k1.reshape(1,-1).tolist()[0] + b1.reshape(1,-1).tolist()[0] + k2.reshape(1,-1).tolist()[0] + b2.reshape(1,-1).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.8979\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9221\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9186\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9064\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0614 - accuracy: 0.8929 - val_loss: 0.1146 - val_accuracy: 0.7800\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9105\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9427\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9172\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9281\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9129 - val_loss: 0.0902 - val_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9095\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9152\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9188\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9248\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9230 - val_loss: 0.0847 - val_accuracy: 0.8400\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9134\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9054\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9142\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9119\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9101 - val_loss: 0.0744 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9418\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9320\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9087\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9235 - val_loss: 0.0781 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9150\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9027\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9155\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9254\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9075 - val_loss: 0.0620 - val_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9345\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.8915\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9235\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9092\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.8941 - val_loss: 0.0638 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 833us/step - loss: 0.0309 - accuracy: 0.9094\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.8984\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9263\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9014\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9133 - val_loss: 0.0587 - val_accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9091\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9065\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9216\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9264\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9387 - val_loss: 0.0594 - val_accuracy: 0.8800\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9019\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9441\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9372\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.8986 - val_loss: 0.0600 - val_accuracy: 0.8600\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9179\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9336\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9334\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9451\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9381 - val_loss: 0.0651 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9349\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9336\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9395\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9203\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9474 - val_loss: 0.0593 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9503\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9369\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9411\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9411\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9451 - val_loss: 0.0586 - val_accuracy: 0.8600\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9144\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9345\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9333\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9245\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9399 - val_loss: 0.0579 - val_accuracy: 0.8600\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9135\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9525\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9364\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9202\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9460 - val_loss: 0.0599 - val_accuracy: 0.8600\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9283\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 1000us/step - loss: 0.0298 - accuracy: 0.9090\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9418\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.0244 - accuracy: 0.9340\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9475 - val_loss: 0.0601 - val_accuracy: 0.8400\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9341\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9453\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9432\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9561\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9241 - val_loss: 0.0585 - val_accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 833us/step - loss: 0.0291 - accuracy: 0.9340\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9445\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 916us/step - loss: 0.0267 - accuracy: 0.9383\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9278\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9268 - val_loss: 0.0671 - val_accuracy: 0.8400\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 833us/step - loss: 0.0228 - accuracy: 0.9493\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9459\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9380\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9356\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9260 - val_loss: 0.0641 - val_accuracy: 0.8600\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9459\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9392\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9521\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9393\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9486 - val_loss: 0.0608 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ec570cc88>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "model.fit(db,epochs=100,validation_data=ds_val,validation_freq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.8600\n",
      "\n",
      "test loss 0.06082410737872124\n",
      "accuracy 0.8600000143051147\n"
     ]
    }
   ],
   "source": [
    "# 评估模型,不输出预测结果\n",
    "loss,accuracy = model.evaluate(ds_val)\n",
    "print('\\ntest loss',loss)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型预测,输入测试集,输出预测结果\n",
    "y_pred = model.predict(TestX)\n",
    "y_pred = tf.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 1, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = tf.argmax(TestY_onehot,axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(400,), dtype=int64, numpy=\n",
       "array([2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1,\n",
       "       2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
       "       2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X)\n",
    "y_pred_train = tf.argmax(y_pred_train,axis=1)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-f40fdb8c2d6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_onehot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "train_y = tf.argmax(Y_onehot,axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "x = list(range(0,len(bestfit)))\n",
    "fig = sns.lineplot(x,bestfit)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fitness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestFit', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = y_pred - test_y\n",
    "x = list(range(0,len(error)))\n",
    "fig = sns.lineplot(x,error,color=\"b\")\n",
    "plt.xlabel(\"Test Data Num\")\n",
    "plt.ylabel(\"error\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./Error_Num', dpi = 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 8)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bestloss),len(bestfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(0,len(bestloss)))\n",
    "fig = sns.lineplot(x,bestloss,color=\"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"lossness\")\n",
    "scatter_fig = fig.get_figure()\n",
    "scatter_fig.savefig('./BestLoss', dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns主题风格  darkgrid  whitegrid  dark  white  ticks\n",
    "sns.set_style(\"ticks\")  #设置主题风格\n",
    "sns.color_palette(\"hls\",8)  #设置颜色空间种类（几种可用颜色）\n",
    "data=np.random.normal(size=(20,8)) + np.arange(8) /2\n",
    "sns.boxplot(data = data,palette = sns.color_palette(\"hls\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描述两个变量的关系 最好用散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mean,cov = [0,1],[(1,.5),(.5,1)]\n",
    "data = np.random.multivariate_normal(mean,cov,200)\n",
    "df = pd.DataFrame(data,columns=[\"x\",\"y\"])\n",
    "#绘制散点图\n",
    "sns.jointplot(x=\"x\",y=\"y\",data = df,color=\"r\")  #如果点很多，用颜色深度表示数量 kind=\"hex\" ,可以单独传x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移植STM32准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testx = X / X.max().max()\n",
    "Testx = np.array(Testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "aa.append(list(Testx[0]))\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sig=model.predict(aa)\n",
    "pre_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmax(pre_sig,axis=None)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Env.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(load_model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"level_check.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #建立一个测试模型\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(5,), name='dense_xiaoming',\n",
    "          kernel_initializer='zeros',  # 全部初始化为0\n",
    "          bias_initializer='ones'),  # 全部初始化为1\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(shape=(8, 5))  # 创建测试数据\n",
    "y = model(x)\n",
    "layer = model.get_layer('dense_xiaoming')  # 通过层的名字得到层\n",
    "(k, b) = layer.get_weights()  # 查看层的初始化权重值和偏置项\n",
    "print(k)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
